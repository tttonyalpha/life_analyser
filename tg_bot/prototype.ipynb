{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "325e371e",
   "metadata": {},
   "source": [
    "# Bot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26d4ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "from telegram import Update, Bot\n",
    "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext\n",
    "\n",
    "bot = Bot(token=API_TOKEN)\n",
    "updater = Updater(token=API_TOKEN, use_context=True)\n",
    "dispatcher = updater.dispatcher\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                     level=logging.INFO)\n",
    "\n",
    "\n",
    "def send_new_channel_messages(update: Update, context: CallbackContext):\n",
    "    channel_id = 'my life'\n",
    "    channel_updates = bot.get_chat_updates(channel_id)\n",
    "\n",
    "    user_id = update.message.from_user.id\n",
    "\n",
    "    for update in channel_updates:\n",
    "        if update.message:\n",
    "            bot.forward_message(chat_id=user_id, from_chat_id=channel_id, message_id=update.message.message_id)\n",
    "\n",
    "\n",
    "def start(update: Update, context: CallbackContext):\n",
    "    user_id = update.message.from_user.id\n",
    "    update.message.reply_text(f\"Hello! I will send you new messages from the channel.\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    dispatcher.add_handler(MessageHandler(Filters.chat_type.channel, send_new_channel_messages))\n",
    "    dispatcher.add_handler(CommandHandler(\"start\", start))\n",
    "\n",
    "    updater.start_polling()\n",
    "    updater.idle()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418dd5f9",
   "metadata": {},
   "source": [
    "# Config upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "939bbbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import json\n",
    "\n",
    "from telethon import TelegramClient\n",
    "from telethon.errors import SessionPasswordNeededError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72b65267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Configs\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "\n",
    "# Setting configuration values\n",
    "api_id = config['Telegram']['api_id']\n",
    "api_hash = config['Telegram']['api_hash']\n",
    "api_token = config['Telegram']['api_token']\n",
    "\n",
    "api_hash = str(api_hash)\n",
    "\n",
    "phone = config['Telegram']['phone']\n",
    "username = config['Telegram']['username']\n",
    "channel_link = config['Telegram']['channel_link'] \n",
    "\n",
    "db_name = config['database']['db_name']\n",
    "db_user = config['database']['db_user']\n",
    "db_password = config['database']['db_password'] \n",
    "db_host = config['database']['db_host'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "976b3fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "#facebook_bart_large_mnli = pipeline(\"zero-shot-classification\", model=\"/media/tonyalpha/HDD/facebook-bart-large-mnli\")\n",
    "#bertweet_base_sentiment_analysis = pipeline(\"text-classification\", model=\"/media/tonyalpha/HDD/bertweet-base-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f1dcc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not client.is_user_authorized():\n",
    "#     client.send_code_request(phone)\n",
    "#     try:\n",
    "#         client.sign_in(phone, input('Enter the code: '))\n",
    "#     except SessionPasswordNeededError:\n",
    "#         client.sign_in(password=input('Password: '))\n",
    "\n",
    "# me = client.get_me()\n",
    "# print(me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1418ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "430ea71a",
   "metadata": {},
   "source": [
    "# Get data from telegram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f74220e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from telethon.tl.types import InputMessagesFilterPhotos\n",
    "from telethon import TelegramClient, events\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os.path\n",
    "\n",
    "def get_posts(num_posts = 1, download_media = False, only_with_media = True, offset_id = 0, posts_list = []):\n",
    "    client = TelegramClient(username, api_id, api_hash)\n",
    "    posts_list = []\n",
    "    async def main(num_posts, download_media, offset_id, posts_list):\n",
    "        \n",
    "        if num_posts < 100:\n",
    "            message_limit = num_posts\n",
    "        else:\n",
    "            message_limit = 100\n",
    "            \n",
    "            \n",
    "        last_post_date = None\n",
    "        post = {}\n",
    "        \n",
    "        await client.start()\n",
    "\n",
    "        try:\n",
    "            entity = await client.get_entity(channel_link)\n",
    "\n",
    "            while True:\n",
    "                messages = await client.get_messages(entity, limit=message_limit, offset_id = offset_id)\n",
    "\n",
    "                for message in messages:\n",
    "                    \n",
    "                    if only_with_media:\n",
    "                        if not message.media:\n",
    "                            continue\n",
    "                    \n",
    "                    if last_post_date == None:\n",
    "                        last_post_date = message.date\n",
    "\n",
    "                    # if delay between uploading messages is more than 10 second i will separate them\n",
    "                    if (last_post_date - message.date).seconds > 10: \n",
    "                        post['upload_date'] = last_post_date.strftime('%Y-%m-%d %H:%M:%S') if last_post_date else None\n",
    "\n",
    "                        last_post_date = message.date\n",
    "\n",
    "                        posts_list.append(post)\n",
    "                        post = {}\n",
    "\n",
    "\n",
    "                    if len(message.message) > 0:\n",
    "                        post['text'] = post.get('text', '') + message.message \n",
    "                        \n",
    "                        # post_id in messages set will be id of message with text and photo \n",
    "                        post['post_id'] = message.id\n",
    "\n",
    "\n",
    "                    if message.media and download_media:\n",
    "\n",
    "                        photo_id = message.media.photo.id\n",
    "                        filename = f'image_{photo_id}.jpg'\n",
    "                        path = f\"./media/{filename}\"\n",
    "\n",
    "                        # some of this i should drop, but later \n",
    "                        post['photos_id_list'] = post.get('photos_id_list', []) + [photo_id]\n",
    "                        post['photos_names_list'] = post.get('photos_names_list', []) + [filename]\n",
    "\n",
    "                        #if file exist check \n",
    "                        if not os.path.isfile(path) and download_media:\n",
    "                            await client.download_media(message, file=path)\n",
    "\n",
    "                    post['id_list'] = post.get('id_list', []) + [message.id]\n",
    "                    post['edit_date'] = message.edit_date.strftime('%Y-%m-%d %H:%M:%S') if message.edit_date else None\n",
    "\n",
    "\n",
    "                offset_id = messages[len(messages) - 1].id\n",
    "\n",
    "                if len(posts_list) >= num_posts:\n",
    "                    break\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "        await client.disconnect()\n",
    "        \n",
    "        return posts_list\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        client.loop.run_until_complete(main(num_posts, download_media, offset_id, posts_list))\n",
    "        \n",
    "    return posts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20c524a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id_list': [724, 723, 722, 721],\n",
       "  'edit_date': '2023-07-27 07:17:32',\n",
       "  'text': '26.07.23\\n\\nHiking with Ann\\n\\nWorking on my project\\n\\n* Gym \\n\\n* Interesting history lecture \\n\\nHow productive have you been?: 4.5/10\\nHow interesting was the day?: 6/10\\nHow stressful was the day?: 1/10',\n",
       "  'post_id': 721,\n",
       "  'upload_date': '2023-07-26 16:28:42'},\n",
       " {'id_list': [720, 719, 718],\n",
       "  'edit_date': '2023-07-26 16:02:57',\n",
       "  'text': '25.07.23\\n\\nAwesome cycling with Anna and her brother \\n\\nLazy work on my project\\n\\nInteresting mathematics lecture before sleep\\n\\nHow productive have you been?: 3.5/10\\nHow interesting was the day?: 6/10\\nHow stressful was the day?: 2/10',\n",
       "  'post_id': 718,\n",
       "  'upload_date': '2023-07-26 13:32:45'},\n",
       " {'id_list': [717, 716, 715],\n",
       "  'edit_date': '2023-07-26 16:02:48',\n",
       "  'text': '24.07.23\\n\\nGym: good traning \\n\\nMy project for portfolio: do some things  \\n\\nInteresting history lecture  \\n\\nHow productive have you been?: 4.5/10\\nHow interesting was the day?: 5/10\\nHow stressful was the day?: 0/10',\n",
       "  'post_id': 715,\n",
       "  'upload_date': '2023-07-26 13:31:56'},\n",
       " {'id_list': [714, 713, 712],\n",
       "  'edit_date': '2023-07-26 16:04:37',\n",
       "  'text': '23.07.23\\n\\nMoving to new flat  \\n\\nWorking on my project\\n\\nHow productive have you been?: 5/10\\nHow interesting was the day?: 5/10\\nHow stressful was the day?: 2/10',\n",
       "  'post_id': 712,\n",
       "  'upload_date': '2023-07-26 13:29:37'},\n",
       " {'id_list': [711, 710, 709],\n",
       "  'edit_date': '2023-07-26 16:04:59',\n",
       "  'text': '22.07.23\\n\\nWork on my project\\n\\nLazy day \\n\\nHow productive have you been?: 5/10\\nHow interesting was the day?: 3/10\\nHow stressful was the day?: 0/10',\n",
       "  'post_id': 709,\n",
       "  'upload_date': '2023-07-26 13:28:22'},\n",
       " {'id_list': [707, 706, 705],\n",
       "  'edit_date': '2023-07-26 16:05:34',\n",
       "  'text': '21.07.23\\n\\nWorking on my project\\n\\nCooking \\n\\nEvening with Anna family \\n\\nHow productive have you been?: 4/10\\nHow interesting was the day?: 6/10\\nHow stressful was the day?: 0/10',\n",
       "  'post_id': 705,\n",
       "  'upload_date': '2023-07-26 11:10:37'},\n",
       " {'id_list': [704, 703, 702],\n",
       "  'edit_date': '2023-07-26 13:35:01',\n",
       "  'text': '20.07.23\\n\\nMy project\\n\\nHousehold stuff\\n\\nMovies time: spider man awesome cartoon!\\n\\nHow productive have you been?: 5/10\\nHow interesting was the day?: 6/10\\nHow stressful was the day?: 0/10',\n",
       "  'post_id': 702,\n",
       "  'upload_date': '2023-07-26 11:07:52'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_posts(num_posts = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a8aa96",
   "metadata": {},
   "source": [
    "# Data parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9c5529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39971730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def parse_text(dct):\n",
    "    \n",
    "    input_string = dct['text']\n",
    "    \n",
    "    date_pattern = r'\\d{2}\\.\\d{2}\\.\\d{2}'\n",
    "    day_pattern = r'\\b(?:MONDAY|TUESDAY|WEDNESDAY|THURSDAY|FRIDAY|SATURDAY|SUNDAY)\\b'\n",
    "    \n",
    "    date_match = re.search(date_pattern, input_string)\n",
    "    day_match = re.search(day_pattern, input_string)\n",
    "    \n",
    "    date = date_match.group() if date_match else None\n",
    "    day = day_match.group() if day_match else None\n",
    "    \n",
    "    parsed_date = date.split('.')[-1] + '-' + date.split('.')[1] + '-' + date.split('.')[0] if date or day else None\n",
    "    \n",
    "    dct['parsed_date'] = parsed_date\n",
    "    \n",
    "    if date_match:\n",
    "        input_string = input_string.replace(date_match.group(), \"\") if parsed_date is not None else input_string\n",
    "    if day_match:\n",
    "        input_string = input_string.replace(day_match.group(), \"\") if parsed_date is not None else input_string\n",
    "    \n",
    "    regex_list = [r'How productive have you been\\?:\\s*(\\S|\\s+|\\d+\\.?\\d*)/10', r'How interesting was the day\\?:\\s*(\\S|\\s+|\\d+\\.?\\d*)/10', r'How stressful was the day\\?:\\s*(\\S|\\s+|\\d+\\.?\\d*)/10']\n",
    "    names_list = ['productivity_score', 'interest_score', 'stress_score']\n",
    "    \n",
    "    for regex, name in zip(regex_list, names_list):\n",
    "        match = re.search(regex, input_string)\n",
    "        \n",
    "        if match:\n",
    "            try:\n",
    "                parsed_score = float(match.group(1))\n",
    "            except:\n",
    "                parsed_score = None\n",
    "        else:\n",
    "            parsed_score = None\n",
    "        \n",
    "        \n",
    "        #parsed_score = match.group(1) if match and match.group(1).isdigit() else None\n",
    "        \n",
    "        dct[name] = parsed_score\n",
    "\n",
    "        input_string = input_string.replace(match.group(), \"\") if match else input_string\n",
    "        \n",
    "    \n",
    "    dct['parsed_text'] = input_string.split('\\n')\n",
    "    return dct\n",
    "    \n",
    "def parse_activities(dct):\n",
    "    \n",
    "    input_list = dct['parsed_text']\n",
    "    \n",
    "    result = []\n",
    "    for item in input_list:\n",
    "        match = re.match(r'^([\\U0001F000-\\U0001F9FF]+|[\\U0001FA00-\\U0001FA6F]+|\\*)?\\s*(.*)$', item)\n",
    "        if match:\n",
    "            emoji = match.group(1)\n",
    "            text = match.group(2).strip()\n",
    "            if emoji or text:\n",
    "                result.append((emoji, text))\n",
    "                \n",
    "    dct['parsed_activities'] = result\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc5d7658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id_list': [724, 723, 722, 721],\n",
       "  'edit_date': '2023-07-27 07:17:32',\n",
       "  'text': '26.07.23\\n\\nHiking with Ann\\n\\nWorking on my project\\n\\n* Gym \\n\\n* Interesting history lecture \\n\\nHow productive have you been?: 4.5/10\\nHow interesting was the day?: 6/10\\nHow stressful was the day?: 1/10',\n",
       "  'post_id': 721,\n",
       "  'upload_date': '2023-07-26 16:28:42'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_posts(num_posts = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "334bfee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_list': [717, 716, 715],\n",
       " 'edit_date': '2023-07-26 16:02:48',\n",
       " 'text': '24.07.23\\n\\nGym: good traning \\n\\nMy project for portfolio: do some things  \\n\\nInteresting history lecture  \\n\\nHow productive have you been?: 4.5/10\\nHow interesting was the day?: 5/10\\nHow stressful was the day?: 0/10',\n",
       " 'post_id': 715,\n",
       " 'upload_date': '2023-07-26 13:31:56',\n",
       " 'parsed_date': '23-07-24',\n",
       " 'productivity_score': 4.5,\n",
       " 'interest_score': 5.0,\n",
       " 'stress_score': 0.0,\n",
       " 'parsed_text': ['',\n",
       "  '',\n",
       "  'Gym: good traning ',\n",
       "  '',\n",
       "  'My project for portfolio: do some things  ',\n",
       "  '',\n",
       "  'Interesting history lecture  ',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_text(get_posts(num_posts = 4)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21a573b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_list': [724, 723, 722, 721],\n",
       " 'edit_date': '2023-07-27 20:00:47',\n",
       " 'text': '26.07.23\\n\\n🙈👌🙋\\u200d♀️🖐 Hiking with Ann\\n\\nWorking on my project\\n\\n* Gym \\n\\n* Interesting history lecture \\n\\nHow productive have you been?: 4.5/10\\nHow interesting was the day?: 6/10\\nHow stressful was the day?: 1/10',\n",
       " 'post_id': 721,\n",
       " 'upload_date': '2023-07-26 16:28:42',\n",
       " 'parsed_date': '23-07-26',\n",
       " 'productivity_score': 4.5,\n",
       " 'interest_score': 6.0,\n",
       " 'stress_score': 1.0,\n",
       " 'parsed_text': ['',\n",
       "  '',\n",
       "  '🙈👌🙋\\u200d♀️🖐 Hiking with Ann',\n",
       "  '',\n",
       "  'Working on my project',\n",
       "  '',\n",
       "  '* Gym ',\n",
       "  '',\n",
       "  '* Interesting history lecture ',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  ''],\n",
       " 'parsed_activities': [('🙈👌🙋', '\\u200d♀️🖐 Hiking with Ann'),\n",
       "  (None, 'Working on my project'),\n",
       "  ('*', 'Gym'),\n",
       "  ('*', 'Interesting history lecture')]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_activities(parse_text(get_posts(num_posts = 3)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571d92d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b100d9",
   "metadata": {},
   "source": [
    "# Upload to DB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c0bb8c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "from getpass import getpass\n",
    "from mysql.connector import connect, Error\n",
    "\n",
    "\n",
    "def db_connect():\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            create_posts_table_query = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS posts(\n",
    "                post_id INT,\n",
    "                text TEXT,\n",
    "                parsed_date DATE,\n",
    "                upload_date DATETIME,\n",
    "                edit_date DATETIME, \n",
    "                productivity_score FLOAT,\n",
    "                interest_score FLOAT,\n",
    "                stress_score FLOAT,\n",
    "                predicted_productivity_score FLOAT,\n",
    "                predicted_interest_score FLOAT,\n",
    "                predicted_stress_score FLOAT,\n",
    "                PRIMARY KEY (post_id)\n",
    "            );\n",
    "            \"\"\"\n",
    "            \n",
    "            create_posts_table_activities = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS activities(\n",
    "                activity_id INT AUTO_INCREMENT,\n",
    "                post_id INT,\n",
    "                activity_name TEXT,\n",
    "                activity_emoji TEXT,\n",
    "                activity_type TEXT,\n",
    "                activity_emotion TEXT,\n",
    "                predicted_activity_type TEXT,\n",
    "                predicted_activity_emotion TEXT,\n",
    "                FOREIGN KEY (post_id) REFERENCES posts(post_id),\n",
    "                PRIMARY KEY (activity_id)\n",
    "            );\n",
    "            \"\"\"\n",
    "            \n",
    "            \n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(create_posts_table_query)\n",
    "                cursor.execute(create_posts_table_activities)\n",
    "                connection.commit()\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "def upload_post(dct):\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            check_if_exist = \"\"\"SELECT EXISTS(SELECT 1 FROM posts WHERE post_id = %s LIMIT 1)\"\"\"\n",
    "            \n",
    "            upload_posts_table_query = f\"\"\"\n",
    "            INSERT INTO posts (post_id, text, parsed_date, upload_date, \n",
    "            edit_date,productivity_score, interest_score, stress_score, \n",
    "            predicted_productivity_score, predicted_interest_score,\n",
    "            predicted_stress_score) \n",
    "            VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "            \n",
    "            post_id = (dct.get('post_id', None),)\n",
    "            uploaded_date = dct.get('upload_date', None)\n",
    "            \n",
    "            insert_data = (dct.get('post_id', None), dct.get('text', None), \n",
    "                    dct.get('parsed_date', None), dct.get('upload_date', None), \n",
    "                    dct.get('edit_date', None),dct.get('productivity_score', None),\n",
    "                    dct.get('interest_score', None),dct.get('stress_score', None),\n",
    "                    dct.get('predicted_productivity_score', None), dct.get('predicted_interest_score', None),\n",
    "                    dct.get('predicted_stress_score', None))\n",
    "            \n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(check_if_exist, post_id)\n",
    "                for el in cursor:\n",
    "                    exist = el[0]\n",
    "                \n",
    "                if not exist:\n",
    "                    cursor.execute(upload_posts_table_query, insert_data)\n",
    "                    connection.commit()\n",
    "                    print(f'post with id:{post_id} and uploaded_date:{uploaded_date} were uploaded')\n",
    "                else:\n",
    "                    print(f'ERROR: post with id:{post_id} and uploaded_date:{uploaded_date} already uploaded')\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "        \n",
    "def upload_activities(dct):\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            \n",
    "            for activity_emoji, activity_name in dct['parsed_activities']:\n",
    "                \n",
    "                activity_name = \"\".join(c for c in activity_name if c.isalpha() or c.isnumeric() or c == ' ' or c == '!').strip(' ')\n",
    "                check_if_exist = \"\"\"SELECT EXISTS(SELECT 1 FROM activities WHERE post_id = %s AND activity_name = %s LIMIT 1)\"\"\"\n",
    "\n",
    "                upload_posts_table_query = f\"\"\"\n",
    "                INSERT INTO activities (post_id, activity_name, activity_emoji, activity_type, \n",
    "                activity_emotion, predicted_activity_type, predicted_activity_emotion) \n",
    "                VALUES(%s, %s, %s, %s, %s, %s, %s)\n",
    "                \"\"\"\n",
    "                post_id = dct.get('post_id', None)\n",
    "                \n",
    "                check_data = (post_id, activity_name)\n",
    "\n",
    "                insert_data = (dct.get('post_id', None), activity_name, \n",
    "                              activity_emoji, dct.get('activity_type', None), dct.get('activity_emotion', None),\n",
    "                              dct.get('predicted_activity_type', None), dct.get('predicted_activity_emotion', None))\n",
    "            \n",
    "                with connection.cursor() as cursor:\n",
    "                    cursor.execute(use_db_query)\n",
    "                    cursor.execute(check_if_exist, check_data)\n",
    "                    for el in cursor:\n",
    "                        exist = el[0]\n",
    "\n",
    "                    if not exist:\n",
    "                        cursor.execute(upload_posts_table_query, insert_data)\n",
    "                        connection.commit()\n",
    "                    else:\n",
    "                        # add overwrite option\n",
    "                        print(f'ERROR: activity with post_id:{post_id} and activity_name:{activity_name} already uploaded')\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "        \n",
    "def update_post(dct):\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            update_posts_table_query = \"\"\"\n",
    "            UPDATE posts SET text = %s, parsed_date = %s,  \n",
    "            upload_date = %s, edit_date = %s, productivity_score = %s,\n",
    "            interest_score = %s, stress_score = %s WHERE post_id = %s\n",
    "            \"\"\"\n",
    "            \n",
    "            data = (dct.get('text', None), \n",
    "                    dct.get('parsed_date', None), dct.get('upload_date', None), \n",
    "                    dct.get('edit_date', None),dct.get('productivity_score', None),\n",
    "                    dct.get('interest_score', None),dct.get('stress_score', None),\n",
    "                   dct.get('post_id', None))\n",
    "\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(update_posts_table_query, data)\n",
    "                connection.commit()\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "def db_show_tables():\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            show_tables = \"SHOW TABLES;\"\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(show_tables)\n",
    "                for el in cursor.fetchall():\n",
    "                    print(el)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "def db_execute_query(query, commit = False):\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(query)\n",
    "                if commit:\n",
    "                    connection.commit()\n",
    "                for el in cursor:\n",
    "                    print(el)\n",
    "    except Error as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cbf26c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5fa8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97dd7e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('activities',)\n",
      "('posts',)\n"
     ]
    }
   ],
   "source": [
    "db_show_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c459b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "db_execute_query('SELECT EXISTS(SELECT * FROM posts WHERE post_id = 9 LIMIT 1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73c60bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_execute_query('DELETE FROM posts WHERE post_id > 0;', commit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "60431726",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_execute_query('SELECT * FROM posts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5bd72943",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_execute_query('SELECT * FROM activities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3f502404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2026"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "datetime.date(2026, 7, 23).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4222329b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3552fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dcd58a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7679a5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2584f335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9e4b065",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6367818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_post(post):\n",
    "    \n",
    "    date = post.get('upload_date', None)\n",
    "    text = post.get('text', None)\n",
    "    \n",
    "    if post.get('parsed_date', None) is None:\n",
    "        print(f'I dont see date, can you add it to post uploaded at {date} with text:{text}?')\n",
    "        return False\n",
    "\n",
    "    if post.get('productivity_score', None) is None:\n",
    "        print(f'I dont see productivity_score, can you add it to post uploaded at {date} with text: {text}?')\n",
    "        return False\n",
    "        \n",
    "    if post.get('interest_score', None) is None:\n",
    "        print(f'I dont see interest_score, can you add it to post uploaded at {date} with text: {text}?')\n",
    "        return False\n",
    "        \n",
    "    if post.get('productivity_score', None) is None:\n",
    "        print(f'I dont see productivity_score, can you add it to post uploaded at {date} with text: {text}?')\n",
    "        return False\n",
    "        \n",
    "    if post.get('stress_score', None) is None:\n",
    "        print(f'I dont see stress_score, can you add it to postuploaded at {date} with text: {text}?')\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def check_activities(post):\n",
    "    \n",
    "    date = post.get('upload_date', None)\n",
    "    \n",
    "    \n",
    "    if post.get('parsed_activities', None) is None or len(post.get('parsed_activities', None)) < 0:\n",
    "        print(f'I dont see activities, can you add some to post uploaded at {date}?')\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f413a82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id_list': [724, 723, 722, 721],\n",
       "  'edit_date': '2023-07-27 07:17:32',\n",
       "  'text': '26.07.23\\n\\nHiking with Ann\\n\\nWorking on my project\\n\\n* Gym \\n\\n* Interesting history lecture \\n\\nHow productive have you been?: 4.5/10\\nHow interesting was the day?: 6/10\\nHow stressful was the day?: 1/10',\n",
       "  'post_id': 721,\n",
       "  'upload_date': '2023-07-26 16:28:42'},\n",
       " {'id_list': [720, 719, 718],\n",
       "  'edit_date': '2023-07-26 16:02:57',\n",
       "  'text': '25.07.23\\n\\nAwesome cycling with Anna and her brother \\n\\nLazy work on my project\\n\\nInteresting mathematics lecture before sleep\\n\\nHow productive have you been?: 3.5/10\\nHow interesting was the day?: 6/10\\nHow stressful was the day?: 2/10',\n",
       "  'post_id': 718,\n",
       "  'upload_date': '2023-07-26 13:32:45'},\n",
       " {'id_list': [717, 716, 715],\n",
       "  'edit_date': '2023-07-26 16:02:48',\n",
       "  'text': '24.07.23\\n\\nGym: good traning \\n\\nMy project for portfolio: do some things  \\n\\nInteresting history lecture  \\n\\nHow productive have you been?: 4.5/10\\nHow interesting was the day?: 5/10\\nHow stressful was the day?: 0/10',\n",
       "  'post_id': 715,\n",
       "  'upload_date': '2023-07-26 13:31:56'},\n",
       " {'id_list': [714, 713, 712],\n",
       "  'edit_date': '2023-07-26 16:04:37',\n",
       "  'text': '23.07.23\\n\\nMoving to new flat  \\n\\nWorking on my project\\n\\nHow productive have you been?: 5/10\\nHow interesting was the day?: 5/10\\nHow stressful was the day?: 2/10',\n",
       "  'post_id': 712,\n",
       "  'upload_date': '2023-07-26 13:29:37'},\n",
       " {'id_list': [711, 710, 709],\n",
       "  'edit_date': '2023-07-26 16:04:59',\n",
       "  'text': '22.07.23\\n\\nWork on my project\\n\\nLazy day \\n\\nHow productive have you been?: 5/10\\nHow interesting was the day?: 3/10\\nHow stressful was the day?: 0/10',\n",
       "  'post_id': 709,\n",
       "  'upload_date': '2023-07-26 13:28:22'},\n",
       " {'id_list': [707, 706, 705],\n",
       "  'edit_date': '2023-07-26 16:05:34',\n",
       "  'text': '21.07.23\\n\\nWorking on my project\\n\\nCooking \\n\\nEvening with Anna family \\n\\nHow productive have you been?: 4/10\\nHow interesting was the day?: 6/10\\nHow stressful was the day?: 0/10',\n",
       "  'post_id': 705,\n",
       "  'upload_date': '2023-07-26 11:10:37'},\n",
       " {'id_list': [704, 703, 702],\n",
       "  'edit_date': '2023-07-26 13:35:01',\n",
       "  'text': '20.07.23\\n\\nMy project\\n\\nHousehold stuff\\n\\nMovies time: spider man awesome cartoon!\\n\\nHow productive have you been?: 5/10\\nHow interesting was the day?: 6/10\\nHow stressful was the day?: 0/10',\n",
       "  'post_id': 702,\n",
       "  'upload_date': '2023-07-26 11:07:52'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_posts(num_posts = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bec1f881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: post with id:(721,) and uploaded_date:2023-07-26 16:28:42 already uploaded\n",
      "ERROR: activity with post_id:721 and activity_name:Hiking with Ann already uploaded\n",
      "ERROR: activity with post_id:721 and activity_name:Working on my project already uploaded\n",
      "ERROR: activity with post_id:721 and activity_name:Gym already uploaded\n",
      "ERROR: activity with post_id:721 and activity_name:Interesting history lecture already uploaded\n",
      "ERROR: post with id:(718,) and uploaded_date:2023-07-26 13:32:45 already uploaded\n",
      "ERROR: activity with post_id:718 and activity_name:Awesome cycling with Anna and her brother already uploaded\n",
      "ERROR: activity with post_id:718 and activity_name:Lazy work on my project already uploaded\n",
      "ERROR: activity with post_id:718 and activity_name:Interesting mathematics lecture before sleep already uploaded\n",
      "ERROR: post with id:(715,) and uploaded_date:2023-07-26 13:31:56 already uploaded\n",
      "ERROR: activity with post_id:715 and activity_name:Gym good traning already uploaded\n",
      "ERROR: activity with post_id:715 and activity_name:My project for portfolio do some things already uploaded\n",
      "ERROR: activity with post_id:715 and activity_name:Interesting history lecture already uploaded\n",
      "ERROR: post with id:(712,) and uploaded_date:2023-07-26 13:29:37 already uploaded\n",
      "ERROR: activity with post_id:712 and activity_name:Moving to new flat already uploaded\n",
      "ERROR: activity with post_id:712 and activity_name:Working on my project already uploaded\n",
      "ERROR: post with id:(709,) and uploaded_date:2023-07-26 13:28:22 already uploaded\n",
      "ERROR: activity with post_id:709 and activity_name:Work on my project already uploaded\n",
      "ERROR: activity with post_id:709 and activity_name:Lazy day already uploaded\n",
      "ERROR: post with id:(705,) and uploaded_date:2023-07-26 11:10:37 already uploaded\n",
      "ERROR: activity with post_id:705 and activity_name:Working on my project already uploaded\n",
      "ERROR: activity with post_id:705 and activity_name:Cooking already uploaded\n",
      "ERROR: activity with post_id:705 and activity_name:Evening with Anna family already uploaded\n",
      "ERROR: post with id:(702,) and uploaded_date:2023-07-26 11:07:52 already uploaded\n",
      "ERROR: activity with post_id:702 and activity_name:My project already uploaded\n",
      "ERROR: activity with post_id:702 and activity_name:Household stuff already uploaded\n",
      "ERROR: activity with post_id:702 and activity_name:Movies time spider man awesome cartoon already uploaded\n",
      "ERROR: post with id:(675,) and uploaded_date:2023-07-20 09:51:07 already uploaded\n",
      "ERROR: activity with post_id:675 and activity_name:Tinkoff final presentation already uploaded\n",
      "ERROR: activity with post_id:675 and activity_name:Little walk in park already uploaded\n",
      "ERROR: activity with post_id:675 and activity_name:Pizza with Anna already uploaded\n",
      "ERROR: activity with post_id:675 and activity_name:Gym already uploaded\n",
      "ERROR: activity with post_id:675 and activity_name:Movie time black mirror already uploaded\n",
      "ERROR: post with id:(671,) and uploaded_date:2023-07-20 09:44:49 already uploaded\n",
      "ERROR: activity with post_id:671 and activity_name:Tinkoff work make presentation  make a report already uploaded\n",
      "ERROR: activity with post_id:671 and activity_name:Gym already uploaded\n",
      "ERROR: activity with post_id:671 and activity_name:My project already uploaded\n",
      "ERROR: activity with post_id:671 and activity_name:Tinkoff meeting already uploaded\n",
      "ERROR: post with id:(663,) and uploaded_date:2023-07-20 09:42:14 already uploaded\n",
      "ERROR: activity with post_id:663 and activity_name:Quick things packing and household chores already uploaded\n",
      "ERROR: activity with post_id:663 and activity_name:Train trip to St Petersburg already uploaded\n",
      "ERROR: activity with post_id:663 and activity_name:Interesting lecture that make me think about myself stupid already uploaded\n",
      "ERROR: activity with post_id:663 and activity_name:Evening with Ann already uploaded\n",
      "ERROR: post with id:(659,) and uploaded_date:2023-07-20 09:40:42 already uploaded\n",
      "ERROR: activity with post_id:659 and activity_name:Coffee and Hiking with Nikita already uploaded\n",
      "ERROR: activity with post_id:659 and activity_name:Random coffee cool hiking in big park for bicycle already uploaded\n",
      "ERROR: post with id:(656,) and uploaded_date:2023-07-20 09:38:50 already uploaded\n",
      "ERROR: activity with post_id:656 and activity_name:Send avito order already uploaded\n",
      "ERROR: activity with post_id:656 and activity_name:Check tickets and write second letter already uploaded\n",
      "ERROR: activity with post_id:656 and activity_name:Presentation preperation already uploaded\n",
      "ERROR: post with id:(650,) and uploaded_date:2023-07-15 10:41:36 already uploaded\n",
      "ERROR: activity with post_id:650 and activity_name:Tinkoff prepresentation already uploaded\n",
      "ERROR: activity with post_id:650 and activity_name:My project read some articles and search models already uploaded\n",
      "ERROR: activity with post_id:650 and activity_name:Lazy day Phone gaming already uploaded\n",
      "ERROR: activity with post_id:650 and activity_name:Scooter repairing already uploaded\n",
      "ERROR: activity with post_id:650 and activity_name:Trying to sell scooter on avito already uploaded\n",
      "ERROR: activity with post_id:650 and activity_name:Late sleep already uploaded\n",
      "ERROR: post with id:(647,) and uploaded_date:2023-07-15 10:37:07 already uploaded\n",
      "ERROR: activity with post_id:647 and activity_name:Gym already uploaded\n",
      "ERROR: activity with post_id:647 and activity_name:Cycling in rainy day already uploaded\n",
      "ERROR: activity with post_id:647 and activity_name:English speaking lesson already uploaded\n",
      "ERROR: activity with post_id:647 and activity_name:Make presentation for Tinkoff already uploaded\n",
      "ERROR: activity with post_id:647 and activity_name:Late sleep already uploaded\n",
      "ERROR: activity with post_id:647 and activity_name:Avito selling back corrector already uploaded\n",
      "ERROR: post with id:(646,) and uploaded_date:2023-07-15 10:34:50 already uploaded\n",
      "ERROR: activity with post_id:646 and activity_name:Home cleaning already uploaded\n",
      "ERROR: activity with post_id:646 and activity_name:Mentor meeting already uploaded\n",
      "ERROR: activity with post_id:646 and activity_name:My project already uploaded\n",
      "ERROR: activity with post_id:646 and activity_name:English series already uploaded\n",
      "ERROR: post with id:(641,) and uploaded_date:2023-07-15 10:33:11 already uploaded\n",
      "ERROR: activity with post_id:641 and activity_name:Gym already uploaded\n",
      "ERROR: activity with post_id:641 and activity_name:Cleaning already uploaded\n",
      "ERROR: activity with post_id:641 and activity_name:My project already uploaded\n",
      "ERROR: activity with post_id:641 and activity_name:English practice already uploaded\n",
      "ERROR: post with id:(632,) and uploaded_date:2023-07-11 15:09:19 already uploaded\n",
      "ERROR: activity with post_id:632 and activity_name:Meeting tinkoff already uploaded\n",
      "ERROR: activity with post_id:632 and activity_name:Work already uploaded\n",
      "ERROR: activity with post_id:632 and activity_name:Discord with Anna already uploaded\n",
      "ERROR: activity with post_id:632 and activity_name:Discord with mother already uploaded\n",
      "ERROR: activity with post_id:632 and activity_name:Cooking already uploaded\n",
      "ERROR: post with id:(628,) and uploaded_date:2023-07-11 15:06:02 already uploaded\n",
      "ERROR: activity with post_id:628 and activity_name:Awesome hiking already uploaded\n",
      "ERROR: activity with post_id:628 and activity_name:Interesting discussion with Foma already uploaded\n",
      "ERROR: activity with post_id:628 and activity_name:Delivery of camping equipment with Diana already uploaded\n",
      "ERROR: activity with post_id:628 and activity_name:Rest after hiking already uploaded\n",
      "ERROR: post with id:(624,) and uploaded_date:2023-07-11 15:05:17 already uploaded\n",
      "ERROR: activity with post_id:624 and activity_name:Awesome big hiking already uploaded\n",
      "ERROR: activity with post_id:624 and activity_name:Put up a tent already uploaded\n",
      "ERROR: activity with post_id:624 and activity_name:Cooking on gase grill already uploaded\n",
      "ERROR: activity with post_id:624 and activity_name:Drink vodka with Nikita already uploaded\n",
      "ERROR: activity with post_id:624 and activity_name:Interesting discussion with Foma already uploaded\n",
      "ERROR: activity with post_id:624 and activity_name:Helping people already uploaded\n",
      "ERROR: post with id:(620,) and uploaded_date:2023-07-11 15:01:47 already uploaded\n",
      "ERROR: activity with post_id:620 and activity_name:Preparation for trip already uploaded\n",
      "ERROR: activity with post_id:620 and activity_name:Evening cycling to grocery already uploaded\n",
      "ERROR: activity with post_id:620 and activity_name:Make presentation for tinkoff already uploaded\n",
      "ERROR: post with id:(616,) and uploaded_date:2023-07-11 14:59:21 already uploaded\n",
      "ERROR: activity with post_id:616 and activity_name:Tinkoff work make presentation already uploaded\n",
      "ERROR: activity with post_id:616 and activity_name:Random coffee awesome hiking already uploaded\n",
      "ERROR: post with id:(612,) and uploaded_date:2023-07-11 14:06:26 already uploaded\n",
      "ERROR: activity with post_id:612 and activity_name:Awesome english speaking practice where we discuss ai technologies and their impact on our life already uploaded\n",
      "ERROR: activity with post_id:612 and activity_name:English speaking with chat bot already uploaded\n",
      "ERROR: activity with post_id:612 and activity_name:Awesome Gym traning in new gym already uploaded\n",
      "ERROR: activity with post_id:612 and activity_name:Late sleep already uploaded\n",
      "ERROR: post with id:(604,) and uploaded_date:2023-07-04 22:10:47 already uploaded\n",
      "ERROR: activity with post_id:604 and activity_name:Laaazy day already uploaded\n",
      "ERROR: activity with post_id:604 and activity_name:TikTok already uploaded\n",
      "ERROR: activity with post_id:604 and activity_name:Playing mobile games already uploaded\n",
      "ERROR: activity with post_id:604 and activity_name:Stupid work already uploaded\n",
      "ERROR: activity with post_id:604 and activity_name:Random coffee already uploaded\n",
      "ERROR: activity with post_id:604 and activity_name:Sell victorinox knife already uploaded\n",
      "ERROR: post with id:(600,) and uploaded_date:2023-07-04 22:08:50 already uploaded\n",
      "ERROR: activity with post_id:600 and activity_name:Chilling already uploaded\n",
      "ERROR: activity with post_id:600 and activity_name:Cooking already uploaded\n",
      "ERROR: activity with post_id:600 and activity_name:Lazy day already uploaded\n",
      "ERROR: activity with post_id:600 and activity_name:Nonexisting ozon pickpoint already uploaded\n",
      "ERROR: post with id:(596,) and uploaded_date:2023-07-04 22:06:43 already uploaded\n",
      "ERROR: activity with post_id:596 and activity_name:Awesome hiking already uploaded\n",
      "ERROR: activity with post_id:596 and activity_name:Random coffee already uploaded\n",
      "ERROR: post with id:(591,) and uploaded_date:2023-07-04 14:46:06 already uploaded\n",
      "ERROR: activity with post_id:591 and activity_name:Passed lab works already uploaded\n",
      "ERROR: activity with post_id:591 and activity_name:Spray myself with a paper already uploaded\n",
      "ERROR: activity with post_id:591 and activity_name:Awesome but traumatic box training already uploaded\n",
      "ERROR: activity with post_id:591 and activity_name:Walk Ann to a train already uploaded\n",
      "ERROR: post with id:(588,) and uploaded_date:2023-07-04 14:44:09 already uploaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: activity with post_id:588 and activity_name:Eat already uploaded\n",
      "ERROR: activity with post_id:588 and activity_name:Relax already uploaded\n",
      "ERROR: activity with post_id:588 and activity_name:Some work already uploaded\n",
      "ERROR: post with id:(584,) and uploaded_date:2023-06-29 22:09:01 already uploaded\n",
      "ERROR: activity with post_id:584 and activity_name:Awesome bike trip already uploaded\n",
      "ERROR: activity with post_id:584 and activity_name:Warm bath already uploaded\n",
      "ERROR: activity with post_id:584 and activity_name:Lecture about burnout already uploaded\n",
      "ERROR: post with id:(580,) and uploaded_date:2023-06-28 15:49:01 already uploaded\n",
      "ERROR: activity with post_id:580 and activity_name:Hiking with Ann already uploaded\n",
      "ERROR: activity with post_id:580 and activity_name:Order tasty food already uploaded\n",
      "ERROR: activity with post_id:580 and activity_name:Watch awesome cartoon with Ann already uploaded\n",
      "ERROR: post with id:(577,) and uploaded_date:2023-06-28 15:47:32 already uploaded\n",
      "ERROR: activity with post_id:577 and activity_name:Terrible Chemistry exam already uploaded\n",
      "ERROR: activity with post_id:577 and activity_name:Bar hookah and interesting discussions with university mates already uploaded\n",
      "ERROR: post with id:(574,) and uploaded_date:2023-06-28 15:46:48 already uploaded\n",
      "ERROR: post with id:(569,) and uploaded_date:2023-06-28 15:45:35 already uploaded\n",
      "ERROR: activity with post_id:569 and activity_name:Morning in Tver already uploaded\n",
      "ERROR: activity with post_id:569 and activity_name:Trip back to Moscow already uploaded\n",
      "ERROR: post with id:(561,) and uploaded_date:2023-06-28 15:43:13 already uploaded\n",
      "ERROR: activity with post_id:561 and activity_name:Nice optics exam already uploaded\n",
      "ERROR: activity with post_id:561 and activity_name:Time with classmates already uploaded\n",
      "ERROR: activity with post_id:561 and activity_name:News Attempted military coup in the country already uploaded\n",
      "ERROR: activity with post_id:561 and activity_name:Forced trip to Tver already uploaded\n",
      "ERROR: post with id:(560,) and uploaded_date:2023-06-28 15:39:11 already uploaded\n",
      "ERROR: activity with post_id:560 and activity_name:Optics preparation for exam already uploaded\n",
      "ERROR: activity with post_id:560 and activity_name:Cooking burgers already uploaded\n",
      "ERROR: activity with post_id:560 and activity_name:Optics send homeworks already uploaded\n",
      "ERROR: post with id:(555,) and uploaded_date:2023-06-28 15:38:05 already uploaded\n",
      "ERROR: activity with post_id:555 and activity_name:Interesting optics lecture already uploaded\n",
      "ERROR: activity with post_id:555 and activity_name:Cozy time in university room already uploaded\n",
      "ERROR: activity with post_id:555 and activity_name:Tinkoff work already uploaded\n",
      "ERROR: post with id:(552,) and uploaded_date:2023-06-28 15:36:40 already uploaded\n",
      "ERROR: activity with post_id:552 and activity_name:Phone gaming already uploaded\n",
      "ERROR: post with id:(549,) and uploaded_date:2023-06-20 15:08:19 already uploaded\n",
      "ERROR: activity with post_id:549 and activity_name:Tinkoff meeting read article and test assembling methods already uploaded\n",
      "ERROR: activity with post_id:549 and activity_name:Optics send hm already uploaded\n",
      "ERROR: activity with post_id:549 and activity_name:IAD send hm already uploaded\n",
      "ERROR: activity with post_id:549 and activity_name:QM prepare for exam already uploaded\n",
      "ERROR: post with id:(546,) and uploaded_date:2023-06-20 15:03:26 already uploaded\n",
      "I dont see productivity_score, can you add it to post uploaded at 2023-06-18 07:37:43 with text: 18.06.23\n",
      "\n",
      "* Tinkoff meeting \n",
      "\n",
      "* Optics: do hm\n",
      "* Optics: lectures \n",
      "\n",
      "* QM: formulas \n",
      "* QM: send mail  \n",
      "* QM: lecture \n",
      "* QM: prepare notes \n",
      "\n",
      "* Write about math phys control work\n",
      "\n",
      "* Tinkoff generation?\n",
      "\n",
      "* Cartoon!\n",
      "\n",
      "How productive have you been?: */10\n",
      "How interesting was the day?: */10\n",
      "How stressful was the day?: */10?\n",
      "ERROR: post with id:(538,) and uploaded_date:2023-06-17 20:19:47 already uploaded\n",
      "ERROR: post with id:(534,) and uploaded_date:2023-06-17 20:17:09 already uploaded\n",
      "ERROR: post with id:(530,) and uploaded_date:2023-06-16 09:14:34 already uploaded\n",
      "ERROR: post with id:(526,) and uploaded_date:2023-06-15 10:14:49 already uploaded\n",
      "ERROR: post with id:(520,) and uploaded_date:2023-06-13 20:42:49 already uploaded\n",
      "ERROR: post with id:(517,) and uploaded_date:2023-06-12 10:11:00 already uploaded\n",
      "ERROR: activity with post_id:517 and activity_name:Burnout already uploaded\n",
      "ERROR: activity with post_id:517 and activity_name:Make list with things todo when you are really tired already uploaded\n",
      "ERROR: activity with post_id:517 and activity_name:Optics hm already uploaded\n",
      "ERROR: activity with post_id:517 and activity_name:Quantum mechanics hm already uploaded\n",
      "ERROR: activity with post_id:517 and activity_name:Tinkoff generation project already uploaded\n",
      "ERROR: activity with post_id:517 and activity_name:Tinkoff work already uploaded\n",
      "ERROR: post with id:(514,) and uploaded_date:2023-06-11 09:33:45 already uploaded\n",
      "ERROR: activity with post_id:514 and activity_name:Optics finish  lab already uploaded\n",
      "ERROR: activity with post_id:514 and activity_name:Tinkoff work stack selection methods already uploaded\n",
      "ERROR: activity with post_id:514 and activity_name:QM lecture already uploaded\n",
      "ERROR: activity with post_id:514 and activity_name:NLP in practice code baseline already uploaded\n",
      "ERROR: post with id:(510,) and uploaded_date:2023-06-09 21:31:28 already uploaded\n",
      "ERROR: activity with post_id:510 and activity_name:Optics test already uploaded\n",
      "ERROR: activity with post_id:510 and activity_name:Optics lectures already uploaded\n",
      "ERROR: activity with post_id:510 and activity_name:Meeting with mentor already uploaded\n",
      "ERROR: activity with post_id:510 and activity_name:Tinkoff work already uploaded\n",
      "ERROR: activity with post_id:510 and activity_name:NLP in practice already uploaded\n",
      "ERROR: post with id:(506,) and uploaded_date:2023-06-09 09:02:07 already uploaded\n",
      "ERROR: activity with post_id:506 and activity_name:Tinkoff meeting already uploaded\n",
      "ERROR: activity with post_id:506 and activity_name:Optics lectures already uploaded\n",
      "ERROR: activity with post_id:506 and activity_name:Write mentor already uploaded\n",
      "ERROR: activity with post_id:506 and activity_name:Meditation already uploaded\n",
      "ERROR: activity with post_id:506 and activity_name:NlP in practice watch lectures and get info already uploaded\n",
      "ERROR: activity with post_id:506 and activity_name:Optics lab work already uploaded\n",
      "ERROR: activity with post_id:506 and activity_name:My project build site already uploaded\n",
      "I dont see date, can you add it to post uploaded at 2023-06-08 07:59:24 with text:SUMMER PLANS :\n",
      "\n",
      "📚👨🏻‍💻  MATH/ML/PROGRAMMING\n",
      "\n",
      "* Watch math for big data course\n",
      "* Watch differential geometry course\n",
      "\n",
      "* Algorithms course \n",
      "* Finish my projects for resume\n",
      "\n",
      "💼 JOB/PROJECTS:\n",
      "\n",
      "* Finish Tinkoff project \n",
      "* Apply for some jobs\n",
      "\n",
      "🇬🇧 ENGLISH: \n",
      "\n",
      "* Find speaking club and visit in regularly \n",
      "* Listen podcasts \n",
      "* Watch films/videos and take notes during it \n",
      "* 1 week only English language\n",
      "* Practice speaking with chat GPT\n",
      "* Practice english in Discord/Penpals/Slack\n",
      "\n",
      "💪🏻 SPORT:\n",
      "\n",
      "* Go fight club Akhmat \n",
      "* Find gym with spa\n",
      "\n",
      "🏕 JOURNEYS:\n",
      "\n",
      "* Сamping trip with tent\n",
      "* Boat trip\n",
      "* Hike with HSE AMI\n",
      "* Visit Saint-Petersburg\n",
      "* Visit Mozdok??\n",
      "\n",
      "🏖 INTERESTING LEISURE :\n",
      "\n",
      "* Watch lectures about China\n",
      "* Watch movie: No Hard Feelings\n",
      "\n",
      "🪂 NEW EXPERIENCE: \n",
      "\n",
      "1 day without phone/laptops etc\n",
      "\n",
      "💵 MONEY\n",
      "* Watch lectures about investment \n",
      "* Make some investments \n",
      "\n",
      "\n",
      "recipes from TikTok?\n",
      "ERROR: post with id:(500,) and uploaded_date:2023-06-08 06:35:15 already uploaded\n",
      "ERROR: activity with post_id:500 and activity_name:Tinkoff work already uploaded\n",
      "ERROR: activity with post_id:500 and activity_name:OAD Deadline already uploaded\n",
      "ERROR: activity with post_id:500 and activity_name:My project sync data already uploaded\n",
      "ERROR: activity with post_id:500 and activity_name:NLP in practice make baseline already uploaded\n",
      "ERROR: activity with post_id:500 and activity_name:Optics lectures already uploaded\n",
      "ERROR: post with id:(497,) and uploaded_date:2023-06-06 20:46:15 already uploaded\n",
      "ERROR: activity with post_id:497 and activity_name:English podcast already uploaded\n",
      "ERROR: activity with post_id:497 and activity_name:Tinkoff work already uploaded\n",
      "ERROR: activity with post_id:497 and activity_name:Filter datasets and train models already uploaded\n",
      "ERROR: activity with post_id:497 and activity_name:Feature filtering  EDA already uploaded\n",
      "ERROR: activity with post_id:497 and activity_name:Neural network methods already uploaded\n",
      "ERROR: activity with post_id:497 and activity_name:Optics lectures already uploaded\n",
      "ERROR: activity with post_id:497 and activity_name:ODS nlp in practice lectures already uploaded\n",
      "ERROR: activity with post_id:497 and activity_name:My project write django site template already uploaded\n",
      "ERROR: activity with post_id:497 and activity_name:Quantum mechanics lectures already uploaded\n",
      "ERROR: activity with post_id:497 and activity_name:Boxing already uploaded\n",
      "ERROR: post with id:(494,) and uploaded_date:2023-06-06 09:54:11 already uploaded\n",
      "ERROR: activity with post_id:494 and activity_name:Tinkoff work already uploaded\n",
      "ERROR: activity with post_id:494 and activity_name:My project watches video about docker already uploaded\n",
      "ERROR: activity with post_id:494 and activity_name:ODS nlp in practice lectures already uploaded\n",
      "ERROR: activity with post_id:494 and activity_name:Optics lecture already uploaded\n",
      "ERROR: post with id:(491,) and uploaded_date:2023-06-05 17:00:31 already uploaded\n",
      "ERROR: activity with post_id:491 and activity_name:Pick up my passport already uploaded\n",
      "ERROR: activity with post_id:491 and activity_name:Сycling trip to passport already uploaded\n",
      "ERROR: activity with post_id:491 and activity_name:Relax in bath already uploaded\n",
      "ERROR: activity with post_id:491 and activity_name:Tinkoff work already uploaded\n",
      "ERROR: activity with post_id:491 and activity_name:Optics test already uploaded\n",
      "ERROR: activity with post_id:491 and activity_name:Quantum mechanics hm already uploaded\n",
      "ERROR: activity with post_id:491 and activity_name:IAD DEADLINE already uploaded\n",
      "ERROR: activity with post_id:491 and activity_name:NLP lecture already uploaded\n",
      "ERROR: post with id:(488,) and uploaded_date:2023-06-03 17:31:20 already uploaded\n",
      "ERROR: activity with post_id:488 and activity_name:NLP lecture  conspects already uploaded\n",
      "ERROR: activity with post_id:488 and activity_name:Register for summer school already uploaded\n",
      "ERROR: activity with post_id:488 and activity_name:Tinkoff work already uploaded\n",
      "ERROR: activity with post_id:488 and activity_name:OPTICS DEADLINE already uploaded\n",
      "ERROR: activity with post_id:488 and activity_name:IAD DEADLINE already uploaded\n",
      "ERROR: activity with post_id:488 and activity_name:Quantum mechanics lecture already uploaded\n",
      "ERROR: activity with post_id:488 and activity_name:Optics lecture already uploaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: post with id:(485,) and uploaded_date:2023-06-03 06:36:22 already uploaded\n",
      "ERROR: activity with post_id:485 and activity_name:DS exam already uploaded\n",
      "ERROR: activity with post_id:485 and activity_name:Optics lab already uploaded\n",
      "ERROR: activity with post_id:485 and activity_name:Judo competition already uploaded\n",
      "ERROR: activity with post_id:485 and activity_name:Opticsqm lecture already uploaded\n",
      "ERROR: activity with post_id:485 and activity_name:NLP lecture conspects already uploaded\n",
      "ERROR: post with id:(479,) and uploaded_date:2023-06-02 07:49:59 already uploaded\n",
      "ERROR: activity with post_id:479 and activity_name:Tinkoff work variables analysis already uploaded\n",
      "ERROR: activity with post_id:479 and activity_name:Tinkoff meeting already uploaded\n",
      "ERROR: activity with post_id:479 and activity_name:ODS Alfa Bank meetup already uploaded\n",
      "ERROR: post with id:(476,) and uploaded_date:2023-06-01 09:26:04 already uploaded\n",
      "ERROR: activity with post_id:476 and activity_name:Tinkoff work test algorytms woth different parametrs already uploaded\n",
      "ERROR: activity with post_id:476 and activity_name:NLP lecture already uploaded\n",
      "ERROR: activity with post_id:476 and activity_name:Docs for international passport already uploaded\n",
      "ERROR: activity with post_id:476 and activity_name:IAD HM already uploaded\n",
      "ERROR: activity with post_id:476 and activity_name:Optics lectures already uploaded\n",
      "ERROR: post with id:(471,) and uploaded_date:2023-05-30 19:24:36 already uploaded\n",
      "ERROR: activity with post_id:471 and activity_name:IAD HM already uploaded\n",
      "ERROR: activity with post_id:471 and activity_name:Optics end hm already uploaded\n",
      "ERROR: activity with post_id:471 and activity_name:Optics lectures already uploaded\n",
      "ERROR: activity with post_id:471 and activity_name:Tinkoff work already uploaded\n",
      "ERROR: activity with post_id:471 and activity_name:find hyperparametrs for stepwise already uploaded\n",
      "ERROR: activity with post_id:471 and activity_name:write program to find best hyperparametrs fastly already uploaded\n",
      "ERROR: activity with post_id:471 and activity_name:add ideas from boruta to stepwise already uploaded\n",
      "ERROR: activity with post_id:471 and activity_name:Box training already uploaded\n",
      "ERROR: activity with post_id:471 and activity_name:Tinkoff meeting already uploaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "posts = get_posts(num_posts = 50)\n",
    "\n",
    "for post in posts:\n",
    "    post = parse_text(post)\n",
    "    post = parse_activities(post)\n",
    "    if check_post(post):\n",
    "        upload_post(post)\n",
    "        if check_activities(post):\n",
    "            upload_activities(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7935f261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95104aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47b032fc",
   "metadata": {},
   "source": [
    "# Activity classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24b3511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3409be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fbe4254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'box traning',\n",
       " 'labels': ['other',\n",
       "  'self_development',\n",
       "  'relax_&_rest',\n",
       "  'travel_&_adventure',\n",
       "  'work_&_job',\n",
       "  'home_chore',\n",
       "  'sport',\n",
       "  'family',\n",
       "  'university'],\n",
       " 'scores': [0.3176390826702118,\n",
       "  0.18102319538593292,\n",
       "  0.10530360788106918,\n",
       "  0.10282707959413528,\n",
       "  0.10149189084768295,\n",
       "  0.08444009721279144,\n",
       "  0.059940967708826065,\n",
       "  0.03241773694753647,\n",
       "  0.014916374348104]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_to_classify = \"box traning\"\n",
    "candidate_labels = ['self_development', 'university', 'work_&_job', 'relax_&_rest', 'sport', 'family', 'travel_&_adventure', 'home_chore', 'other']\n",
    "facebook_bart_large_mnli(sequence_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8989939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activity_type(activity_name, classifier):\n",
    "    candidate_labels = ['self_development', 'university', 'work_&_job', 'relax_&_rest', 'sport', 'family', 'travel_&_adventure', 'home_chore', 'other']\n",
    "    return classifier(activity_name, candidate_labels)['labels'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c9526a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sport'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_activity_type('boxing traning',facebook_bart_large_mnli)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeb8e56",
   "metadata": {},
   "source": [
    "# Sentiment analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44908445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "bertweet_base_sentiment_analysis = pipeline(\"text-classification\", model=\"/media/tonyalpha/HDD/bertweet-base-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9206b404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEG', 'score': 0.8925472497940063},\n",
       " {'label': 'NEU', 'score': 0.0853690579533577},\n",
       " {'label': 'POS', 'score': 0.022083677351474762}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertweet_base_sentiment_analysis('Sad day', top_k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3452ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96fca69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e870f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dc0f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b0ff2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e448bc5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23032f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d4ec38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ed1fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b3b7d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e049104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df50732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a087ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736a5430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37911588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53875174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148dd395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fb4da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842de21d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0a0854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285cf11e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c3a6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed9b528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a007fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87ffb9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89b445ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf06b60357b449aa3989e5a2d4f2e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e513cdf44054a55b8996fca5b1e574d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/2.04k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b69fcc109e49898727f7e37dcdf8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/6.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b691bfe0e5494e9bf80942152a69c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/196M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a254b4a65604b8aadaaf1f14cb2f1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/650000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c87d9c09e5064d2fa4768a5550e95137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'text': 'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\'s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\\"serving off their orders\\\\\" when they didn\\'t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\'ve eaten at various McDonalds restaurants for over 30 years. I\\'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "dataset[\"train\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49932379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662b4baaf27e4232a0dbe97d4dd52e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd082cccd5ee4d4aab3295c7282ac363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f952412163f44774a4f7dee4156c9c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3455aee3059c46118e65104c4323edb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16cc464ef1694d6bbedf9dfe254adf5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/650000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4142f7dfd54e4f10b957a6236b309a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e1cc54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bc78cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853c8b23f9594586b68fa39fdb65d358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-cdd4dd3d4f8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-cased\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    472\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2448\u001b[0m                         \u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcommit_hash\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2449\u001b[0m                     }\n\u001b[0;32m-> 2450\u001b[0;31m                     \u001b[0mresolved_archive_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcached_file_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2452\u001b[0m                     \u001b[0;31m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    410\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1362\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"downloading %s to %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m             http_get(\n\u001b[0m\u001b[1;32m   1365\u001b[0m                 \u001b[0murl_to_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m                 \u001b[0mtemp_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries, expected_size)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetEffectiveLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOTSET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     )\n\u001b[0;32m--> 541\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_catcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m                 \u001b[0mflush_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;31m# StringIO doesn't like amt=None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f21d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e3e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43185d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdd518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781141df",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339ec3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb193b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb53c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247b00ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0de44945",
   "metadata": {},
   "source": [
    "# Sync with DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8044a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611b0e72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e689d541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2a7498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab3c866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee39819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab374d9a",
   "metadata": {},
   "source": [
    "# Etc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721a59af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
