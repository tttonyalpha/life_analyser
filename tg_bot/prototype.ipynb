{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d729fa18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-21 13:10:36,369 - apscheduler.scheduler - INFO - Scheduler started\n",
      "2023-07-21 13:10:56,730 - telegram.ext.dispatcher - ERROR - No error handlers are registered, logging exception.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tonyalpha/.local/lib/python3.8/site-packages/telegram/ext/dispatcher.py\", line 557, in process_update\n",
      "    handler.handle_update(update, self, check, context)\n",
      "  File \"/home/tonyalpha/.local/lib/python3.8/site-packages/telegram/ext/handler.py\", line 199, in handle_update\n",
      "    return self.callback(update, context)\n",
      "  File \"<ipython-input-1-971e397ffdcf>\", line 22, in send_new_channel_messages\n",
      "    channel_updates = bot.get_chat_updates(channel_id)\n",
      "AttributeError: 'Bot' object has no attribute 'get_chat_updates'\n",
      "2023-07-21 13:11:06,016 - telegram.ext.updater - INFO - Received signal 2 (SIGINT), stopping...\n",
      "2023-07-21 13:11:06,019 - apscheduler.scheduler - INFO - Scheduler has been shut down\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import logging\n",
    "from telegram import Update, Bot\n",
    "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext\n",
    "\n",
    "# Replace 'YOUR_BOT_TOKEN' with the token you got from the BotFather\n",
    "bot = Bot(token=API_TOKEN)\n",
    "updater = Updater(token=API_TOKEN, use_context=True)\n",
    "dispatcher = updater.dispatcher\n",
    "\n",
    "# Enable logging\n",
    "logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                     level=logging.INFO)\n",
    "\n",
    "\n",
    "def send_new_channel_messages(update: Update, context: CallbackContext):\n",
    "    # Replace 'YOUR_CHANNEL_ID' with the ID of the channel from which you want to read messages\n",
    "    channel_id = 'my life'\n",
    "\n",
    "    # Get the list of all updates in the channel\n",
    "    channel_updates = bot.get_chat_updates(channel_id)\n",
    "\n",
    "    # Get the user ID to send messages\n",
    "    user_id = update.message.from_user.id\n",
    "\n",
    "    # Iterate through all the updates and send new messages to the user\n",
    "    for update in channel_updates:\n",
    "        if update.message:\n",
    "            bot.forward_message(chat_id=user_id, from_chat_id=channel_id, message_id=update.message.message_id)\n",
    "\n",
    "\n",
    "def start(update: Update, context: CallbackContext):\n",
    "    user_id = update.message.from_user.id\n",
    "    update.message.reply_text(f\"Hello! I will send you new messages from the channel.\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Add a handler for new messages in the channel\n",
    "    dispatcher.add_handler(MessageHandler(Filters.chat_type.channel, send_new_channel_messages))\n",
    "    # Add a handler for the /start command\n",
    "    dispatcher.add_handler(CommandHandler(\"start\", start))\n",
    "\n",
    "    updater.start_polling()\n",
    "    updater.idle()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc99910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c5ff57fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-192-20c5fbbb96dc>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-192-20c5fbbb96dc>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    a[2]['text'].\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "a[2]['text']."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f002fb5",
   "metadata": {},
   "source": [
    "# Config upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ac44c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import json\n",
    "\n",
    "from telethon import TelegramClient\n",
    "from telethon.errors import SessionPasswordNeededError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c367e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Configs\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "\n",
    "# Setting configuration values\n",
    "api_id = config['Telegram']['api_id']\n",
    "api_hash = config['Telegram']['api_hash']\n",
    "api_token = config['Telegram']['api_token']\n",
    "\n",
    "api_hash = str(api_hash)\n",
    "\n",
    "phone = config['Telegram']['phone']\n",
    "username = config['Telegram']['username']\n",
    "channel_link = config['Telegram']['channel_link'] \n",
    "\n",
    "db_name = config['database']['db_name']\n",
    "db_user = config['database']['db_user']\n",
    "db_password = config['database']['db_password'] \n",
    "db_host = config['database']['db_host'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472c1372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "50dedff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<coroutine object UserMethods.get_me at 0x7f86fd106540>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-258-bc2b6df2013c>:1: RuntimeWarning: coroutine 'UserMethods.is_user_authorized' was never awaited\n",
      "  if not client.is_user_authorized():\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "<ipython-input-258-bc2b6df2013c>:8: RuntimeWarning: coroutine 'UserMethods.get_me' was never awaited\n",
      "  me = client.get_me()\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "if not client.is_user_authorized():\n",
    "    client.send_code_request(phone)\n",
    "    try:\n",
    "        client.sign_in(phone, input('Enter the code: '))\n",
    "    except SessionPasswordNeededError:\n",
    "        client.sign_in(password=input('Password: '))\n",
    "\n",
    "me = client.get_me()\n",
    "print(me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cec9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f4d776c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-adc2bb114a1f>:11: RuntimeWarning: coroutine 'TelegramBaseClient.connect' was never awaited\n",
      "  assert client.connect()\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "<ipython-input-3-adc2bb114a1f>:12: RuntimeWarning: coroutine 'UserMethods.is_user_authorized' was never awaited\n",
      "  if not client.is_user_authorized():\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "chat_id = 'my life'\n",
    "\n",
    "from telethon import TelegramClient\n",
    "from telethon.tl.functions.messages import GetHistoryRequest\n",
    "import telethon.sync\n",
    "\n",
    "client = TelegramClient(None,\n",
    "                    api_id,\n",
    "                    api_hash)\n",
    "\n",
    "assert client.connect()\n",
    "if not client.is_user_authorized():\n",
    "    client.send_code_request(phone_number)\n",
    "    me = client.sign_in(phone_number, input('Enter code: '))\n",
    "\n",
    "channel_username='my life' # your channel\n",
    "channel_entity=client.get_entity(channel_username)\n",
    "posts = client(GetHistoryRequest(\n",
    "    peer=channel_entity,\n",
    "    limit=100,\n",
    "    offset_date=None,\n",
    "    offset_id=0,\n",
    "    max_id=0,\n",
    "    min_id=0,\n",
    "    add_offset=0,\n",
    "    hash=0))\n",
    "# messages stored in `posts.messages`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a15bb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-e72b7ee019a6>:4: RuntimeWarning: coroutine 'AuthMethods._start' was never awaited\n",
      "  client.start()\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "<ipython-input-21-e72b7ee019a6>:6: RuntimeWarning: coroutine 'MessageMethods.get_messages' was never awaited\n",
      "  for message in client.get_messages(channel_username, limit=10):\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'coroutine' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e72b7ee019a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mchannel_username\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'my life'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel_username\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'coroutine' object is not iterable"
     ]
    }
   ],
   "source": [
    "from telethon import TelegramClient, events, sync\n",
    "\n",
    "client = TelegramClient(None, api_id, api_hash)\n",
    "client.start()\n",
    "channel_username = 'my life'\n",
    "for message in client.get_messages(channel_username, limit=10):\n",
    "    print(message.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16e74f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61db9024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from telethon.sync import TelegramClient\n",
    "\n",
    "\n",
    "\n",
    "# We have to manually call \"start\" if we want an explicit bot token\n",
    "bot = TelegramClient('bot', api_id, api_hash).start(bot_token=api_token)\n",
    "\n",
    "# But then we can use the client instance as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "117d0d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from telethon.tl.functions.channels import GetParticipantsRequest\n",
    "from telethon.tl.types import ChannelParticipantsSearch\n",
    "from telethon.tl.types import (\n",
    "PeerChannel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a031c74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter entity(telegram URL or entity id):https://web.telegram.org/k/#-1810810362\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_input_channel = input(\"enter entity(telegram URL or entity id):\")\n",
    "\n",
    "if user_input_channel.isdigit():\n",
    "    entity = PeerChannel(int(user_input_channel))\n",
    "else:\n",
    "    entity = user_input_channel\n",
    "\n",
    "my_channel = client.get_entity(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b57c1315",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'coroutine' object has no attribute 'users'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-260026df92e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mhash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     ))\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparticipants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mall_participants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticipants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'coroutine' object has no attribute 'users'"
     ]
    }
   ],
   "source": [
    "\n",
    "offset = 0\n",
    "limit = 100\n",
    "all_participants = []\n",
    "\n",
    "while True:\n",
    "    participants = client(GetParticipantsRequest(\n",
    "        my_channel, ChannelParticipantsSearch(''), offset, limit,\n",
    "        hash=0\n",
    "    ))\n",
    "    if not participants.users:\n",
    "        break\n",
    "    all_participants.extend(participants.users)\n",
    "    offset += len(participants.users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f75a69a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from telethon.tl.functions.messages import (GetHistoryRequest)\n",
    "from telethon.tl.types import (\n",
    "PeerChannel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f933c6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Offset ID is: 0 ; Total Messages: 0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'coroutine' object has no attribute 'messages'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-3a17a70c97d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mhash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     ))\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'coroutine' object has no attribute 'messages'"
     ]
    }
   ],
   "source": [
    "\n",
    "offset_id = 0\n",
    "limit = 100\n",
    "all_messages = []\n",
    "total_messages = 0\n",
    "total_count_limit = 0\n",
    "\n",
    "while True:\n",
    "    print(\"Current Offset ID is:\", offset_id, \"; Total Messages:\", total_messages)\n",
    "    history = client(GetHistoryRequest(\n",
    "        peer=my_channel,\n",
    "        offset_id=offset_id,\n",
    "        offset_date=None,\n",
    "        add_offset=0,\n",
    "        limit=limit,\n",
    "        max_id=0,\n",
    "        min_id=0,\n",
    "        hash=0\n",
    "    ))\n",
    "    if not history.messages:\n",
    "        break\n",
    "    messages = history.messages\n",
    "    for message in messages:\n",
    "        all_messages.append(message.to_dict())\n",
    "    offset_id = messages[len(messages) - 1].id\n",
    "    total_messages = len(all_messages)\n",
    "    if total_count_limit != 0 and total_messages >= total_count_limit:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c0b3f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-ac3a12e7944d>:8: RuntimeWarning: coroutine 'AuthMethods._start' was never awaited\n",
      "  bot.start(bot_token=api_token)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Future pending cb=[shield.<locals>._outer_done_callback() at /usr/lib/python3.8/asyncio/tasks.py:902]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "from telethon import TelegramClient\n",
    "from telethon.tl import functions, types\n",
    "\n",
    "\n",
    "\n",
    "bot = TelegramClient(None, api_id, api_hash)\n",
    "bot.start(bot_token=api_token)\n",
    "\n",
    "\n",
    "async def main():\n",
    "    channel = await client.get_entity('my life')\n",
    "    messages = await client.get_messages(channel, limit= None) #pass your own args\n",
    "\n",
    "    #then if you want to get all the messages text\n",
    "    for x in messages:\n",
    "        print(x.text) #return message.text\n",
    "\n",
    "        \n",
    "bot.disconnect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "23639e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2023, 7, 20)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.date.today() - datetime.timedelta(days=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3fd02fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cbcbe32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from telethon.tl.types import InputMessagesFilterPhotos\n",
    "from telethon import TelegramClient, events\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os.path\n",
    "\n",
    "def get_posts(num_posts = 1, download_media = False, only_with_media = True, offset_id = 0, posts_list = []):\n",
    "    client = TelegramClient(username, api_id, api_hash)\n",
    "    posts_list = []\n",
    "    async def main(num_posts, download_media, offset_id, posts_list):\n",
    "        \n",
    "        if num_posts < 100:\n",
    "            message_limit = num_posts\n",
    "        else:\n",
    "            message_limit = 100\n",
    "            \n",
    "            \n",
    "        last_post_date = None\n",
    "        post = {}\n",
    "        \n",
    "        await client.start()\n",
    "\n",
    "        try:\n",
    "            entity = await client.get_entity(channel_link)\n",
    "\n",
    "            while True:\n",
    "                messages = await client.get_messages(entity, limit=message_limit, offset_id = offset_id)\n",
    "\n",
    "                for message in messages:\n",
    "                    \n",
    "                    if only_with_media:\n",
    "                        if not message.media:\n",
    "                            continue\n",
    "                    \n",
    "                    if last_post_date == None:\n",
    "                        last_post_date = message.date\n",
    "\n",
    "\n",
    "                    if last_post_date != message.date: \n",
    "                        post['upload_date'] = last_post_date.strftime('%Y-%m-%d %H:%M:%S') if last_post_date else None\n",
    "\n",
    "                        last_post_date = message.date\n",
    "\n",
    "                        posts_list.append(post)\n",
    "                        post = {}\n",
    "\n",
    "\n",
    "                    if len(message.message) > 0:\n",
    "                        post['text'] = post.get('text', '') + message.message \n",
    "                        \n",
    "                        # post_id in messages set will be id of message with text and photo \n",
    "                        post['post_id'] = message.id\n",
    "\n",
    "\n",
    "                    if message.media and download_media:\n",
    "\n",
    "                        photo_id = message.media.photo.id\n",
    "                        filename = f'image_{photo_id}.jpg'\n",
    "                        path = f\"./media/{filename}\"\n",
    "\n",
    "                        # some of this i should drop, but later \n",
    "                        post['photos_id_list'] = post.get('photos_id_list', []) + [photo_id]\n",
    "                        post['photos_names_list'] = post.get('photos_names_list', []) + [filename]\n",
    "\n",
    "                        #if file exist check \n",
    "                        if not os.path.isfile(path) and download_media:\n",
    "                            await client.download_media(message, file=path)\n",
    "\n",
    "                    post['id_list'] = post.get('id_list', []) + [message.id]\n",
    "                    post['edit_date'] = message.edit_date.strftime('%Y-%m-%d %H:%M:%S') if message.edit_date else None\n",
    "\n",
    "\n",
    "                offset_id = messages[len(messages) - 1].id\n",
    "\n",
    "                if len(posts_list) >= num_posts:\n",
    "                    break\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "        await client.disconnect()\n",
    "        \n",
    "        return posts_list\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        client.loop.run_until_complete(main(num_posts, download_media, offset_id, posts_list))\n",
    "        \n",
    "    return posts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d203e69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'asdfsdf',\n",
       "  'post_id': 700,\n",
       "  'id_list': [700],\n",
       "  'edit_date': None,\n",
       "  'upload_date': '2023-07-24 14:39:42'}]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_posts(num_posts = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53e71eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "546060bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'05.04.23\\n\\nüë®\\u200düë®\\u200düë¶\\u200düë¶ ü§¶üèº Did not find team for HSE hackaton\\nüíÅüèº\\u200d‚ôÇÔ∏èüí¨ ODS random coffee with Roman\\nüìö DL: semianr\\n\\nDay rate: 5.5/10'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-1]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db9e941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "a6bb77ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['—á–ø–æ–∫',\n",
       " '',\n",
       " 'How productive have you been?:6.999/10',\n",
       " 'How interesting was the day?: 6/10',\n",
       " 'How stressful was the day?: 2/10']"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " a[0]['text'].split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb45a04",
   "metadata": {},
   "source": [
    "# Data parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec38d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7772233b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b36db03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "\n",
    "\n",
    "def parse_text(dct):\n",
    "    \n",
    "    input_string = dct['text']\n",
    "    print(input_string)\n",
    "    \n",
    "    date_pattern = r'\\d{2}\\.\\d{2}\\.\\d{2}'\n",
    "    day_pattern = r'\\b(?:MONDAY|TUESDAY|WEDNESDAY|THURSDAY|FRIDAY|SATURDAY|SUNDAY)\\b'\n",
    "    \n",
    "    date_match = re.search(date_pattern, input_string)\n",
    "    day_match = re.search(day_pattern, input_string)\n",
    "    \n",
    "    date = date_match.group() if date_match else None\n",
    "    day = day_match.group() if day_match else None\n",
    "    \n",
    "    parsed_date = date.replace('.', '-') if date or day else None\n",
    "    \n",
    "    dct['parsed_date'] = parsed_date\n",
    "    \n",
    "    if date_match:\n",
    "        input_string = input_string.replace(date_match.group(), \"\") if parsed_date is not None else input_string\n",
    "    if day_match:\n",
    "        input_string = input_string.replace(day_match.group(), \"\") if parsed_date is not None else input_string\n",
    "    \n",
    "    regex_list = [r'How productive have you been\\?:\\s*(\\d+\\.?\\d*)/10', r'How interesting was the day\\?:\\s*(\\d+\\.?\\d*)/10', r'How stressful was the day\\?:\\s*(\\d+\\.?\\d*)/10']\n",
    "    names_list = ['productivity_score', 'interest_score', 'stress_score']\n",
    "    \n",
    "    \n",
    "    for regex, name in zip(regex_list, names_list):\n",
    "        match = re.search(regex, input_string)\n",
    "        parsed_score = float(match.group(1)) if match else None\n",
    "        \n",
    "        dct[name] = parsed_score\n",
    "\n",
    "        input_string = input_string.replace(match.group(), \"\") if parsed_score is not None else input_string\n",
    "        \n",
    "    \n",
    "    dct['parsed_text'] = input_string.split('\\n')\n",
    "    \n",
    "    print('Text parsed!')\n",
    "    return dct\n",
    "    \n",
    "def parse_activities(dct):\n",
    "    \n",
    "    input_list = dct['parsed_text']\n",
    "    \n",
    "    result = []\n",
    "    for item in input_list:\n",
    "        match = re.match(r'^([\\U0001F000-\\U0001F9FF]+|[\\U0001FA00-\\U0001FA6F]+)?\\s*(.*)$', item)\n",
    "        if match:\n",
    "            emoji = match.group(1)\n",
    "            text = match.group(2).strip()\n",
    "            if emoji or text:\n",
    "                result.append((emoji, text))\n",
    "                \n",
    "    dct['parsed_activities'] = result\n",
    "    \n",
    "    print('Activities parsed!')\n",
    "    return dct\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a511a457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f90bf6246774a71bd385281a4189dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee097d91c7e432a827986b946ac9187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", return_all_scores=True)\n",
    "classifier(\"I love this!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8929f92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hi!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f1a6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4577dc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea6865b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "54ac99d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.06.23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id_list': [564, 563, 562, 561],\n",
       " 'edit_date': None,\n",
       " 'text': '24.06.23',\n",
       " 'post_id': 561,\n",
       " 'upload_date': '2023-06-28 15:43:13',\n",
       " 'parsed_date': '24-06-23',\n",
       " 'productivity_score': None,\n",
       " 'interest_score': None,\n",
       " 'stress_score': None,\n",
       " 'parsed_text': [''],\n",
       " 'parsed_activities': []}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_activities(parse_text(a[30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "289b0507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_list': [564, 563, 562, 561],\n",
       " 'edit_date': None,\n",
       " 'text': '24.06.23',\n",
       " 'post_id': 561,\n",
       " 'upload_date': '2023-06-28 15:43:13'}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "5721791b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'24.05.23\\n\\n* IAD: control work \\n\\n* My project for resume \\n* My project: life analyze\\n\\n* English speaking club \\n\\n* Optics: think about future....\\n\\nHow productive have you been?: */10\\nHow interesting was the day?: */10\\nHow stressful was the day?: */10\\nPAI: *'"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[79]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6867e125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48a8a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d29031d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0ef040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e31c060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdd07ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a559de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45ba198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce660a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6b033c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077e0bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5304e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "e78c543e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.01.23\n",
      "16.02.23\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0031d1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8099da1",
   "metadata": {},
   "source": [
    "# Upload to DB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3865d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6392a1bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9063bcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to database successfully\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49e71f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5c465cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "cursor.execute(\"SELECT * FROM pg_catalog.pg_tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8956dfb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ce4c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b6c1cd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "from getpass import getpass\n",
    "from mysql.connector import connect, Error\n",
    "\n",
    "\n",
    "def db_connect():\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            create_posts_table_query = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS posts(\n",
    "                post_id INT,\n",
    "                text TEXT,\n",
    "                parsed_date DATE,\n",
    "                upload_date DATETIME,\n",
    "                edit_date DATETIME, \n",
    "                productivity_score FLOAT,\n",
    "                interest_score FLOAT,\n",
    "                stress_score FLOAT,\n",
    "                PRIMARY KEY (post_id)\n",
    "            );\n",
    "            \"\"\"\n",
    "            \n",
    "            create_posts_table_activities = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS activities(\n",
    "                activity_id INT AUTO_INCREMENT,\n",
    "                post_id INT,\n",
    "                activity_name TEXT,\n",
    "                activity_emoji TEXT,\n",
    "                activity_type TEXT,\n",
    "                activity_emotion TEXT,\n",
    "                \n",
    "                FOREIGN KEY (post_id) REFERENCES posts(post_id),\n",
    "                PRIMARY KEY (activity_id)\n",
    "            );\n",
    "            \"\"\"\n",
    "            \n",
    "            \n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(create_posts_table_query)\n",
    "                cursor.execute(create_posts_table_activities)\n",
    "                connection.commit()\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "def upload_post(dct):\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            check_if_exist = \"\"\"SELECT EXISTS(SELECT 1 FROM posts WHERE post_id = %s LIMIT 1)\"\"\"\n",
    "            \n",
    "            upload_posts_table_query = f\"\"\"\n",
    "            INSERT INTO posts (post_id, text, parsed_date, upload_date, \n",
    "            edit_date,productivity_score, interest_score, stress_score) \n",
    "            VALUES(%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "            \n",
    "            post_id = (dct.get('post_id', None),)\n",
    "            \n",
    "            insert_data = (dct.get('post_id', None), dct.get('text', None), \n",
    "                    dct.get('parsed_date', None), dct.get('upload_date', None), \n",
    "                    dct.get('edit_date', None),dct.get('productivity_score', None),\n",
    "                    dct.get('interest_score', None),dct.get('stress_score', None))\n",
    "            \n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(check_if_exist, post_id)\n",
    "                for el in cursor:\n",
    "                    exist = el[0]\n",
    "                \n",
    "                if not exist:\n",
    "                    cursor.execute(upload_posts_table_query, insert_data)\n",
    "                    connection.commit()\n",
    "                else:\n",
    "                    print('ERROR: post already uploaded, if you need update it use update_post()')\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "        \n",
    "def upload_activities(dct):\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            check_if_exist = \"\"\"SELECT EXISTS(SELECT 1 FROM posts WHERE post_id = %s LIMIT 1)\"\"\"\n",
    "            \n",
    "            upload_posts_table_query = f\"\"\"\n",
    "            INSERT INTO posts (post_id, text, parsed_date, upload_date, \n",
    "            edit_date,productivity_score, interest_score, stress_score) \n",
    "            VALUES(%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "            \n",
    "            post_id = (dct.get('post_id', None),)\n",
    "            \n",
    "            insert_data = (dct.get('post_id', None), dct.get('text', None), \n",
    "                    dct.get('parsed_date', None), dct.get('upload_date', None), \n",
    "                    dct.get('edit_date', None),dct.get('productivity_score', None),\n",
    "                    dct.get('interest_score', None),dct.get('stress_score', None))\n",
    "            \n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(check_if_exist, post_id)\n",
    "                for el in cursor:\n",
    "                    exist = el[0]\n",
    "                \n",
    "                if not exist:\n",
    "                    cursor.execute(upload_posts_table_query, insert_data)\n",
    "                    connection.commit()\n",
    "                else:\n",
    "                    print('ERROR: post already uploaded, if you need update it use update_post()')\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "        \n",
    "def update_post(dct):\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            update_posts_table_query = \"\"\"\n",
    "            UPDATE posts SET text = %s, parsed_date = %s,  \n",
    "            upload_date = %s, edit_date = %s, productivity_score = %s,\n",
    "            interest_score = %s, stress_score = %s WHERE post_id = %s\n",
    "            \"\"\"\n",
    "            \n",
    "            data = (dct.get('text', None), \n",
    "                    dct.get('parsed_date', None), dct.get('upload_date', None), \n",
    "                    dct.get('edit_date', None),dct.get('productivity_score', None),\n",
    "                    dct.get('interest_score', None),dct.get('stress_score', None),\n",
    "                   dct.get('post_id', None))\n",
    "\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(update_posts_table_query, data)\n",
    "                connection.commit()\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "def db_show_tables():\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            show_tables = \"SHOW TABLES;\"\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(show_tables)\n",
    "                for el in cursor.fetchall():\n",
    "                    print(el)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "def db_execute_query(query):\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(query)\n",
    "                for el in cursor:\n",
    "                    print(el)\n",
    "    except Error as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bc43e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c47a417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "cc6c6f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('posts',)\n"
     ]
    }
   ],
   "source": [
    "db_show_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "53ab073a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "db_execute_query('SELECT EXISTS(SELECT * FROM posts WHERE post_id = 9 LIMIT 1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3b8df7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_execute_query('SELECT * FROM posts;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a92f97b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4a166a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b29eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24557de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2d238d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ae2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7268282e",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c5d32f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_post(post):\n",
    "    \n",
    "    date = post.get('upload_date', None)\n",
    "    \n",
    "    if post.get('parsed_date', None) is None:\n",
    "        print(f'I dont see date, can you add it to post uploaded at {date}?')\n",
    "        return False\n",
    "\n",
    "    if post.get('productivity_score', None) is None:\n",
    "        print(f'I dont see productivity_score, can you add it to post uploaded at {date}?')\n",
    "        return False\n",
    "        \n",
    "    if post.get('interest_score', None) is None:\n",
    "        print(f'I dont see interest_score, can you add it to post uploaded at {date}?')\n",
    "        return False\n",
    "        \n",
    "    if post.get('productivity_score', None) is None:\n",
    "        print(f'I dont see productivity_score, can you add it to post uploaded at {date}?')\n",
    "        return False\n",
    "        \n",
    "    if post.get('stress_score', None) is None:\n",
    "        print(f'I dont see stress_score, can you add it to postuploaded at {date}?')\n",
    "        return False\n",
    "    print('Post correct!')\n",
    "    return True\n",
    "\n",
    "def check_activities(post):\n",
    "    \n",
    "    date = post.get('upload_date', None)\n",
    "    \n",
    "    if post.get('parsed_activities', None) is None or len(post.get('parsed_activities', None)) < 0:\n",
    "        print(f'I dont see activities, can you add some to post uploaded at {date}?')\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "20ddfc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = get_posts(num_posts = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c230289c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '05.04.23\\nasdfsdf\\n\\nHow productive have you been?: 0/10\\nHow interesting was the day?: 9/10\\nHow stressful was the day?: 0/10',\n",
       "  'post_id': 700,\n",
       "  'id_list': [700],\n",
       "  'edit_date': '2023-07-24 15:57:47',\n",
       "  'upload_date': '2023-07-24 14:39:42'}]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "25ac3e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05.04.23\n",
      "asdfsdf\n",
      "\n",
      "How productive have you been?: 0/10\n",
      "How interesting was the day?: 9/10\n",
      "How stressful was the day?: 0/10\n",
      "Text parsed!\n",
      "Activities parsed!\n",
      "Post correct!\n",
      "ERROR: post already uploaded, if you need update it use update_post()\n",
      "—á–ø–æ–∫\n",
      "\n",
      "How productive have you been?:6.999/10\n",
      "How interesting was the day?: 6/10\n",
      "How stressful was the day?: 2/10\n",
      "Text parsed!\n",
      "Activities parsed!\n",
      "I dont see date, can you add it to post uploaded at 2023-07-23 16:22:13?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "posts = get_posts(num_posts = 2)\n",
    "\n",
    "for post in posts:\n",
    "    post = parse_text(post)\n",
    "    post = parse_activities(post)\n",
    "    if check_post(post):\n",
    "        upload_post(post)\n",
    "    \n",
    "    if check_activities(post):\n",
    "        upload_activities(post)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb8b42f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d70ff64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "857eada4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'neutral', 'score': 0.44008079171180725}]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", top_k=1)\n",
    "classifier(\"hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "749ba1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8116fe6cf8c14fb7b418e266e0fc1074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-db09c37de75e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text-classification\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SamLowe/roberta-base-go_emotions\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hello!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;31m# Will load the correct model if possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0mmodel_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m     framework, model = infer_framework_load_model(\n\u001b[0m\u001b[1;32m    780\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0mmodel_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"eval\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    472\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2448\u001b[0m                         \u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcommit_hash\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2449\u001b[0m                     }\n\u001b[0;32m-> 2450\u001b[0;31m                     \u001b[0mresolved_archive_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcached_file_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2452\u001b[0m                     \u001b[0;31m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    410\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1362\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"downloading %s to %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m             http_get(\n\u001b[0m\u001b[1;32m   1365\u001b[0m                 \u001b[0murl_to_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m                 \u001b[0mtemp_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries, expected_size)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetEffectiveLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOTSET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     )\n\u001b[0;32m--> 541\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_catcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m                 \u001b[0mflush_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;31m# StringIO doesn't like amt=None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", top_k=1)\n",
    "classifier(\"hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e036dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65ecb4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4164372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8969707a",
   "metadata": {},
   "source": [
    "# Sync with DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0234cf42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d68775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7e1945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4632bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6509eaa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4eefe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c966cb3f",
   "metadata": {},
   "source": [
    "# Etc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4202a819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
