{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19b5fcf5",
   "metadata": {},
   "source": [
    "# Bot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcccfdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb20975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "from telegram import Update, Bot\n",
    "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext\n",
    "\n",
    "bot = Bot(token=API_TOKEN)\n",
    "updater = Updater(token=API_TOKEN, use_context=True)\n",
    "dispatcher = updater.dispatcher\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                     level=logging.INFO)\n",
    "\n",
    "\n",
    "def send_new_channel_messages(update: Update, context: CallbackContext):\n",
    "    channel_id = 'my life'\n",
    "    channel_updates = bot.get_chat_updates(channel_id)\n",
    "\n",
    "    user_id = update.message.from_user.id\n",
    "\n",
    "    for update in channel_updates:\n",
    "        if update.message:\n",
    "            bot.forward_message(chat_id=user_id, from_chat_id=channel_id, message_id=update.message.message_id)\n",
    "\n",
    "\n",
    "def start(update: Update, context: CallbackContext):\n",
    "    user_id = update.message.from_user.id\n",
    "    update.message.reply_text(f\"Hello! I will send you new messages from the channel.\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    dispatcher.add_handler(MessageHandler(Filters.chat_type.channel, send_new_channel_messages))\n",
    "    dispatcher.add_handler(CommandHandler(\"start\", start))\n",
    "\n",
    "    updater.start_polling()\n",
    "    updater.idle()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5b175e",
   "metadata": {},
   "source": [
    "# Config upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23b71f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import json\n",
    "\n",
    "from telethon import TelegramClient\n",
    "from telethon.errors import SessionPasswordNeededError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4689bfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Configs\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "\n",
    "# Setting configuration values\n",
    "api_id = config['Telegram']['api_id']\n",
    "api_hash = config['Telegram']['api_hash']\n",
    "api_token = config['Telegram']['api_token']\n",
    "\n",
    "api_hash = str(api_hash)\n",
    "\n",
    "phone = config['Telegram']['phone']\n",
    "username = config['Telegram']['username']\n",
    "channel_link = config['Telegram']['channel_link'] \n",
    "\n",
    "db_name = config['database']['db_name']\n",
    "db_user = config['database']['db_user']\n",
    "db_password = config['database']['db_password'] \n",
    "db_host = config['database']['db_host'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a18a659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da7089c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "#facebook_bart_large_mnli = pipeline(\"zero-shot-classification\", model=\"/media/tonyalpha/HDD/facebook-bart-large-mnli\")\n",
    "#bertweet_base_sentiment_analysis = pipeline(\"text-classification\", model=\"/media/tonyalpha/HDD/bertweet-base-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "002ffb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not client.is_user_authorized():\n",
    "#     client.send_code_request(phone)\n",
    "#     try:\n",
    "#         client.sign_in(phone, input('Enter the code: '))\n",
    "#     except SessionPasswordNeededError:\n",
    "#         client.sign_in(password=input('Password: '))\n",
    "\n",
    "# me = client.get_me()\n",
    "# print(me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0c9a59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d059cfb3",
   "metadata": {},
   "source": [
    "# Get data from telegram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff233508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from telethon.tl.types import InputMessagesFilterPhotos\n",
    "from telethon import TelegramClient, events\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os.path\n",
    "\n",
    "def get_posts(num_posts = 1, download_media = False, only_with_media = True, offset_id = 0, posts_list = []):\n",
    "    client = TelegramClient(username, api_id, api_hash)\n",
    "    posts_list = []\n",
    "    async def main(num_posts, download_media, offset_id, posts_list):\n",
    "        \n",
    "        if num_posts < 100:\n",
    "            message_limit = num_posts\n",
    "        else:\n",
    "            message_limit = 100\n",
    "            \n",
    "            \n",
    "        last_post_date = None\n",
    "        post = {}\n",
    "        \n",
    "        await client.start()\n",
    "\n",
    "        try:\n",
    "            entity = await client.get_entity(channel_link)\n",
    "\n",
    "            while True:\n",
    "                messages = await client.get_messages(entity, limit=message_limit, offset_id = offset_id)\n",
    "\n",
    "                for message in messages:\n",
    "                    \n",
    "                    if only_with_media:\n",
    "                        if not message.media:\n",
    "                            continue\n",
    "                    \n",
    "                    if last_post_date == None:\n",
    "                        last_post_date = message.date\n",
    "\n",
    "                    # if delay between uploading messages is more than 10 second i will separate them\n",
    "                    if (last_post_date - message.date).seconds > 10: \n",
    "                        post['upload_date'] = last_post_date.strftime('%Y-%m-%d %H:%M:%S') if last_post_date else None\n",
    "\n",
    "                        last_post_date = message.date\n",
    "\n",
    "                        posts_list.append(post)\n",
    "                        post = {}\n",
    "\n",
    "\n",
    "                    if len(message.message) > 0:\n",
    "                        post['text'] = post.get('text', '') + message.message \n",
    "                        \n",
    "                        # post_id in messages set will be id of message with text and photo \n",
    "                        post['post_id'] = message.id\n",
    "\n",
    "\n",
    "                    if message.media and download_media:\n",
    "\n",
    "                        photo_id = message.media.photo.id\n",
    "                        filename = f'image_{photo_id}.jpg'\n",
    "                        path = f\"./media/{filename}\"\n",
    "\n",
    "                        # some of this i should drop, but later \n",
    "                        post['photos_id_list'] = post.get('photos_id_list', []) + [photo_id]\n",
    "                        post['photos_names_list'] = post.get('photos_names_list', []) + [filename]\n",
    "\n",
    "                        #if file exist check \n",
    "                        if not os.path.isfile(path) and download_media:\n",
    "                            await client.download_media(message, file=path)\n",
    "\n",
    "                    post['id_list'] = post.get('id_list', []) + [message.id]\n",
    "                    post['edit_date'] = message.edit_date.strftime('%Y-%m-%d %H:%M:%S') if message.edit_date else None\n",
    "\n",
    "\n",
    "                offset_id = messages[len(messages) - 1].id\n",
    "\n",
    "                if len(posts_list) >= num_posts:\n",
    "                    break\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "        await client.disconnect()\n",
    "        \n",
    "        return posts_list\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        client.loop.run_until_complete(main(num_posts, download_media, offset_id, posts_list))\n",
    "        \n",
    "    return posts_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b45136",
   "metadata": {},
   "source": [
    "# Data parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cb8597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee503487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def parse_text(dct):\n",
    "    \n",
    "    input_string = dct.get('text', None)\n",
    "    \n",
    "    if input_string is None:\n",
    "        return dct\n",
    "    \n",
    "    date_pattern = r'\\d{2}\\.\\d{2}\\.\\d{2}'\n",
    "    day_pattern = r'\\b(?:MONDAY|TUESDAY|WEDNESDAY|THURSDAY|FRIDAY|SATURDAY|SUNDAY)\\b'\n",
    "    \n",
    "    date_match = re.search(date_pattern, input_string)\n",
    "    day_match = re.search(day_pattern, input_string)\n",
    "    \n",
    "    date = date_match.group() if date_match else None\n",
    "    day = day_match.group() if day_match else None\n",
    "    \n",
    "    parsed_date = date.split('.')[-1] + '-' + date.split('.')[1] + '-' + date.split('.')[0] if date or day else None\n",
    "    \n",
    "    dct['parsed_date'] = parsed_date\n",
    "    \n",
    "    if date_match:\n",
    "        input_string = input_string.replace(date_match.group(), \"\") if parsed_date is not None else input_string\n",
    "    if day_match:\n",
    "        input_string = input_string.replace(day_match.group(), \"\") if parsed_date is not None else input_string\n",
    "    \n",
    "    regex_list = [r'How productive have you been\\?:\\s*(\\S|\\s+|\\d+\\.?\\d*)/10', r'How interesting was the day\\?:\\s*(\\S|\\s+|\\d+\\.?\\d*)/10', r'How stressful was the day\\?:\\s*(\\S|\\s+|\\d+\\.?\\d*)/10']\n",
    "    names_list = ['productivity_score', 'interest_score', 'stress_score']\n",
    "    \n",
    "    for regex, name in zip(regex_list, names_list):\n",
    "        match = re.search(regex, input_string)\n",
    "        \n",
    "        if match:\n",
    "            try:\n",
    "                parsed_score = float(match.group(1))\n",
    "            except:\n",
    "                parsed_score = None\n",
    "        else:\n",
    "            parsed_score = None\n",
    "        \n",
    "        \n",
    "        #parsed_score = match.group(1) if match and match.group(1).isdigit() else None\n",
    "        \n",
    "        dct[name] = parsed_score\n",
    "\n",
    "        input_string = input_string.replace(match.group(), \"\") if match else input_string\n",
    "        \n",
    "    \n",
    "    dct['parsed_text'] = input_string.split('\\n')\n",
    "    return dct\n",
    "    \n",
    "def parse_activities(dct):\n",
    "    \n",
    "    input_list = dct.get('parsed_text', None)\n",
    "    \n",
    "    if input_list is None:\n",
    "        return dct\n",
    "    \n",
    "    result = []\n",
    "    for item in input_list:\n",
    "        match = re.match(r'^([\\U0001F000-\\U0001F9FF]+|[\\U0001FA00-\\U0001FA6F]+|\\*)?\\s*(.*)$', item)\n",
    "        if match:\n",
    "            emoji = match.group(1)\n",
    "            text = match.group(2).strip()\n",
    "            if emoji or text:\n",
    "                result.append((emoji, text))\n",
    "                \n",
    "    dct['parsed_activities'] = result\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15020b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570c7f16",
   "metadata": {},
   "source": [
    "# Upload to DB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51f6bc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "def update_post(post_id, update_data):\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            \n",
    "            update_post_table_query= ''\n",
    "            update_values = []\n",
    "            \n",
    "            for key, value in update_data.items():\n",
    "                    update_post_table_query += key + ' = %s, '\n",
    "                    update_values += [value]\n",
    "            \n",
    "            update_post_table_query = update_post_table_query.rstrip(', ')\n",
    "            update_post_table_query = 'UPDATE posts SET ' + update_post_table_query + ' WHERE post_id = %s;'\n",
    "            \n",
    "            update_values += [post_id]\n",
    "            update_values = tuple(update_values)\n",
    "            \n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(update_post_table_query, update_values)\n",
    "                connection.commit()\n",
    "                \n",
    "            print(f'UPDATED: post with id:{post_id}')\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "        \n",
    "                \n",
    "def update_activity(activity_id, update_data):\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            \n",
    "            update_activity_table_query= ''\n",
    "            update_values = []\n",
    "            \n",
    "            for key, value in update_data.items():\n",
    "                    update_activity_table_query += key + ' = %s, '\n",
    "                    update_values += [value]\n",
    "            \n",
    "            update_activity_table_query = update_activity_table_query.rstrip(', ')\n",
    "            update_activity_table_query = 'UPDATE activities SET ' + update_activity_table_query + ' WHERE activity_id = %s;'\n",
    "            \n",
    "            update_values += [activity_id]\n",
    "            update_values = tuple(update_values)\n",
    "            \n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(update_activity_table_query, update_values)\n",
    "                connection.commit()\n",
    "                \n",
    "            print(f'UPDATED: activity with id:{activity_id}')\n",
    "    except Error as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b6fd79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "from getpass import getpass\n",
    "from mysql.connector import connect, Error\n",
    "\n",
    "\n",
    "def db_connect():\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            create_posts_table_query = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS posts(\n",
    "                post_id INT,\n",
    "                text TEXT,\n",
    "                parsed_date DATE,\n",
    "                upload_date DATETIME,\n",
    "                edit_date DATETIME, \n",
    "                productivity_score FLOAT,\n",
    "                interest_score FLOAT,\n",
    "                stress_score FLOAT,\n",
    "                predicted_productivity_score FLOAT,\n",
    "                predicted_interest_score FLOAT,\n",
    "                predicted_stress_score FLOAT,\n",
    "                PRIMARY KEY (post_id)\n",
    "            );\n",
    "            \"\"\"\n",
    "            \n",
    "            create_posts_table_activities = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS activities(\n",
    "                activity_id INT AUTO_INCREMENT,\n",
    "                post_id INT,\n",
    "                activity_name TEXT,\n",
    "                activity_emoji TEXT,\n",
    "                activity_type TEXT,\n",
    "                activity_emotion TEXT,\n",
    "                predicted_activity_type TEXT,\n",
    "                predicted_activity_emotion TEXT,\n",
    "                FOREIGN KEY (post_id) REFERENCES posts(post_id),\n",
    "                PRIMARY KEY (activity_id)\n",
    "            );\n",
    "            \"\"\"\n",
    "            \n",
    "            \n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(create_posts_table_query)\n",
    "                cursor.execute(create_posts_table_activities)\n",
    "                connection.commit()\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "def upload_post(dct, overwrite = False):\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            check_if_exist = \"\"\"SELECT EXISTS(SELECT 1 FROM posts WHERE post_id = %s LIMIT 1)\"\"\"\n",
    "            \n",
    "            upload_posts_table_query = f\"\"\"\n",
    "            INSERT INTO posts (post_id, text, parsed_date, upload_date, \n",
    "            edit_date,productivity_score, interest_score, stress_score, \n",
    "            predicted_productivity_score, predicted_interest_score,\n",
    "            predicted_stress_score) \n",
    "            VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "            \n",
    "            post_id = (dct.get('post_id', None),)\n",
    "            uploaded_date = dct.get('upload_date', None)\n",
    "            \n",
    "            insert_data = (dct.get('post_id', None), dct.get('text', None), \n",
    "                    dct.get('parsed_date', None), dct.get('upload_date', None), \n",
    "                    dct.get('edit_date', None),dct.get('productivity_score', None),\n",
    "                    dct.get('interest_score', None),dct.get('stress_score', None),\n",
    "                    dct.get('predicted_productivity_score', None), dct.get('predicted_interest_score', None),\n",
    "                    dct.get('predicted_stress_score', None))\n",
    "            \n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(check_if_exist, post_id)\n",
    "                for el in cursor:\n",
    "                    exist = el[0]\n",
    "                \n",
    "                if not exist:\n",
    "                    cursor.execute(upload_posts_table_query, insert_data)\n",
    "                    connection.commit()\n",
    "                    print(f'UPLOADED: post with id:{post_id} and uploaded_date:{uploaded_date}')\n",
    "                else:\n",
    "                    if overwrite:\n",
    "                        pass\n",
    "                        print('OVERWRITED: post with id:{post_id} and uploaded_date:{uploaded_date}')\n",
    "                    else:\n",
    "                        print(f'ERROR: post with id:{post_id} and uploaded_date:{uploaded_date} already uploaded')\n",
    "                        print('If you want to overwrite data add flag')\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "        \n",
    "def upload_activities(dct, overwrite = False):\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            \n",
    "            for activity_emoji, activity_name in dct['parsed_activities']:\n",
    "                \n",
    "                # add or not? \n",
    "                #if activity_emoji == '*' or activity_emoji == '📦':\n",
    "                #   continue\n",
    "                \n",
    "                activity_name = \"\".join(c for c in activity_name if c.isalpha() or c.isnumeric() or c == ' ' or c == '!').strip(' ')\n",
    "                check_if_exist = \"\"\"SELECT EXISTS(SELECT 1 FROM activities WHERE post_id = %s AND activity_name = %s LIMIT 1)\"\"\"\n",
    "\n",
    "                upload_posts_table_query = f\"\"\"\n",
    "                INSERT INTO activities (post_id, activity_name, activity_emoji, activity_type, \n",
    "                activity_emotion, predicted_activity_type, predicted_activity_emotion) \n",
    "                VALUES(%s, %s, %s, %s, %s, %s, %s)\n",
    "                \"\"\"\n",
    "                post_id = dct.get('post_id', None)\n",
    "                \n",
    "                check_data = (post_id, activity_name)\n",
    "\n",
    "                insert_data = (dct.get('post_id', None), activity_name, \n",
    "                              activity_emoji, dct.get('activity_type', None), dct.get('activity_emotion', None),\n",
    "                              dct.get('predicted_activity_type', None), dct.get('predicted_activity_emotion', None))\n",
    "            \n",
    "                with connection.cursor() as cursor:\n",
    "                    cursor.execute(use_db_query)\n",
    "                    cursor.execute(check_if_exist, check_data)\n",
    "                    for el in cursor:\n",
    "                        exist = el[0]\n",
    "\n",
    "                    if not exist:\n",
    "                        cursor.execute(upload_posts_table_query, insert_data)\n",
    "                        connection.commit()\n",
    "                        print(f'UPLOADED: activity with post_id:{post_id} and activity_name:{activity_name}')\n",
    "                    else:\n",
    "                        # add overwrite option\n",
    "                        print(f'ERROR: activity with post_id:{post_id} and activity_name:{activity_name} already uploaded')\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "        \n",
    "def update_post(dct):\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            update_posts_table_query = \"\"\"\n",
    "            UPDATE posts SET text = %s, parsed_date = %s,  \n",
    "            upload_date = %s, edit_date = %s, productivity_score = %s,\n",
    "            interest_score = %s, stress_score = %s WHERE post_id = %s\n",
    "            \"\"\"\n",
    "            \n",
    "            data = (dct.get('text', None), \n",
    "                    dct.get('parsed_date', None), dct.get('upload_date', None), \n",
    "                    dct.get('edit_date', None),dct.get('productivity_score', None),\n",
    "                    dct.get('interest_score', None),dct.get('stress_score', None),\n",
    "                   dct.get('post_id', None))\n",
    "\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(update_posts_table_query, data)\n",
    "                connection.commit()\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "def db_show_tables():\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            show_tables = \"SHOW TABLES;\"\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(show_tables)\n",
    "                for el in cursor.fetchall():\n",
    "                    print(el)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "def db_execute_query(query, commit = False):\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(query)\n",
    "                if commit:\n",
    "                    connection.commit()\n",
    "                for el in cursor:\n",
    "                    print(el)\n",
    "    except Error as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21197180",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3bb72ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('activities',)\n",
      "('posts',)\n"
     ]
    }
   ],
   "source": [
    "db_show_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f2310ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9,)\n"
     ]
    }
   ],
   "source": [
    "db_execute_query('SELECT activity_id FROM activities WHERE post_id = 721 AND activity_name = \"Hiking with Ann\" LIMIT 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e2dff9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_execute_query('DELETE FROM posts WHERE post_id > 0;', commit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3963fac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_execute_query('DROP TABLE posts;', commit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "774015ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_execute_query('SELECT * FROM activities WHERE post_id = 135')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "48c4ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_execute_query('DELETE FROM posts WHERE post_id = 135', commit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "672af51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATED: activity with id:9\n"
     ]
    }
   ],
   "source": [
    "update_activity(9, {'activity_name': 'Hiking with Ann'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68894743",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_execute_query('SELECT * FROM posts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39184a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(244, 422, 'Write people about specialization', None, 'social_&_friends', None, None, None)\n"
     ]
    }
   ],
   "source": [
    "db_execute_query('SELECT * FROM activities WHERE activity_name LIKE \\'Write people about specialization\\'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d25e417",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_activity(244, {'activity_name': 'Hiking with Ann'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cdfc6d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2026"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "datetime.date(2026, 7, 23).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66671078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28970da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ed6349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d5c24f7",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "273cecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_post(post):\n",
    "    \n",
    "    date = post.get('upload_date', None)\n",
    "    \n",
    "    if post.get('text', None) is None:\n",
    "        print(f'I dont see any text, can you add it to post uploaded at {date}?')\n",
    "        return False\n",
    "    \n",
    "    text = post.get('text', None)\n",
    "    \n",
    "    if post.get('parsed_date', None) is None:\n",
    "        print(f'I dont see date, can you add it to post uploaded at {date} with text:{text}?')\n",
    "        return False\n",
    "\n",
    "    if post.get('productivity_score', None) is None:\n",
    "        print(f'I dont see productivity_score, can you add it to post uploaded at {date} with text: {text}?')\n",
    "        return False\n",
    "        \n",
    "    if post.get('interest_score', None) is None:\n",
    "        print(f'I dont see interest_score, can you add it to post uploaded at {date} with text: {text}?')\n",
    "        return False\n",
    "        \n",
    "    if post.get('productivity_score', None) is None:\n",
    "        print(f'I dont see productivity_score, can you add it to post uploaded at {date} with text: {text}?')\n",
    "        return False\n",
    "        \n",
    "    if post.get('stress_score', None) is None:\n",
    "        print(f'I dont see stress_score, can you add it to post uploaded at {date} with text: {text}?')\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def check_activities(post):\n",
    "    \n",
    "    date = post.get('upload_date', None)\n",
    "    \n",
    "    \n",
    "    if post.get('parsed_activities', None) is None or len(post.get('parsed_activities', None)) < 0:\n",
    "        print(f'I dont see activities, can you add some to post uploaded at {date}?')\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e6b6a13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "posts = get_posts(num_posts = 1000)\n",
    "\n",
    "for post in posts:\n",
    "    post = parse_text(post)\n",
    "    post = parse_activities(post)\n",
    "    if check_post(post):\n",
    "        upload_post(post, overwrite = False)\n",
    "        if check_activities(post):\n",
    "            upload_activities(post, overwrite = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d63990a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg\n"
     ]
    }
   ],
   "source": [
    "print('fg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55997de",
   "metadata": {},
   "source": [
    "# Data markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fb5606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def markup_activities_type(activity_types):\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            \n",
    "            get_activities = '''SELECT * FROM activities WHERE activity_type is NULL'''    \n",
    "            \n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(get_activities)\n",
    "                for el in cursor:\n",
    "                    activity_id = el[0]\n",
    "                    activity_name = el[2]\n",
    "                    print('==============================================================================')\n",
    "                    print(f'ACTIVITY NAME: {activity_name}')\n",
    "                    #print('What type of activity this is?')\n",
    "                    print('\\n'.join([str(i) + ' - ' + activity_types[i-1] for i in range(1, len(activity_types) + 1)]))\n",
    "                    type_num = input('SELECT ACTIVITY TYPE:')\n",
    "                    \n",
    "                    try:\n",
    "                        activity_type = activity_types[int(type_num) - 1]\n",
    "                        update_activity(activity_id, {'activity_type':activity_type})\n",
    "                        clear_output(wait=False)\n",
    "                    except Error as e:\n",
    "                        print(f'ERROR: {e}')\n",
    "\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "        \n",
    "def markup_activities_sentiment(activity_emotions):\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            get_activities = '''SELECT * FROM activities WHERE activity_emotion is NULL'''    \n",
    "            \n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(get_activities)\n",
    "                for el in cursor:\n",
    "                    activity_id = el[0]\n",
    "                    activity_name = el[2]\n",
    "                    print('==============================================================================')\n",
    "                    print(f'ACTIVITY NAME: {activity_name}')\n",
    "                    #print('What type of activity this is?')\n",
    "                    print('\\n'.join([str(i) + ' - ' + activity_emotions[i-1] for i in range(1, len(activity_emotions) + 1)]))\n",
    "                    emotion_num = input('SELECT ACTIVITY SENTIMENT:')\n",
    "                    \n",
    "                    try:\n",
    "                        activity_emotion = activity_emotions[int(emotion_num) - 1]\n",
    "                        update_activity(activity_id, {'activity_emotion':activity_emotion})\n",
    "                        clear_output(wait=False)\n",
    "                    except Error as e:\n",
    "                        print(f'ERROR: {e}')\n",
    "\n",
    "    except Error as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94cd5f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_types = ['self_development', 'university', 'work', 'relax_&_rest', 'chill', 'sport_&_health', 'family', 'social_&_friends', 'travel_&_adventure', 'chore', 'other']\n",
    "encode_activity_type_dict = {activity_types[i]:i for i in range(len(activity_types))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c07923",
   "metadata": {},
   "outputs": [],
   "source": [
    "markup_activities_type(activity_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa4d8121",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_emotions = ['Positive', 'Negative', 'Neutral']\n",
    "encode_emotion_dict = {activity_emotions[i]:i+1 for i in range(len(activity_emotions))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "410ab1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "markup_activities_sentiment(activity_emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77faf0a",
   "metadata": {},
   "source": [
    "# SQL to Pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0acc0e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def sql_to_df(table_name):\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            show_activities = f\"SELECT * FROM {table_name};\"\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                df = pd.read_sql(show_activities, connection)\n",
    "            return df         \n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3748ad29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>activity_name</th>\n",
       "      <th>activity_emoji</th>\n",
       "      <th>activity_type</th>\n",
       "      <th>activity_emotion</th>\n",
       "      <th>predicted_activity_type</th>\n",
       "      <th>predicted_activity_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>721</td>\n",
       "      <td>Hiking with Ann</td>\n",
       "      <td>None</td>\n",
       "      <td>family</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>721</td>\n",
       "      <td>Working on my project</td>\n",
       "      <td>None</td>\n",
       "      <td>self_development</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>721</td>\n",
       "      <td>Gym</td>\n",
       "      <td>*</td>\n",
       "      <td>sport_&amp;_health</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>721</td>\n",
       "      <td>Interesting history lecture</td>\n",
       "      <td>*</td>\n",
       "      <td>relax_&amp;_rest</td>\n",
       "      <td>Positive</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>718</td>\n",
       "      <td>Awesome cycling with Anna and her brother</td>\n",
       "      <td>None</td>\n",
       "      <td>family</td>\n",
       "      <td>Positive</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activity_id  post_id                              activity_name  \\\n",
       "0            9      721                            Hiking with Ann   \n",
       "1           10      721                      Working on my project   \n",
       "2           11      721                                        Gym   \n",
       "3           12      721                Interesting history lecture   \n",
       "4           13      718  Awesome cycling with Anna and her brother   \n",
       "\n",
       "  activity_emoji     activity_type activity_emotion predicted_activity_type  \\\n",
       "0           None            family          Neutral                    None   \n",
       "1           None  self_development          Neutral                    None   \n",
       "2              *    sport_&_health          Neutral                    None   \n",
       "3              *      relax_&_rest         Positive                    None   \n",
       "4           None            family         Positive                    None   \n",
       "\n",
       "  predicted_activity_emotion  \n",
       "0                       None  \n",
       "1                       None  \n",
       "2                       None  \n",
       "3                       None  \n",
       "4                       None  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activities_df = sql_to_df('activities')\n",
    "activities_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce65b642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='activity_type'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "activities_df.groupby(by = ['activity_type']).activity_id.count().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c53927f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>text</th>\n",
       "      <th>parsed_date</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>edit_date</th>\n",
       "      <th>productivity_score</th>\n",
       "      <th>interest_score</th>\n",
       "      <th>stress_score</th>\n",
       "      <th>predicted_productivity_score</th>\n",
       "      <th>predicted_interest_score</th>\n",
       "      <th>predicted_stress_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125</td>\n",
       "      <td>27.01.23\\n❌ Statistics HM\\n✅ Tinkoff HM (first...</td>\n",
       "      <td>2023-01-27</td>\n",
       "      <td>2023-01-27 08:45:32</td>\n",
       "      <td>2023-07-26 15:44:40</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126</td>\n",
       "      <td>28.01.23\\nSlept for 6 hours, in the morning i ...</td>\n",
       "      <td>2023-01-28</td>\n",
       "      <td>2023-01-28 19:24:38</td>\n",
       "      <td>2023-07-26 15:44:31</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127</td>\n",
       "      <td>29.01.23 \\n\\n✅ Statistics: seminar \\n✅ TInkoff...</td>\n",
       "      <td>2023-01-29</td>\n",
       "      <td>2023-01-28 20:57:43</td>\n",
       "      <td>2023-07-26 15:44:17</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>30.01.23\\n\\n❌ Wiping with cold water\\n✅ Sport:...</td>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>2023-01-29 20:41:27</td>\n",
       "      <td>2023-07-26 15:43:52</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129</td>\n",
       "      <td>31.01.23\\n\\n✅ Wiping with cold water\\n✅ Sport:...</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>2023-01-30 21:44:57</td>\n",
       "      <td>2023-07-26 15:43:42</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                               text parsed_date  \\\n",
       "0      125  27.01.23\\n❌ Statistics HM\\n✅ Tinkoff HM (first...  2023-01-27   \n",
       "1      126  28.01.23\\nSlept for 6 hours, in the morning i ...  2023-01-28   \n",
       "2      127  29.01.23 \\n\\n✅ Statistics: seminar \\n✅ TInkoff...  2023-01-29   \n",
       "3      128  30.01.23\\n\\n❌ Wiping with cold water\\n✅ Sport:...  2023-01-30   \n",
       "4      129  31.01.23\\n\\n✅ Wiping with cold water\\n✅ Sport:...  2023-01-31   \n",
       "\n",
       "          upload_date           edit_date  productivity_score  interest_score  \\\n",
       "0 2023-01-27 08:45:32 2023-07-26 15:44:40                 6.0             6.0   \n",
       "1 2023-01-28 19:24:38 2023-07-26 15:44:31                 4.0             4.0   \n",
       "2 2023-01-28 20:57:43 2023-07-26 15:44:17                 5.0             5.0   \n",
       "3 2023-01-29 20:41:27 2023-07-26 15:43:52                 7.0             7.0   \n",
       "4 2023-01-30 21:44:57 2023-07-26 15:43:42                 7.0             7.0   \n",
       "\n",
       "   stress_score predicted_productivity_score predicted_interest_score  \\\n",
       "0           1.0                         None                     None   \n",
       "1           3.0                         None                     None   \n",
       "2           2.0                         None                     None   \n",
       "3           1.0                         None                     None   \n",
       "4           1.0                         None                     None   \n",
       "\n",
       "  predicted_stress_score  \n",
       "0                   None  \n",
       "1                   None  \n",
       "2                   None  \n",
       "3                   None  \n",
       "4                   None  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df = sql_to_df('posts')\n",
    "posts_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799a3c6c",
   "metadata": {},
   "source": [
    "# Activity classification: fine-tune DistilBERT/RoBERTa base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3eedff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_types = ['self_development', 'university', 'work', 'relax_&_rest', 'chill', 'sport_&_health', 'family', 'social_&_friends', 'travel_&_adventure', 'chore', 'other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81167746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'self_development': 0,\n",
       " 'university': 1,\n",
       " 'work': 2,\n",
       " 'relax_&_rest': 3,\n",
       " 'chill': 4,\n",
       " 'sport_&_health': 5,\n",
       " 'family': 6,\n",
       " 'social_&_friends': 7,\n",
       " 'travel_&_adventure': 8,\n",
       " 'chore': 9,\n",
       " 'other': 10}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_activity_type_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55d4a1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = activities_df[['activity_name','activity_type']]\n",
    "def encode_type(x):\n",
    "    return encode_activity_type_dict[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8314b792",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-82106bc8f75c>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['encoded_activity_type'] = df['activity_type'].apply(lambda x: encode_type(x))\n"
     ]
    }
   ],
   "source": [
    "df['encoded_activity_type'] = df['activity_type'].apply(lambda x: encode_type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d266b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_name</th>\n",
       "      <th>activity_type</th>\n",
       "      <th>encoded_activity_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hiking with Ann</td>\n",
       "      <td>family</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Working on my project</td>\n",
       "      <td>self_development</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gym</td>\n",
       "      <td>sport_&amp;_health</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Interesting history lecture</td>\n",
       "      <td>relax_&amp;_rest</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Awesome cycling with Anna and her brother</td>\n",
       "      <td>family</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>still recovering from lack of sleep</td>\n",
       "      <td>relax_&amp;_rest</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>Slept for 6 hours in the morning i have visite...</td>\n",
       "      <td>other</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>Statistics HM</td>\n",
       "      <td>self_development</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>Tinkoff HM first two tasks</td>\n",
       "      <td>self_development</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>Send a request for mentoring programm</td>\n",
       "      <td>self_development</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>636 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         activity_name     activity_type  \\\n",
       "0                                      Hiking with Ann            family   \n",
       "1                                Working on my project  self_development   \n",
       "2                                                  Gym    sport_&_health   \n",
       "3                          Interesting history lecture      relax_&_rest   \n",
       "4            Awesome cycling with Anna and her brother            family   \n",
       "..                                                 ...               ...   \n",
       "631                still recovering from lack of sleep      relax_&_rest   \n",
       "632  Slept for 6 hours in the morning i have visite...             other   \n",
       "633                                      Statistics HM  self_development   \n",
       "634                         Tinkoff HM first two tasks  self_development   \n",
       "635              Send a request for mentoring programm  self_development   \n",
       "\n",
       "     encoded_activity_type  \n",
       "0                        6  \n",
       "1                        0  \n",
       "2                        5  \n",
       "3                        3  \n",
       "4                        6  \n",
       "..                     ...  \n",
       "631                      3  \n",
       "632                     10  \n",
       "633                      0  \n",
       "634                      0  \n",
       "635                      0  \n",
       "\n",
       "[636 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52498781",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('activities_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "aa0699f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 1337\n",
    "\n",
    "\n",
    "def set_seed(seed=random_state):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccc447c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "496af723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import DistilBertModel, DistilBertTokenizer, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.cuda.amp import GradScaler, autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "1c21be7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 16\n",
    "EPOCHS = 2\n",
    "LEARNING_RATE = 2e-05\n",
    "EPS =  1e-8\n",
    "NUM_CLASSES = len(activity_types)\n",
    "\n",
    "distilbert_path = '/media/tonyalpha/HDD/distilbert-base-uncased'\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(distilbert_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "fea40953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "  \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "c06d3c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        title = str(self.data.activity_type[index])\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            title,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.data.encoded_activity_type[index], dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "7ab3114b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  36\n"
     ]
    }
   ],
   "source": [
    "#let's define max sentence len \n",
    "\n",
    "max_len = 0\n",
    "\n",
    "for sent in df.activity_name:\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "19d2ffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "b18b494e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (636, 3)\n",
      "TRAIN Dataset: (509, 3)\n",
      "TEST Dataset: (127, 3)\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "\n",
    "train_size = 0.8\n",
    "train_dataset=df.sample(frac=train_size,random_state=random_state)\n",
    "test_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "aeebe283",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "\n",
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "train_loader = DataLoader(training_set, **train_params)\n",
    "test_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "160a2e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillBERT_classifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistillBERT_classifier, self).__init__()\n",
    "        self.l1 = DistilBertModel.from_pretrained(distilbert_path)\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, NUM_CLASSES)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "df1f6429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, train_metrics, val_losses, val_metrics):\n",
    "    '''\n",
    "    Plot losses and metrics while training\n",
    "      - train_losses: sequence of train losses\n",
    "      - train_metrics: sequence of train MSE values\n",
    "      - val_losses: sequence of validation losses\n",
    "      - val_metrics: sequence of validation MSE values\n",
    "    '''\n",
    "    clear_output()\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    axs[0].plot(range(1, len(train_losses) + 1), train_losses, label='train')\n",
    "    axs[0].plot(range(1, len(val_losses) + 1), val_losses, label='val')\n",
    "    axs[1].plot(range(1, len(train_metrics) + 1), train_metrics, label='train')\n",
    "    axs[1].plot(range(1, len(val_metrics) + 1), val_metrics, label='val')\n",
    "\n",
    "    # if max(train_losses) / min(train_losses) > 10:\n",
    "    #    axs[0].set_yscale('log')\n",
    "    #\n",
    "    # if max(train_metrics) / min(train_metrics) > 10:\n",
    "    #    axs[0].set_yscale('log')\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel('epoch')\n",
    "        ax.legend()\n",
    "\n",
    "    axs[0].set_ylabel('loss')\n",
    "    axs[1].set_ylabel('metric')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def train_and_validate(device, model, optimizer, criterion, metric, train_loader, val_loader,\n",
    "                       num_epochs, verbose=True):\n",
    "    '''\n",
    "    Train and validate neural network\n",
    "      - model: neural network to train\n",
    "      - optimizer: optimizer chained to a model\n",
    "      - criterion: loss function class\n",
    "      - metric: function to measure MSE taking neural networks predictions\n",
    "                 and ground truth labels\n",
    "      - train_loader: DataLoader with train set\n",
    "      - val_loader: DataLoader with validation set\n",
    "      - num_epochs: number of epochs to train\n",
    "      - verbose: whether to plot metrics during training\n",
    "      - device: device to use for training and inference, e.g. 'cpu', 'cuda'\n",
    "    Returns:\n",
    "      - train_mse: training MSE over the last epoch\n",
    "      - val_mse: validation MSE after the last epoch\n",
    "    '''\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    train_metrics, val_metrics = [], []\n",
    "    \n",
    "    \n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    total_steps = len(train_loader) * num_epochs\n",
    "    \n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer=optimizer, \n",
    "                                                num_warmup_steps=0,\n",
    "                                                num_training_steps=total_steps)\n",
    "    \n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        \n",
    "        model.train()\n",
    "        running_loss, running_metric = 0, 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f'Training {epoch}/{num_epochs}') \\\n",
    "        if verbose else train_loader\n",
    "\n",
    "        for i, batch in enumerate(pbar, 1):\n",
    "            \n",
    "            ids = batch['input_ids'].to(device)\n",
    "            mask = batch['attention_mask'].to(device)\n",
    "            targets = batch['targets'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast():\n",
    "                logits = model(ids, mask)               \n",
    "                loss = loss_function(logits, targets)\n",
    "            \n",
    "            \n",
    "#             logits = logits.detach().cpu().numpy()\n",
    "#             targets = targets.to('cpu').numpy()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                big_val, big_idx = torch.max(logits.data, 1)\n",
    "                \n",
    "                metric_value = metric(big_idx, targets)\n",
    "                if type(metric_value) == torch.Tensor:\n",
    "                    metric_value = metric_value.item()\n",
    "\n",
    "                running_loss += loss.item() \n",
    "                running_metric += metric_value\n",
    "                \n",
    "                \n",
    "            \n",
    "                \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            scheduler.step()\n",
    "           \n",
    "\n",
    "            if verbose and i % 100 == 0:\n",
    "                pbar.set_postfix({'loss': loss.item(), 'MSE': metric_value})\n",
    "\n",
    "        train_losses += [running_loss / len(train_loader)]\n",
    "        train_metrics += [running_metric / len(train_loader)]\n",
    "        \n",
    "        \n",
    "        model.eval()\n",
    "        running_loss, running_metric = 0, 0\n",
    "        \n",
    "        pbar = tqdm(val_loader, desc=f'Validating {epoch}/{num_epochs}') \\\n",
    "            if verbose else val_loader\n",
    "        \n",
    "        \n",
    "        for i, batch in enumerate(pbar, 1):\n",
    "            \n",
    "            ids = batch['input_ids'].to(device)\n",
    "            mask = batch['attention_mask'].to(device)\n",
    "            targets = batch['targets'].to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(ids, mask)\n",
    "                loss = loss_function(logits.data, targets)\n",
    "                \n",
    "                # logits = logits.detach().cpu().numpy()\n",
    "                # targets = targets.to('cpu').numpy()\n",
    "                \n",
    "                big_val, big_idx = torch.max(logits, 1)\n",
    "                \n",
    "                metric_value = metric(big_idx, targets)\n",
    "                \n",
    "                if type(metric_value) == torch.Tensor:\n",
    "                    metric_value = metric_value.item()\n",
    "                    \n",
    "                running_loss += loss.item() \n",
    "                running_metric += metric_value\n",
    "\n",
    "            if verbose and i % 100 == 0:\n",
    "                pbar.set_postfix({'loss': loss.item(), 'MSE': metric_value})\n",
    "\n",
    "                \n",
    "        val_losses += [running_loss / len(val_loader)]\n",
    "        val_metrics += [running_metric / len(val_loader)]\n",
    "\n",
    "        if verbose:\n",
    "            plot_losses(train_losses, train_metrics, val_losses, val_metrics)\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Validation metric: {val_metrics[-1]:.3f}')\n",
    "\n",
    "    return train_metrics[-1], val_metrics[-1]\n",
    "\n",
    "\n",
    "def accuracy(big_idx, targets):\n",
    "    n_correct = (big_idx==targets).sum().item()\n",
    "    return n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2bc4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febb85ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed5c086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "511db25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /media/tonyalpha/HDD/distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = DistillBERT_classifier()\n",
    "model.to(device)\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = LEARNING_RATE, eps = EPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "64324b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def accuracy(preds, labels):\n",
    "#     pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "#     labels_flat = labels.flatten()\n",
    "#     return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39b146d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 16\n",
    "EPOCHS = 2\n",
    "LEARNING_RATE = 2e-05\n",
    "EPS =  1e-8\n",
    "NUM_CLASSES = len(activity_types)\n",
    "\n",
    "train_and_validate(device, model, optimizer, criterion = loss_function, metric = accuracy, \n",
    "                   train_loader = train_loader, val_loader = test_loader, num_epochs = EPOCHS, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297a4d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Hiking in park'\n",
    "\n",
    "encoded_dict = tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "            \n",
    "        )\n",
    "\n",
    "ids = torch.tensor(encoded_dict['input_ids'], dtype=torch.long).to(device)\n",
    "mask = torch.tensor(encoded_dict['attention_mask'], dtype=torch.long).to(device)\n",
    "\n",
    "with autocast():\n",
    "    logits = model(ids, mask)\n",
    "\n",
    "probs = torch.softmax(logits, dim = 1)\n",
    "big_val, big_idx = torch.max(probs, 1)\n",
    "\n",
    "predicted_prob = big_val.cpu().detach().numpy()[0]\n",
    "predicted_index = big_idx.cpu().numpy()[0]\n",
    "\n",
    "print(f'activiti type: {activity_types[predicted_index].upper()} with probability:{predicted_prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e65913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd608443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ed2b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cc45a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b371773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4a0909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260534d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_file = './models/pytorch_distilbert_news.bin'\n",
    "output_vocab_file = './models/vocab_distilbert_news.bin'\n",
    "\n",
    "model_to_save = model\n",
    "torch.save(model_to_save, output_model_file)\n",
    "tokenizer.save_vocabulary(output_vocab_file)\n",
    "\n",
    "print('All files saved')\n",
    "print('This tutorial is completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8b9a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a0c10b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5534809e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff037e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b508f136",
   "metadata": {},
   "source": [
    "# Sentiment analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "279d0f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "835ea02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "bertweet_base_sentiment_analysis = pipeline(\"text-classification\", model=\"/media/tonyalpha/HDD/bertweet-base-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "351f52a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEG', 'score': 0.8925472497940063},\n",
       " {'label': 'NEU', 'score': 0.0853690579533577},\n",
       " {'label': 'POS', 'score': 0.022083677351474762}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertweet_base_sentiment_analysis('Sad day', top_k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9236e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a70632c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51296c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eaa935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d8569b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be81ec27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffa9f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc67be7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ef4245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3bcbba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6017754c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203476e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4aa7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cc781f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29db8d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47582d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1329ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bf1883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12718e54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c65c8fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8667abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeca1d41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77895426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e199ca47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2c2ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89e29f29",
   "metadata": {},
   "source": [
    "# Sync with DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16da3c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7da1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f305d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fcb80c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974acb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8525b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "906c28ee",
   "metadata": {},
   "source": [
    "# Etc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afef809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
