{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d25c80bf",
   "metadata": {},
   "source": [
    "# Bot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4895570e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fa4af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "from telegram import Update, Bot\n",
    "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext\n",
    "\n",
    "bot = Bot(token=API_TOKEN)\n",
    "updater = Updater(token=API_TOKEN, use_context=True)\n",
    "dispatcher = updater.dispatcher\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                     level=logging.INFO)\n",
    "\n",
    "\n",
    "def send_new_channel_messages(update: Update, context: CallbackContext):\n",
    "    channel_id = 'my life'\n",
    "    channel_updates = bot.get_chat_updates(channel_id)\n",
    "\n",
    "    user_id = update.message.from_user.id\n",
    "\n",
    "    for update in channel_updates:\n",
    "        if update.message:\n",
    "            bot.forward_message(chat_id=user_id, from_chat_id=channel_id, message_id=update.message.message_id)\n",
    "\n",
    "\n",
    "def start(update: Update, context: CallbackContext):\n",
    "    user_id = update.message.from_user.id\n",
    "    update.message.reply_text(f\"Hello! I will send you new messages from the channel.\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    dispatcher.add_handler(MessageHandler(Filters.chat_type.channel, send_new_channel_messages))\n",
    "    dispatcher.add_handler(CommandHandler(\"start\", start))\n",
    "\n",
    "    updater.start_polling()\n",
    "    updater.idle()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d559c4",
   "metadata": {},
   "source": [
    "# Config upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1b7bd509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import json\n",
    "\n",
    "from telethon import TelegramClient\n",
    "from telethon.errors import SessionPasswordNeededError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3e26336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Configs\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "\n",
    "# Setting configuration values\n",
    "api_id = config['Telegram']['api_id']\n",
    "api_hash = config['Telegram']['api_hash']\n",
    "api_token = config['Telegram']['api_token']\n",
    "\n",
    "api_hash = str(api_hash)\n",
    "\n",
    "phone = config['Telegram']['phone']\n",
    "username = config['Telegram']['username']\n",
    "channel_link = config['Telegram']['channel_link'] \n",
    "\n",
    "db_name = config['database']['db_name']\n",
    "db_user = config['database']['db_user']\n",
    "db_password = config['database']['db_password'] \n",
    "db_host = config['database']['db_host'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "802e1177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "#facebook_bart_large_mnli = pipeline(\"zero-shot-classification\", model=\"/media/tonyalpha/HDD/facebook-bart-large-mnli\")\n",
    "#bertweet_base_sentiment_analysis = pipeline(\"text-classification\", model=\"/media/tonyalpha/HDD/bertweet-base-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ede0af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not client.is_user_authorized():\n",
    "#     client.send_code_request(phone)\n",
    "#     try:\n",
    "#         client.sign_in(phone, input('Enter the code: '))\n",
    "#     except SessionPasswordNeededError:\n",
    "#         client.sign_in(password=input('Password: '))\n",
    "\n",
    "# me = client.get_me()\n",
    "# print(me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aac3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de7015f7",
   "metadata": {},
   "source": [
    "# Get data from telegram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8fc97231",
   "metadata": {},
   "outputs": [],
   "source": [
    "from telethon.tl.types import InputMessagesFilterPhotos\n",
    "from telethon import TelegramClient, events\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os.path\n",
    "\n",
    "def get_posts(num_posts = 1, download_media = False, only_with_media = True, offset_id = 0, posts_list = []):\n",
    "    client = TelegramClient(username, api_id, api_hash)\n",
    "    posts_list = []\n",
    "    async def main(num_posts, download_media, offset_id, posts_list):\n",
    "        \n",
    "        if num_posts < 100:\n",
    "            message_limit = num_posts\n",
    "        else:\n",
    "            message_limit = 100\n",
    "            \n",
    "            \n",
    "        last_post_date = None\n",
    "        post = {}\n",
    "        \n",
    "        await client.start()\n",
    "\n",
    "        try:\n",
    "            entity = await client.get_entity(channel_link)\n",
    "\n",
    "            while True:\n",
    "                messages = await client.get_messages(entity, limit=message_limit, offset_id = offset_id)\n",
    "\n",
    "                for message in messages:\n",
    "                    \n",
    "                    if only_with_media:\n",
    "                        if not message.media:\n",
    "                            continue\n",
    "                    \n",
    "                    if last_post_date == None:\n",
    "                        last_post_date = message.date\n",
    "\n",
    "                    # if delay between uploading messages is more than 10 second i will separate them\n",
    "                    if (last_post_date - message.date).seconds > 10: \n",
    "                        post['upload_date'] = last_post_date.strftime('%Y-%m-%d %H:%M:%S') if last_post_date else None\n",
    "\n",
    "                        last_post_date = message.date\n",
    "\n",
    "                        posts_list.append(post)\n",
    "                        post = {}\n",
    "\n",
    "\n",
    "                    if len(message.message) > 0:\n",
    "                        post['text'] = post.get('text', '') + message.message \n",
    "                        \n",
    "                        # post_id in messages set will be id of message with text and photo \n",
    "                        post['post_id'] = message.id\n",
    "\n",
    "\n",
    "                    if message.media and download_media:\n",
    "\n",
    "                        photo_id = message.media.photo.id\n",
    "                        filename = f'image_{photo_id}.jpg'\n",
    "                        path = f\"./media/{filename}\"\n",
    "\n",
    "                        # some of this i should drop, but later \n",
    "                        post['photos_id_list'] = post.get('photos_id_list', []) + [photo_id]\n",
    "                        post['photos_names_list'] = post.get('photos_names_list', []) + [filename]\n",
    "\n",
    "                        #if file exist check \n",
    "                        if not os.path.isfile(path) and download_media:\n",
    "                            await client.download_media(message, file=path)\n",
    "\n",
    "                    post['id_list'] = post.get('id_list', []) + [message.id]\n",
    "                    post['edit_date'] = message.edit_date.strftime('%Y-%m-%d %H:%M:%S') if message.edit_date else None\n",
    "\n",
    "\n",
    "                offset_id = messages[len(messages) - 1].id\n",
    "\n",
    "                if len(posts_list) >= num_posts:\n",
    "                    break\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "        await client.disconnect()\n",
    "        \n",
    "        return posts_list\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        client.loop.run_until_complete(main(num_posts, download_media, offset_id, posts_list))\n",
    "        \n",
    "    return posts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14a8bf02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id_list': [724, 723, 722, 721],\n",
       "  'edit_date': '2023-07-27 20:00:47',\n",
       "  'text': '26.07.23\\n\\nüôàüëåüôã\\u200d‚ôÄÔ∏èüñê Hiking with Ann\\n\\nWorking on my project\\n\\n* Gym \\n\\n* Interesting history lecture \\n\\nHow productive have you been?: 4.5/10\\nHow interesting was the day?: 6/10\\nHow stressful was the day?: 1/10',\n",
       "  'post_id': 721,\n",
       "  'upload_date': '2023-07-26 16:28:42'},\n",
       " {'id_list': [720, 719, 718],\n",
       "  'edit_date': '2023-07-26 16:02:57',\n",
       "  'text': '25.07.23\\n\\nAwesome cycling with Anna and her brother \\n\\nLazy work on my project\\n\\nInteresting mathematics lecture before sleep\\n\\nHow productive have you been?: 3.5/10\\nHow interesting was the day?: 6/10\\nHow stressful was the day?: 2/10',\n",
       "  'post_id': 718,\n",
       "  'upload_date': '2023-07-26 13:32:45'},\n",
       " {'id_list': [717, 716, 715],\n",
       "  'edit_date': '2023-07-26 16:02:48',\n",
       "  'text': '24.07.23\\n\\nGym: good traning \\n\\nMy project for portfolio: do some things  \\n\\nInteresting history lecture  \\n\\nHow productive have you been?: 4.5/10\\nHow interesting was the day?: 5/10\\nHow stressful was the day?: 0/10',\n",
       "  'post_id': 715,\n",
       "  'upload_date': '2023-07-26 13:31:56'},\n",
       " {'id_list': [714, 713, 712],\n",
       "  'edit_date': '2023-07-26 16:04:37',\n",
       "  'text': '23.07.23\\n\\nMoving to new flat  \\n\\nWorking on my project\\n\\nHow productive have you been?: 5/10\\nHow interesting was the day?: 5/10\\nHow stressful was the day?: 2/10',\n",
       "  'post_id': 712,\n",
       "  'upload_date': '2023-07-26 13:29:37'},\n",
       " {'id_list': [711, 710, 709],\n",
       "  'edit_date': '2023-07-26 16:04:59',\n",
       "  'text': '22.07.23\\n\\nWork on my project\\n\\nLazy day \\n\\nHow productive have you been?: 5/10\\nHow interesting was the day?: 3/10\\nHow stressful was the day?: 0/10',\n",
       "  'post_id': 709,\n",
       "  'upload_date': '2023-07-26 13:28:22'},\n",
       " {'id_list': [707, 706, 705],\n",
       "  'edit_date': '2023-07-26 16:05:34',\n",
       "  'text': '21.07.23\\n\\nWorking on my project\\n\\nCooking \\n\\nEvening with Anna family \\n\\nHow productive have you been?: 4/10\\nHow interesting was the day?: 6/10\\nHow stressful was the day?: 0/10',\n",
       "  'post_id': 705,\n",
       "  'upload_date': '2023-07-26 11:10:37'},\n",
       " {'id_list': [704, 703, 702],\n",
       "  'edit_date': '2023-07-26 13:35:01',\n",
       "  'text': '20.07.23\\n\\nMy project\\n\\nHousehold stuff\\n\\nMovies time: spider man awesome cartoon!\\n\\nHow productive have you been?: 5/10\\nHow interesting was the day?: 6/10\\nHow stressful was the day?: 0/10',\n",
       "  'post_id': 702,\n",
       "  'upload_date': '2023-07-26 11:07:52'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_posts(num_posts = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1d1deb",
   "metadata": {},
   "source": [
    "# Data parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e967f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "30914e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def parse_text(dct):\n",
    "    \n",
    "    input_string = dct.get('text', None)\n",
    "    \n",
    "    if input_string is None:\n",
    "        return dct\n",
    "    \n",
    "    date_pattern = r'\\d{2}\\.\\d{2}\\.\\d{2}'\n",
    "    day_pattern = r'\\b(?:MONDAY|TUESDAY|WEDNESDAY|THURSDAY|FRIDAY|SATURDAY|SUNDAY)\\b'\n",
    "    \n",
    "    date_match = re.search(date_pattern, input_string)\n",
    "    day_match = re.search(day_pattern, input_string)\n",
    "    \n",
    "    date = date_match.group() if date_match else None\n",
    "    day = day_match.group() if day_match else None\n",
    "    \n",
    "    parsed_date = date.split('.')[-1] + '-' + date.split('.')[1] + '-' + date.split('.')[0] if date or day else None\n",
    "    \n",
    "    dct['parsed_date'] = parsed_date\n",
    "    \n",
    "    if date_match:\n",
    "        input_string = input_string.replace(date_match.group(), \"\") if parsed_date is not None else input_string\n",
    "    if day_match:\n",
    "        input_string = input_string.replace(day_match.group(), \"\") if parsed_date is not None else input_string\n",
    "    \n",
    "    regex_list = [r'How productive have you been\\?:\\s*(\\S|\\s+|\\d+\\.?\\d*)/10', r'How interesting was the day\\?:\\s*(\\S|\\s+|\\d+\\.?\\d*)/10', r'How stressful was the day\\?:\\s*(\\S|\\s+|\\d+\\.?\\d*)/10']\n",
    "    names_list = ['productivity_score', 'interest_score', 'stress_score']\n",
    "    \n",
    "    for regex, name in zip(regex_list, names_list):\n",
    "        match = re.search(regex, input_string)\n",
    "        \n",
    "        if match:\n",
    "            try:\n",
    "                parsed_score = float(match.group(1))\n",
    "            except:\n",
    "                parsed_score = None\n",
    "        else:\n",
    "            parsed_score = None\n",
    "        \n",
    "        \n",
    "        #parsed_score = match.group(1) if match and match.group(1).isdigit() else None\n",
    "        \n",
    "        dct[name] = parsed_score\n",
    "\n",
    "        input_string = input_string.replace(match.group(), \"\") if match else input_string\n",
    "        \n",
    "    \n",
    "    dct['parsed_text'] = input_string.split('\\n')\n",
    "    return dct\n",
    "    \n",
    "def parse_activities(dct):\n",
    "    \n",
    "    input_list = dct.get('parsed_text', None)\n",
    "    \n",
    "    if input_list is None:\n",
    "        return dct\n",
    "    \n",
    "    result = []\n",
    "    for item in input_list:\n",
    "        match = re.match(r'^([\\U0001F000-\\U0001F9FF]+|[\\U0001FA00-\\U0001FA6F]+|\\*)?\\s*(.*)$', item)\n",
    "        if match:\n",
    "            emoji = match.group(1)\n",
    "            text = match.group(2).strip()\n",
    "            if emoji or text:\n",
    "                result.append((emoji, text))\n",
    "                \n",
    "    dct['parsed_activities'] = result\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4c6f2ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id_list': [724, 723, 722, 721],\n",
       "  'edit_date': '2023-07-28 12:50:10',\n",
       "  'text': '26.07.23\\n\\nsakisaki Hiking with Ann\\n\\nWorking on my project\\n\\n* Gym \\n\\n* Interesting history lecture \\n\\nHow productive have you been?: 4.5/10\\nHow interesting was the day?: 6/10\\nHow stressful was the day?: 1/10',\n",
       "  'post_id': 721,\n",
       "  'upload_date': '2023-07-26 16:28:42'}]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_posts(num_posts = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fe13e657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_list': [717, 716, 715],\n",
       " 'edit_date': '2023-07-26 16:02:48',\n",
       " 'text': '24.07.23\\n\\nGym: good traning \\n\\nMy project for portfolio: do some things  \\n\\nInteresting history lecture  \\n\\nHow productive have you been?: 4.5/10\\nHow interesting was the day?: 5/10\\nHow stressful was the day?: 0/10',\n",
       " 'post_id': 715,\n",
       " 'upload_date': '2023-07-26 13:31:56',\n",
       " 'parsed_date': '23-07-24',\n",
       " 'productivity_score': 4.5,\n",
       " 'interest_score': 5.0,\n",
       " 'stress_score': 0.0,\n",
       " 'parsed_text': ['',\n",
       "  '',\n",
       "  'Gym: good traning ',\n",
       "  '',\n",
       "  'My project for portfolio: do some things  ',\n",
       "  '',\n",
       "  'Interesting history lecture  ',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '']}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_text(get_posts(num_posts = 4)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4e6389a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_list': [724, 723, 722, 721],\n",
       " 'edit_date': '2023-07-28 12:50:10',\n",
       " 'text': '26.07.23\\n\\nsakisaki Hiking with Ann\\n\\nWorking on my project\\n\\n* Gym \\n\\n* Interesting history lecture \\n\\nHow productive have you been?: 4.5/10\\nHow interesting was the day?: 6/10\\nHow stressful was the day?: 1/10',\n",
       " 'post_id': 721,\n",
       " 'upload_date': '2023-07-26 16:28:42',\n",
       " 'parsed_date': '23-07-26',\n",
       " 'productivity_score': 4.5,\n",
       " 'interest_score': 6.0,\n",
       " 'stress_score': 1.0,\n",
       " 'parsed_text': ['',\n",
       "  '',\n",
       "  'sakisaki Hiking with Ann',\n",
       "  '',\n",
       "  'Working on my project',\n",
       "  '',\n",
       "  '* Gym ',\n",
       "  '',\n",
       "  '* Interesting history lecture ',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  ''],\n",
       " 'parsed_activities': [(None, 'sakisaki Hiking with Ann'),\n",
       "  (None, 'Working on my project'),\n",
       "  ('*', 'Gym'),\n",
       "  ('*', 'Interesting history lecture')]}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_activities(parse_text(get_posts(num_posts = 3)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520e5c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11414101",
   "metadata": {},
   "source": [
    "# Upload to DB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "e6830fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "def update_post(post_id, update_data):\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            \n",
    "            update_post_table_query= ''\n",
    "            update_values = []\n",
    "            \n",
    "            for key, value in update_data.items():\n",
    "                    update_post_table_query += key + ' = %s, '\n",
    "                    update_values += [value]\n",
    "            \n",
    "            update_post_table_query = update_post_table_query.rstrip(', ')\n",
    "            update_post_table_query = 'UPDATE posts SET ' + update_post_table_query + ' WHERE post_id = %s;'\n",
    "            \n",
    "            update_values += [post_id]\n",
    "            update_values = tuple(update_values)\n",
    "            \n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(update_post_table_query, update_values)\n",
    "                connection.commit()\n",
    "                \n",
    "            print(f'UPDATED: post with id:{post_id}')\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "        \n",
    "                \n",
    "def update_activity(activity_id, update_data):\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            \n",
    "            update_activity_table_query= ''\n",
    "            update_values = []\n",
    "            \n",
    "            for key, value in update_data.items():\n",
    "                    update_activity_table_query += key + ' = %s, '\n",
    "                    update_values += [value]\n",
    "            \n",
    "            update_activity_table_query = update_activity_table_query.rstrip(', ')\n",
    "            update_activity_table_query = 'UPDATE activities SET ' + update_activity_table_query + ' WHERE activity_id = %s;'\n",
    "            \n",
    "            update_values += [activity_id]\n",
    "            update_values = tuple(update_values)\n",
    "            \n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(update_activity_table_query, update_values)\n",
    "                connection.commit()\n",
    "                \n",
    "            print(f'UPDATED: activity with id:{activity_id}')\n",
    "    except Error as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b4c97e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "from getpass import getpass\n",
    "from mysql.connector import connect, Error\n",
    "\n",
    "\n",
    "def db_connect():\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            create_posts_table_query = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS posts(\n",
    "                post_id INT,\n",
    "                text TEXT,\n",
    "                parsed_date DATE,\n",
    "                upload_date DATETIME,\n",
    "                edit_date DATETIME, \n",
    "                productivity_score FLOAT,\n",
    "                interest_score FLOAT,\n",
    "                stress_score FLOAT,\n",
    "                predicted_productivity_score FLOAT,\n",
    "                predicted_interest_score FLOAT,\n",
    "                predicted_stress_score FLOAT,\n",
    "                PRIMARY KEY (post_id)\n",
    "            );\n",
    "            \"\"\"\n",
    "            \n",
    "            create_posts_table_activities = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS activities(\n",
    "                activity_id INT AUTO_INCREMENT,\n",
    "                post_id INT,\n",
    "                activity_name TEXT,\n",
    "                activity_emoji TEXT,\n",
    "                activity_type TEXT,\n",
    "                activity_emotion TEXT,\n",
    "                predicted_activity_type TEXT,\n",
    "                predicted_activity_emotion TEXT,\n",
    "                FOREIGN KEY (post_id) REFERENCES posts(post_id),\n",
    "                PRIMARY KEY (activity_id)\n",
    "            );\n",
    "            \"\"\"\n",
    "            \n",
    "            \n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(create_posts_table_query)\n",
    "                cursor.execute(create_posts_table_activities)\n",
    "                connection.commit()\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "def upload_post(dct, overwrite = False):\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            check_if_exist = \"\"\"SELECT EXISTS(SELECT 1 FROM posts WHERE post_id = %s LIMIT 1)\"\"\"\n",
    "            \n",
    "            upload_posts_table_query = f\"\"\"\n",
    "            INSERT INTO posts (post_id, text, parsed_date, upload_date, \n",
    "            edit_date,productivity_score, interest_score, stress_score, \n",
    "            predicted_productivity_score, predicted_interest_score,\n",
    "            predicted_stress_score) \n",
    "            VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "            \n",
    "            post_id = (dct.get('post_id', None),)\n",
    "            uploaded_date = dct.get('upload_date', None)\n",
    "            \n",
    "            insert_data = (dct.get('post_id', None), dct.get('text', None), \n",
    "                    dct.get('parsed_date', None), dct.get('upload_date', None), \n",
    "                    dct.get('edit_date', None),dct.get('productivity_score', None),\n",
    "                    dct.get('interest_score', None),dct.get('stress_score', None),\n",
    "                    dct.get('predicted_productivity_score', None), dct.get('predicted_interest_score', None),\n",
    "                    dct.get('predicted_stress_score', None))\n",
    "            \n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(check_if_exist, post_id)\n",
    "                for el in cursor:\n",
    "                    exist = el[0]\n",
    "                \n",
    "                if not exist:\n",
    "                    cursor.execute(upload_posts_table_query, insert_data)\n",
    "                    connection.commit()\n",
    "                    print(f'UPLOADED: post with id:{post_id} and uploaded_date:{uploaded_date}')\n",
    "                else:\n",
    "                    if overwrite:\n",
    "                        pass\n",
    "                        print('OVERWRITED: post with id:{post_id} and uploaded_date:{uploaded_date}')\n",
    "                    else:\n",
    "                        print(f'ERROR: post with id:{post_id} and uploaded_date:{uploaded_date} already uploaded')\n",
    "                        print('If you want to overwrite data add flag')\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "        \n",
    "def upload_activities(dct, overwrite = False):\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            \n",
    "            for activity_emoji, activity_name in dct['parsed_activities']:\n",
    "                \n",
    "                activity_name = \"\".join(c for c in activity_name if c.isalpha() or c.isnumeric() or c == ' ' or c == '!').strip(' ')\n",
    "                check_if_exist = \"\"\"SELECT EXISTS(SELECT 1 FROM activities WHERE post_id = %s AND activity_name = %s LIMIT 1)\"\"\"\n",
    "\n",
    "                upload_posts_table_query = f\"\"\"\n",
    "                INSERT INTO activities (post_id, activity_name, activity_emoji, activity_type, \n",
    "                activity_emotion, predicted_activity_type, predicted_activity_emotion) \n",
    "                VALUES(%s, %s, %s, %s, %s, %s, %s)\n",
    "                \"\"\"\n",
    "                post_id = dct.get('post_id', None)\n",
    "                \n",
    "                check_data = (post_id, activity_name)\n",
    "\n",
    "                insert_data = (dct.get('post_id', None), activity_name, \n",
    "                              activity_emoji, dct.get('activity_type', None), dct.get('activity_emotion', None),\n",
    "                              dct.get('predicted_activity_type', None), dct.get('predicted_activity_emotion', None))\n",
    "            \n",
    "                with connection.cursor() as cursor:\n",
    "                    cursor.execute(use_db_query)\n",
    "                    cursor.execute(check_if_exist, check_data)\n",
    "                    for el in cursor:\n",
    "                        exist = el[0]\n",
    "\n",
    "                    if not exist:\n",
    "                        cursor.execute(upload_posts_table_query, insert_data)\n",
    "                        connection.commit()\n",
    "                        print(f'UPLOADED: activity with post_id:{post_id} and activity_name:{activity_name}')\n",
    "                    else:\n",
    "                        # add overwrite option\n",
    "                        print(f'ERROR: activity with post_id:{post_id} and activity_name:{activity_name} already uploaded')\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "        \n",
    "def update_post(dct):\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            update_posts_table_query = \"\"\"\n",
    "            UPDATE posts SET text = %s, parsed_date = %s,  \n",
    "            upload_date = %s, edit_date = %s, productivity_score = %s,\n",
    "            interest_score = %s, stress_score = %s WHERE post_id = %s\n",
    "            \"\"\"\n",
    "            \n",
    "            data = (dct.get('text', None), \n",
    "                    dct.get('parsed_date', None), dct.get('upload_date', None), \n",
    "                    dct.get('edit_date', None),dct.get('productivity_score', None),\n",
    "                    dct.get('interest_score', None),dct.get('stress_score', None),\n",
    "                   dct.get('post_id', None))\n",
    "\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(update_posts_table_query, data)\n",
    "                connection.commit()\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "def db_show_tables():\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            show_tables = \"SHOW TABLES;\"\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(show_tables)\n",
    "                for el in cursor.fetchall():\n",
    "                    print(el)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "def db_execute_query(query, commit = False):\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(query)\n",
    "                if commit:\n",
    "                    connection.commit()\n",
    "                for el in cursor:\n",
    "                    print(el)\n",
    "    except Error as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7d7a07d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfs\n",
      "(215,) <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "db_test_shit('SELECT activity_id FROM activities WHERE post_id = 721 AND activity_name = \"Hiking with Ann\" LIMIT 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "873817dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n"
     ]
    }
   ],
   "source": [
    "print(get_activity_id(721, 'Hiking with Ann'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bce3ed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "773ffa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('activities',)\n",
      "('posts',)\n"
     ]
    }
   ],
   "source": [
    "db_show_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "64f90490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(215,)\n"
     ]
    }
   ],
   "source": [
    "db_execute_query('SELECT activity_id FROM activities WHERE post_id = 721 AND activity_name = \"Hiking with Ann\" LIMIT 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "364ae810",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_execute_query('DELETE FROM posts WHERE post_id > 0;', commit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cb49bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_execute_query('DROP TABLE posts;', commit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2ca4ad6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(718, '25.07.23\\n\\nAwesome cycling with Anna and her brother \\n\\nLazy work on my project\\n\\nInteresting mathematics lecture before sleep\\n\\nHow productive have you been?: 3.5/10\\nHow interesting was the day?: 6/10\\nHow stressful was the day?: 2/10', datetime.date(2023, 7, 25), datetime.datetime(2023, 7, 26, 13, 32, 45), datetime.datetime(2023, 7, 26, 16, 2, 57), 3.5, 6.0, 2.0, None, None, None)\n",
      "(721, '26.07.23\\n\\nsakisaki Hiking with Ann\\n\\nWorking on my project\\n\\n* Gym \\n\\n* Interesting history lecture \\n\\nHow productive have you been?: 4.5/10\\nHow interesting was the day?: 6/10\\nHow stressful was the day?: 1/10', datetime.date(2023, 7, 26), datetime.datetime(2023, 7, 26, 16, 28, 42), datetime.datetime(2023, 7, 28, 12, 50, 10), 4.5, 6.0, 1.0, None, None, None)\n"
     ]
    }
   ],
   "source": [
    "db_execute_query('SELECT * FROM posts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "7f5c75bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATED: activity with id:9\n"
     ]
    }
   ],
   "source": [
    "update_activity(9, {'activity_name': 'Hiking with Ann'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "cde937c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 721, 'Hiking with Ann', None, 'family', None, None, None)\n",
      "(10, 721, 'Working on my project', None, 'self_development', None, None, None)\n",
      "(11, 721, 'Gym', '*', 'sport_&_health', None, None, None)\n",
      "(12, 721, 'Interesting history lecture', '*', None, None, None, None)\n",
      "(13, 718, 'Awesome cycling with Anna and her brother', None, None, None, None, None)\n",
      "(14, 718, 'Lazy work on my project', None, None, None, None, None)\n",
      "(15, 718, 'Interesting mathematics lecture before sleep', None, None, None, None, None)\n",
      "(16, 715, 'Gym good traning', None, None, None, None, None)\n",
      "(17, 715, 'My project for portfolio do some things', None, None, None, None, None)\n",
      "(18, 715, 'Interesting history lecture', None, None, None, None, None)\n",
      "(19, 712, 'Moving to new flat', None, None, None, None, None)\n",
      "(20, 712, 'Working on my project', None, None, None, None, None)\n",
      "(21, 709, 'Work on my project', None, None, None, None, None)\n",
      "(22, 709, 'Lazy day', None, None, None, None, None)\n",
      "(23, 705, 'Working on my project', None, None, None, None, None)\n",
      "(24, 705, 'Cooking', None, None, None, None, None)\n",
      "(25, 705, 'Evening with Anna family', None, None, None, None, None)\n",
      "(26, 702, 'My project', None, None, None, None, None)\n",
      "(27, 702, 'Household stuff', None, None, None, None, None)\n",
      "(28, 702, 'Movies time spider man awesome cartoon!', None, None, None, None, None)\n",
      "(29, 675, 'Tinkoff final presentation', None, None, None, None, None)\n",
      "(30, 675, 'Little walk in park', None, None, None, None, None)\n",
      "(31, 675, 'Pizza with Anna', None, None, None, None, None)\n",
      "(32, 675, 'Gym', None, None, None, None, None)\n",
      "(33, 675, 'Movie time black mirror', None, None, None, None, None)\n",
      "(34, 671, 'Tinkoff work make presentation  make a report', '*', None, None, None, None)\n",
      "(35, 671, 'Gym', '*', None, None, None, None)\n",
      "(36, 671, 'My project', '*', None, None, None, None)\n",
      "(37, 671, 'Tinkoff meeting', '*', None, None, None, None)\n",
      "(38, 663, 'Quick things packing and household chores', None, None, None, None, None)\n",
      "(39, 663, 'Train trip to St Petersburg', None, None, None, None, None)\n",
      "(40, 663, 'Interesting lecture that make me think about myself stupid', None, None, None, None, None)\n",
      "(41, 663, 'Evening with Ann', None, None, None, None, None)\n",
      "(42, 659, 'Coffee and Hiking with Nikita', None, None, None, None, None)\n",
      "(43, 659, 'Random coffee cool hiking in big park for bicycle', None, None, None, None, None)\n",
      "(44, 656, 'Send avito order', None, None, None, None, None)\n",
      "(45, 656, 'Check tickets and write second letter', None, None, None, None, None)\n",
      "(46, 656, 'Presentation preperation', None, None, None, None, None)\n",
      "(47, 650, 'Tinkoff prepresentation', None, None, None, None, None)\n",
      "(48, 650, 'My project read some articles and search models', None, None, None, None, None)\n",
      "(49, 650, 'Lazy day Phone gaming', None, None, None, None, None)\n",
      "(50, 650, 'Scooter repairing', None, None, None, None, None)\n",
      "(51, 650, 'Trying to sell scooter on avito', None, None, None, None, None)\n",
      "(52, 650, 'Late sleep', None, None, None, None, None)\n",
      "(53, 647, 'Gym', None, None, None, None, None)\n",
      "(54, 647, 'Cycling in rainy day', None, None, None, None, None)\n",
      "(55, 647, 'English speaking lesson', None, None, None, None, None)\n",
      "(56, 647, 'Make presentation for Tinkoff', None, None, None, None, None)\n",
      "(57, 647, 'Late sleep', None, None, None, None, None)\n",
      "(58, 647, 'Avito selling back corrector', None, None, None, None, None)\n",
      "(59, 646, 'Home cleaning', None, None, None, None, None)\n",
      "(60, 646, 'Mentor meeting', None, None, None, None, None)\n",
      "(61, 646, 'My project', None, None, None, None, None)\n",
      "(62, 646, 'English series', None, None, None, None, None)\n",
      "(63, 641, 'Gym', None, None, None, None, None)\n",
      "(64, 641, 'Cleaning', None, None, None, None, None)\n",
      "(65, 641, 'My project', None, None, None, None, None)\n",
      "(66, 641, 'English practice', None, None, None, None, None)\n",
      "(67, 632, 'Meeting tinkoff', None, None, None, None, None)\n",
      "(68, 632, 'Work', None, None, None, None, None)\n",
      "(69, 632, 'Discord with Anna', None, None, None, None, None)\n",
      "(70, 632, 'Discord with mother', None, None, None, None, None)\n",
      "(71, 632, 'Cooking', None, None, None, None, None)\n",
      "(72, 628, 'Awesome hiking 2', None, None, None, None, None)\n",
      "(73, 628, 'Interesting discussion with Foma 2', None, None, None, None, None)\n",
      "(74, 628, 'Delivery of camping equipment with Diana', None, None, None, None, None)\n",
      "(75, 628, 'Rest after hiking', None, None, None, None, None)\n",
      "(76, 624, 'Awesome big hiking', None, None, None, None, None)\n",
      "(77, 624, 'Put up a tent', None, None, None, None, None)\n",
      "(78, 624, 'Cooking on gase grill', None, None, None, None, None)\n",
      "(79, 624, 'Drink vodka with Nikita', None, None, None, None, None)\n",
      "(80, 624, 'Interesting discussion with Foma', None, None, None, None, None)\n",
      "(81, 624, 'Helping people', None, None, None, None, None)\n",
      "(82, 620, 'Preparation for trip!', None, None, None, None, None)\n",
      "(83, 620, 'Evening cycling to grocery', None, None, None, None, None)\n",
      "(84, 620, 'Make presentation for tinkoff', None, None, None, None, None)\n",
      "(85, 616, 'Tinkoff work make presentation', None, None, None, None, None)\n",
      "(86, 616, 'Random coffee awesome hiking', None, None, None, None, None)\n",
      "(87, 612, 'Awesome english speaking practice where we discuss ai technologies and their impact on our life', None, None, None, None, None)\n",
      "(88, 612, 'English speaking with chat bot', None, None, None, None, None)\n",
      "(89, 612, 'Awesome Gym traning in new gym', None, None, None, None, None)\n",
      "(90, 612, 'Late sleep', None, None, None, None, None)\n",
      "(91, 604, 'Laaazy day 2', None, None, None, None, None)\n",
      "(92, 604, 'TikTok', None, None, None, None, None)\n",
      "(93, 604, 'Playing mobile games', None, None, None, None, None)\n",
      "(94, 604, 'Stupid work', None, None, None, None, None)\n",
      "(95, 604, 'Random coffee', None, None, None, None, None)\n",
      "(96, 604, 'Sell victorinox knife', None, None, None, None, None)\n",
      "(97, 600, 'Chilling', None, None, None, None, None)\n",
      "(98, 600, 'Cooking', None, None, None, None, None)\n",
      "(99, 600, 'Lazy day', None, None, None, None, None)\n",
      "(100, 600, 'Nonexisting ozon pickpoint', None, None, None, None, None)\n",
      "(101, 596, 'Awesome hiking', None, None, None, None, None)\n",
      "(102, 596, 'Random coffee', None, None, None, None, None)\n",
      "(103, 591, 'Passed lab works', None, None, None, None, None)\n",
      "(104, 591, 'Spray myself with a paper', None, None, None, None, None)\n",
      "(105, 591, 'Awesome but traumatic box training', None, None, None, None, None)\n",
      "(106, 591, 'Walk Ann to a train', None, None, None, None, None)\n",
      "(107, 588, 'Eat', None, None, None, None, None)\n",
      "(108, 588, 'Relax', None, None, None, None, None)\n",
      "(109, 588, 'Some work', None, None, None, None, None)\n",
      "(110, 584, 'Awesome bike trip!', None, None, None, None, None)\n",
      "(111, 584, 'Warm bath', None, None, None, None, None)\n",
      "(112, 584, 'Lecture about burnout', None, None, None, None, None)\n",
      "(113, 580, 'Hiking with Ann', None, None, None, None, None)\n",
      "(114, 580, 'Order tasty food', None, None, None, None, None)\n",
      "(115, 580, 'Watch awesome cartoon with Ann', None, None, None, None, None)\n",
      "(116, 577, 'Terrible Chemistry exam', None, None, None, None, None)\n",
      "(117, 577, 'Bar hookah and interesting discussions with university mates', None, None, None, None, None)\n",
      "(118, 569, 'Morning in Tver', None, None, None, None, None)\n",
      "(119, 569, 'Trip back to Moscow', None, None, None, None, None)\n",
      "(120, 561, 'Nice optics exam', None, None, None, None, None)\n",
      "(121, 561, 'Time with classmates', None, None, None, None, None)\n",
      "(122, 561, 'News Attempted military coup in the country', None, None, None, None, None)\n",
      "(123, 561, 'Forced trip to Tver', None, None, None, None, None)\n",
      "(124, 560, 'Optics preparation for exam', None, None, None, None, None)\n",
      "(125, 560, 'Cooking burgers', None, None, None, None, None)\n",
      "(126, 560, 'Optics send homeworks', None, None, None, None, None)\n",
      "(127, 555, 'Interesting optics lecture', None, None, None, None, None)\n",
      "(128, 555, 'Cozy time in university room', None, None, None, None, None)\n",
      "(129, 555, 'Tinkoff work', None, None, None, None, None)\n",
      "(130, 552, 'Phone gaming', None, None, None, None, None)\n",
      "(131, 549, 'Tinkoff meeting read article and test assembling methods', '*', None, None, None, None)\n",
      "(132, 549, 'Optics send hm', '*', None, None, None, None)\n",
      "(133, 549, 'IAD send hm', '*', None, None, None, None)\n",
      "(134, 549, 'QM prepare for exam', '*', None, None, None, None)\n",
      "(135, 546, 'Try to recover after burnout 6', None, None, None, None, None)\n",
      "(136, 546, 'Prepare for university exams', None, None, None, None, None)\n",
      "(137, 538, 'Try to recover after burnout 5', None, None, None, None, None)\n",
      "(138, 538, 'Chill with classmates', None, None, None, None, None)\n",
      "(139, 538, 'Hiking', None, None, None, None, None)\n",
      "(140, 534, 'Try to recover after burnout 4', None, None, None, None, None)\n",
      "(141, 534, 'Try to do prepare to university test', None, None, None, None, None)\n",
      "(142, 534, 'Gym', None, None, None, None, None)\n",
      "(143, 530, 'Try to recover after burnout 3', None, None, None, None, None)\n",
      "(144, 530, 'Awesome cycling', None, None, None, None, None)\n",
      "(145, 530, 'Got new international passport!', None, None, None, None, None)\n",
      "(146, 530, 'Picnic on the grass on the sparrow hills in Moscow', None, None, None, None, None)\n",
      "(147, 526, 'Try to recover after burnout 2', None, None, None, None, None)\n",
      "(148, 526, 'Awesome cycling to university', None, None, None, None, None)\n",
      "(149, 520, 'Try to recover after burnout', None, None, None, None, None)\n",
      "(150, 520, 'Awesome cycling in park', None, None, None, None, None)\n",
      "(151, 517, 'Burnout', 'üåãüòµ', None, None, None, None)\n",
      "(152, 517, 'Make list with things todo when you are really tired', '*', None, None, None, None)\n",
      "(153, 517, 'Optics hm', '*', None, None, None, None)\n",
      "(154, 517, 'Quantum mechanics hm', '*', None, None, None, None)\n",
      "(155, 517, 'Tinkoff generation project', '*', None, None, None, None)\n",
      "(156, 517, 'Tinkoff work', '*', None, None, None, None)\n",
      "(157, 514, 'Optics finish 1 lab', 'üìù', None, None, None, None)\n",
      "(158, 514, 'Tinkoff work stack selection methods', 'üíºüë®üèª', None, None, None, None)\n",
      "(159, 514, 'QM lecture', 'üì¶', None, None, None, None)\n",
      "(160, 514, 'NLP in practice code baseline', 'üì¶', None, None, None, None)\n",
      "(161, 510, 'Optics test', 'üìù', None, None, None, None)\n",
      "(162, 510, 'Optics lectures', 'üéíüìñ', None, None, None, None)\n",
      "(163, 510, 'Meeting with mentor', 'üôãüèª', None, None, None, None)\n",
      "(164, 510, 'Tinkoff work', 'üíºüë®üèª', None, None, None, None)\n",
      "(165, 510, 'NLP in practice', 'üì¶', None, None, None, None)\n",
      "(166, 506, 'Tinkoff meeting', 'üíºüí¨', None, None, None, None)\n",
      "(167, 506, 'Optics lectures', 'üéíüìñ', None, None, None, None)\n",
      "(168, 506, 'Write mentor', 'üìùüôãüèº', None, None, None, None)\n",
      "(169, 506, 'Meditation', 'üßòüèº', None, None, None, None)\n",
      "(170, 506, 'NlP in practice watch lectures and get info', 'üë®üèª', None, None, None, None)\n",
      "(171, 506, 'Optics lab work', 'üì¶', None, None, None, None)\n",
      "(172, 506, 'My project build site', 'üì¶', None, None, None, None)\n",
      "(173, 500, 'Tinkoff work', 'üíºüë®üèª', None, None, None, None)\n",
      "(174, 500, 'OAD Deadline', 'üìù', None, None, None, None)\n",
      "(175, 500, 'My project sync data', 'üì¶', None, None, None, None)\n",
      "(176, 500, 'NLP in practice make baseline', 'üì¶', None, None, None, None)\n",
      "(177, 500, 'Optics lectures', 'üì¶', None, None, None, None)\n",
      "(178, 497, 'English podcast', 'üá¨üáßüéô', None, None, None, None)\n",
      "(179, 497, 'Tinkoff work', 'üíºüë®üèª', None, None, None, None)\n",
      "(180, 497, '1 Filter datasets and train models', None, None, None, None, None)\n",
      "(181, 497, '2 Feature filtering  EDA', None, None, None, None, None)\n",
      "(182, 497, '3 Neural network methods', None, None, None, None, None)\n",
      "(183, 497, 'Optics lectures', 'üìñ', None, None, None, None)\n",
      "(184, 497, 'ODS nlp in practice lectures', 'üë®üèª', None, None, None, None)\n",
      "(185, 497, 'My project write django site template', 'üìöüë®üèª', None, None, None, None)\n",
      "(186, 497, 'Quantum mechanics lectures', 'üì¶', None, None, None, None)\n",
      "(187, 497, 'Boxing', 'üì¶', None, None, None, None)\n",
      "(188, 494, 'Tinkoff work', 'üíºüë®üèª', None, None, None, None)\n",
      "(189, 494, 'My project watches video about docker', 'üë®üèª', None, None, None, None)\n",
      "(190, 494, 'ODS nlp in practice lectures', 'üë®üèª', None, None, None, None)\n",
      "(191, 494, 'Optics lecture', 'üì¶', None, None, None, None)\n",
      "(192, 491, 'Pick up my passport', 'üóÉ', None, None, None, None)\n",
      "(193, 491, '–°ycling trip to passport', 'üö¥üèº', None, None, None, None)\n",
      "(194, 491, 'Relax in bath', 'üõÅüí™üèª', None, None, None, None)\n",
      "(195, 491, 'Tinkoff work', 'üíºüë®üèª', None, None, None, None)\n",
      "(196, 491, 'Optics test', 'üìù', None, None, None, None)\n",
      "(197, 491, 'Quantum mechanics hm', 'üìù', None, None, None, None)\n",
      "(198, 491, 'IAD DEADLINE', 'üìù', None, None, None, None)\n",
      "(199, 491, 'NLP lecture', 'üìö', None, None, None, None)\n",
      "(200, 488, 'NLP lecture  conspects', 'üìö', None, None, None, None)\n",
      "(201, 488, 'Register for summer school!!!', 'üìÑ', None, None, None, None)\n",
      "(202, 488, 'Tinkoff work', 'üíºüë®üèª', None, None, None, None)\n",
      "(203, 488, 'OPTICS DEADLINE', 'üì¶', None, None, None, None)\n",
      "(204, 488, 'IAD DEADLINE', 'üì¶', None, None, None, None)\n",
      "(205, 488, 'Quantum mechanics lecture', 'üì¶', None, None, None, None)\n",
      "(206, 488, 'Optics lecture', 'üì¶', None, None, None, None)\n",
      "(207, 485, 'DS exam', 'üìù', None, None, None, None)\n",
      "(208, 485, 'Optics lab', 'ü•º', None, None, None, None)\n",
      "(209, 485, 'Judo competition', 'ü§ºüèÜ', None, None, None, None)\n",
      "(210, 485, 'Opticsqm lecture', 'üì¶', None, None, None, None)\n",
      "(211, 485, 'NLP lecture conspects', 'üì¶', None, None, None, None)\n",
      "(212, 479, 'Tinkoff work variables analysis', 'üíºüë®üèª', None, None, None, None)\n",
      "(213, 479, 'Tinkoff meeting', 'üíºüí¨', None, None, None, None)\n",
      "(214, 479, 'ODS Alfa Bank meetup', 'üë•üí¨', None, None, None, None)\n",
      "(215, 476, 'Tinkoff work test algorytms woth different parametrs', 'üíºüë®üèª', None, None, None, None)\n",
      "(216, 476, 'NLP lecture', 'üìö', None, None, None, None)\n",
      "(217, 476, 'Docs for international passport', 'üëÆüèºüìÑ', None, None, None, None)\n",
      "(218, 476, 'IAD HM', 'üì¶', None, None, None, None)\n",
      "(219, 476, 'Optics lectures', 'üì¶', None, None, None, None)\n",
      "(220, 471, 'IAD HM', '*', None, None, None, None)\n",
      "(221, 471, 'Optics end hm', 'üßæ', None, None, None, None)\n",
      "(222, 471, 'Optics lectures', 'üì¶', None, None, None, None)\n",
      "(223, 471, 'Tinkoff work', None, None, None, None, None)\n",
      "(224, 471, '1 find hyperparametrs for stepwise', 'üíºüë®üèª', None, None, None, None)\n",
      "(225, 471, '2 write program to find best hyperparametrs fastly', None, None, None, None, None)\n",
      "(226, 471, '3 add ideas from boruta to stepwise', None, None, None, None, None)\n",
      "(227, 471, 'Box training', 'ü•ä', None, None, None, None)\n",
      "(228, 471, 'Tinkoff meeting', 'üíºüí¨', None, None, None, None)\n",
      "(229, 442, 'Tinkoff work', 'üíºüë®üèª', None, None, None, None)\n",
      "(230, 442, 'Done my projects', '*', None, None, None, None)\n",
      "(231, 442, 'Send job application', '*', None, None, None, None)\n",
      "(232, 442, 'Start my day analyze project', '*', None, None, None, None)\n",
      "(233, 440, 'End resume project', '*', None, None, None, None)\n",
      "(234, 440, 'Tinkoff work', 'üíºüë®üèª', None, None, None, None)\n",
      "(235, 438, 'End resume project', '*', None, None, None, None)\n",
      "(236, 438, 'Tinkoff work', 'üíºüë®üèª', None, None, None, None)\n",
      "(237, 438, 'Boxing', None, None, None, None, None)\n",
      "(238, 422, 'Sport little workout  box traning', 'ü•ä', None, None, None, None)\n",
      "(239, 422, 'Tinkoff work', None, None, None, None, None)\n",
      "(240, 422, 'Tinkoff generation hm', None, None, None, None, None)\n",
      "(241, 422, 'NLP hm', None, None, None, None, None)\n",
      "(242, 422, 'Meeting with mentor', None, None, None, None, None)\n",
      "(243, 422, 'ODS meeting', None, None, None, None, None)\n",
      "(244, 422, 'Write people about specialization', None, None, None, None, None)\n",
      "(245, 422, 'Write mother', None, None, None, None, None)\n",
      "(246, 422, 'Register on data fest', None, None, None, None, None)\n",
      "(247, 420, 'Boxing', 'ü•ä', None, None, None, None)\n",
      "(248, 420, 'Planning', 'üóì', None, None, None, None)\n",
      "(249, 420, 'Tinkoff work', 'üíºüë®üèª', None, None, None, None)\n",
      "(250, 420, 'Tinkoff lab meeting', 'üíºüí¨', None, None, None, None)\n",
      "(251, 420, 'IAD', 'üìùüë®üèª', None, None, None, None)\n",
      "(252, 420, 'ODS meeting', 'üì¶', None, None, None, None)\n",
      "(253, 420, 'NLP', 'üì¶', None, None, None, None)\n",
      "(254, 420, 'Tinkoww generation hm', 'üì¶', None, None, None, None)\n",
      "(255, 418, 'Teaching specialization exam', 'üìùüë®üèª', None, None, None, None)\n",
      "(256, 418, 'Yandex meeting I won prizes!', 'üíªüôãüèºüôãüèª', None, None, None, None)\n",
      "(257, 418, 'IAD hm', 'üìùüë®üèª', None, None, None, None)\n",
      "(258, 418, 'Cycling and podcast', 'üö¥üèºüéß', None, None, None, None)\n",
      "(259, 414, 'Tinkoff work', 'üíºüë®üèª', None, None, None, None)\n",
      "(260, 414, 'IAD paaarly', 'üìùüë®üèª', None, None, None, None)\n",
      "(261, 414, 'Drinking cidre', 'üç∫ü§ï', None, None, None, None)\n",
      "(262, 411, 'NLP hm paaaartly', 'üìö', None, None, None, None)\n",
      "(263, 411, 'DL seminar', 'üìö', None, None, None, None)\n",
      "(264, 411, 'OAD hm', 'ü§Æ', None, None, None, None)\n",
      "(265, 411, 'IAD hm', 'ü§ï', None, None, None, None)\n",
      "(266, 411, 'Tinkoff work', 'üì¶', None, None, None, None)\n",
      "(267, 411, 'QM hm', 'üì¶', None, None, None, None)\n",
      "(268, 411, 'Ask people about specialization', 'üì¶', None, None, None, None)\n",
      "(269, 408, 'Tinkoff work', 'üíºüë®üèª', None, None, None, None)\n",
      "(270, 408, 'Tinkoff lab meeting', 'üíºüí¨', None, None, None, None)\n",
      "(271, 408, 'Write to mentors', 'üìùüôãüèº', None, None, None, None)\n",
      "(272, 408, 'NLP', 'üì¶', None, None, None, None)\n",
      "(273, 408, 'hm OAD', 'üì¶', None, None, None, None)\n",
      "(274, 406, 'Tinkoff work', 'üíºüë®üèª', None, None, None, None)\n",
      "(275, 406, 'Make holidays recap', 'üéû', None, None, None, None)\n",
      "(276, 406, 'Find mentors and make bio', 'üîçüìë', None, None, None, None)\n",
      "(277, 406, 'Box', 'ü•ä', None, None, None, None)\n",
      "(278, 406, 'NLP seminar', 'üì¶', None, None, None, None)\n",
      "(279, 406, 'ODS', 'üì¶', None, None, None, None)\n",
      "(280, 406, 'Optics', 'üì¶', None, None, None, None)\n",
      "(281, 403, 'Apply for job', 'üíºüóí', None, None, None, None)\n",
      "(282, 403, 'NLP lectureseminarhmproject', 'üìö', None, None, None, None)\n",
      "(283, 403, 'NLP seminar', 'üìö', None, None, None, None)\n",
      "(284, 403, 'English podcasts', 'üá¨üáßüéô', None, None, None, None)\n",
      "(285, 403, 'English lesson', 'üá¨üáßüó£', None, None, None, None)\n",
      "(286, 403, 'Boxing', 'ü•ä', None, None, None, None)\n",
      "(287, 403, 'Optics lecture', 'üì¶', None, None, None, None)\n",
      "(288, 403, 'History lecture', 'üì¶', None, None, None, None)\n",
      "(289, 403, 'Tinkoff lab work', 'üì¶', None, None, None, None)\n",
      "(290, 399, 'NLP seminar', 'üìö', None, None, None, None)\n",
      "(291, 399, 'Tinkoff work', 'üíºüë®üèª', None, None, None, None)\n",
      "(292, 399, 'Repair everything', None, None, None, None, None)\n",
      "(293, 399, 'My project', 'üì¶', None, None, None, None)\n",
      "(294, 399, 'NLP lecture', 'üì¶', None, None, None, None)\n",
      "(295, 399, 'Optics', 'üì¶', None, None, None, None)\n",
      "(296, 397, 'NLP lecture', 'üìö', None, None, None, None)\n",
      "(297, 397, 'NLP seminar partly', 'üìö', None, None, None, None)\n",
      "(298, 397, 'Bike repair', 'üö≤', None, None, None, None)\n",
      "(299, 397, 'Go ozon', 'üõí', None, None, None, None)\n",
      "(300, 397, 'Tinkoff lab work partly', 'üíºüë®üèª', None, None, None, None)\n",
      "(301, 397, 'Sport pull ups', 'üí™üèª', None, None, None, None)\n",
      "(302, 397, 'Algoritms', 'üì¶', None, None, None, None)\n",
      "(303, 395, 'Boxing', 'ü•ä', None, None, None, None)\n",
      "(304, 395, 'NLP seminar', 'üìö', None, None, None, None)\n",
      "(305, 395, 'NLP lecture', 'üìö', None, None, None, None)\n",
      "(306, 395, 'Tinkoff lab work', 'üíºüë®üèª', None, None, None, None)\n",
      "(307, 395, 'Some math tasks', 'üìù', None, None, None, None)\n",
      "(308, 395, 'History lectures', 'üì¶', None, None, None, None)\n",
      "(309, 392, 'NLP lecture partly', 'üìö', None, None, None, None)\n",
      "(310, 392, 'NLP seminar partly', 'üìö', None, None, None, None)\n",
      "(311, 392, 'Cinema', 'üì∫', None, None, None, None)\n",
      "(312, 392, 'Swimming', 'üì¶', None, None, None, None)\n",
      "(313, 392, 'ML 2 sharp values lecture', 'üì¶', None, None, None, None)\n",
      "(314, 387, 'Tinkoff lab working', 'üíºüë®üèª', None, None, None, None)\n",
      "(315, 387, 'Tinkoff lab meeting', 'üíºüí¨', None, None, None, None)\n",
      "(316, 387, 'NLP notes  lecture', 'üìö', None, None, None, None)\n",
      "(317, 387, 'Planning', 'üóì', None, None, None, None)\n",
      "(318, 387, 'My pet project make dashboards for day monitoring', 'üì¶', None, None, None, None)\n",
      "(319, 387, 'History lecture', 'üì¶', None, None, None, None)\n",
      "(320, 377, 'Picnic in the country', 'üçΩüèïü•©', None, None, None, None)\n",
      "(321, 377, 'NLP reading notes', 'üìö', None, None, None, None)\n",
      "(322, 377, 'Interesting history lecture', 'üì∫üßë', None, None, None, None)\n",
      "(323, 369, 'Tinkoff work', None, None, None, None, None)\n",
      "(324, 369, 'DL lecture partly', None, None, None, None, None)\n",
      "(325, 369, 'Running traning', None, None, None, None, None)\n",
      "(326, 369, 'Cycling with Anna', None, None, None, None, None)\n",
      "(327, 367, 'Tinkoff lab work', None, None, None, None, None)\n",
      "(328, 367, 'Tinkoff lab meeting', None, None, None, None, None)\n",
      "(329, 367, 'Interesting history lecture', None, None, None, None, None)\n",
      "(330, 367, 'Sell skateboard', None, None, None, None, None)\n",
      "(331, 363, 'Visited Moscow zoo', None, None, None, None, None)\n",
      "(332, 363, 'Cycling', None, None, None, None, None)\n",
      "(333, 363, 'Dl lecture partly', None, None, None, None, None)\n",
      "(334, 350, 'Cycling', None, None, None, None, None)\n",
      "(335, 350, 'Tinkoff lab work', None, None, None, None, None)\n",
      "(336, 350, 'DL Adrey Korpaty video', None, None, None, None, None)\n",
      "(337, 350, 'ML competitional course', None, None, None, None, None)\n",
      "(338, 348, 'ML recsys competition send solutions late', None, None, None, None, None)\n",
      "(339, 348, 'New cool bike unboxing and assembling!', None, None, None, None, None)\n",
      "(340, 339, 'Tinkoff lab working', 'üíºüë®üèª', None, None, None, None)\n",
      "(341, 339, 'Tinkoff lab meeting', 'üíºüí¨', None, None, None, None)\n",
      "(342, 339, 'Go to the Georgian restaurant with Ann', None, None, None, None, None)\n",
      "(343, 336, 'Send documents to mother', 'üì®', None, None, None, None)\n",
      "(344, 336, 'Tinkoff lab work', 'üíºüë®üèª', None, None, None, None)\n",
      "(345, 336, 'Boxing traning', None, None, None, None, None)\n",
      "(346, 336, 'Quantum mechanics hm', 'üìù', None, None, None, None)\n",
      "(347, 336, 'Rec sys lectures', 'üì¶', None, None, None, None)\n",
      "(348, 334, 'Rec sys seminar', 'üìö', None, None, None, None)\n",
      "(349, 334, 'Tinkoff lab work', 'üíºüë®üèª', None, None, None, None)\n",
      "(350, 334, 'Go to the restaurant with Ann', None, None, None, None, None)\n",
      "(351, 331, 'Rec sys seminar', 'üìö', None, None, None, None)\n",
      "(352, 331, 'Tinkoff lab work', 'üì¶', None, None, None, None)\n",
      "(353, 331, 'Data dojo', 'üë®üèª', None, None, None, None)\n",
      "(354, 329, 'Matphys control work', 'üìù', None, None, None, None)\n",
      "(355, 329, 'Recsys lecture', 'üìö', None, None, None, None)\n",
      "(356, 329, 'Cycling', None, None, None, None, None)\n",
      "(357, 329, 'Tinkoff work', 'üì¶', None, None, None, None)\n",
      "(358, 326, 'Tinkoff lab working', 'üíºüë®üèª', None, None, None, None)\n",
      "(359, 326, 'Tinkoff lab meeting', 'üíºüí¨', None, None, None, None)\n",
      "(360, 326, 'Mathematical physics preparation for control work', 'üìù', None, None, None, None)\n",
      "(361, 326, 'OAD pass hm', 'üìù', None, None, None, None)\n",
      "(362, 326, 'Rec sys lectures', 'üì¶', None, None, None, None)\n",
      "(363, 324, 'Rec sys lecture', None, None, None, None, None)\n",
      "(364, 324, 'Mathematical physics prepare for test', None, None, None, None, None)\n",
      "(365, 324, 'IAD  OAD deadlines', None, None, None, None, None)\n",
      "(366, 324, 'Tinkoff lab work', None, None, None, None, None)\n",
      "(367, 322, 'Tinkoff work', 'üíºüë®üèª', None, None, None, None)\n",
      "(368, 322, 'Tinkoff lab meeting', 'üíºüí¨', None, None, None, None)\n",
      "(369, 322, 'Psycholigost', 'üßëüèº', None, None, None, None)\n",
      "(370, 322, 'Tea with neighbor', None, None, None, None, None)\n",
      "(371, 320, 'Quantum mechanics lecture  hm', 'üìù', None, None, None, None)\n",
      "(372, 320, 'Hospital check', 'üè•', None, None, None, None)\n",
      "(373, 320, 'Tinkoff work', 'üíºüë®üèª', None, None, None, None)\n",
      "(374, 320, 'DL seminar', 'üì¶', None, None, None, None)\n",
      "(375, 320, 'DL homework', 'üì¶', None, None, None, None)\n",
      "(376, 318, 'Optics lab passing', 'üìù', None, None, None, None)\n",
      "(377, 318, 'DL hm', 'üìö', None, None, None, None)\n",
      "(378, 318, 'Tinkoff hm', 'üìö', None, None, None, None)\n",
      "(379, 318, 'Tinkoff work', None, None, None, None, None)\n",
      "(380, 318, 'Reading Harry Potter and methods of rationality', 'üì¶', None, None, None, None)\n",
      "(381, 316, 'Sport martial art', 'üí™üèªü•ä', None, None, None, None)\n",
      "(382, 316, 'DL lecture', 'üìö', None, None, None, None)\n",
      "(383, 316, 'DL hm', 'üìö', None, None, None, None)\n",
      "(384, 316, 'Talk with mother', 'üë©', None, None, None, None)\n",
      "(385, 316, 'Optics lecture', 'üì¶', None, None, None, None)\n",
      "(386, 316, 'Tinkoff hm', 'üì¶', None, None, None, None)\n",
      "(387, 316, 'Tinkoff work', 'üì¶', None, None, None, None)\n",
      "(388, 316, 'Reading Harry Potter and methods of rationality', 'üì¶', None, None, None, None)\n",
      "(389, 314, 'IAD  Tinkoff finish homework', 'üìù', None, None, None, None)\n",
      "(390, 314, 'DL Lecture', 'üìö', None, None, None, None)\n",
      "(391, 314, 'Sport martial art', 'üì¶', None, None, None, None)\n",
      "(392, 314, 'DL hm', 'üì¶', None, None, None, None)\n",
      "(393, 314, 'Optics prepare laboratory work notes', 'üì¶', None, None, None, None)\n",
      "(394, 314, 'Cartoon', 'üì¶', None, None, None, None)\n",
      "(395, 312, 'Tinkoff lab fix stepwise selection and code backward and forward', 'üíºüë®üèª', None, None, None, None)\n",
      "(396, 312, 'Tinkoff lab meeting', 'üíºüí¨', None, None, None, None)\n",
      "(397, 312, 'IAD  Tinkoff generation HM', 'üìù', None, None, None, None)\n",
      "(398, 312, 'Mathematical physics seminar', 'üßëüèª', None, None, None, None)\n",
      "(399, 312, 'Evening cartoon', None, None, None, None, None)\n",
      "(400, 312, 'Yandex coderun solve one task', 'üì¶', None, None, None, None)\n",
      "(401, 312, 'DL seminar', 'üì¶', None, None, None, None)\n",
      "(402, 312, 'DL hm', 'üì¶', None, None, None, None)\n",
      "(403, 310, 'Tinkoff lab coding stepwise selection', 'üíºüë®üèª', None, None, None, None)\n",
      "(404, 310, 'Yandex intern week one task', 'üßëüèª', None, None, None, None)\n",
      "(405, 310, 'Sport martial art', 'üí™üèªü•ä', None, None, None, None)\n",
      "(406, 308, 'Tinkoff ml lab write two algorithms', 'üíºüë®üèª', None, None, None, None)\n",
      "(407, 308, 'DL cs224n lecture on RNN', 'üìö', None, None, None, None)\n",
      "(408, 308, 'DL IAD lecture', None, None, None, None, None)\n",
      "(409, 308, 'DL homework', None, None, None, None, None)\n",
      "(410, 308, 'Mathematical physics seminar', None, None, None, None, None)\n",
      "(411, 308, 'English read article  watched interview', 'üá¨üáß', None, None, None, None)\n",
      "(412, 308, 'Sport running 5 km', 'üí™üèªüèÉüèª', None, None, None, None)\n",
      "(413, 294, 'DL seminar partly', 'üìö', None, None, None, None)\n",
      "(414, 294, 'DL IAD lecture batchnorm', 'üìö', None, None, None, None)\n",
      "(415, 294, 'Yandex intern week two tasks', 'üßëüèª', None, None, None, None)\n",
      "(416, 294, 'Tinkoff lab meeting  work  NDA making', 'üíºüí¨', None, None, None, None)\n",
      "(417, 294, 'Cleaning the room', 'üßπ', None, None, None, None)\n",
      "(418, 290, 'Physics Optics Lab we have done work only at 3 pm it was really stupid and boring things', 'ü§ï', None, None, None, None)\n",
      "(419, 290, 'DL watched some lectures', 'üìö', None, None, None, None)\n",
      "(420, 288, 'Metting with Anastasia', 'üë®üèª', None, None, None, None)\n",
      "(421, 288, 'Tinkoff lab do some work', 'üíº', None, None, None, None)\n",
      "(422, 288, 'DL lecture', 'üìö', None, None, None, None)\n",
      "(423, 286, 'Tinkoff lab team meeting', 'üë®üèª', None, None, None, None)\n",
      "(424, 286, 'Dl homework', 'üìö', None, None, None, None)\n",
      "(425, 286, 'DL lecture', 'üìö', None, None, None, None)\n",
      "(426, 286, 'Sport running', 'üí™üèªüèÉüèª', None, None, None, None)\n",
      "(427, 284, 'Did not find team for HSE hackaton', 'üë®', None, None, None, None)\n",
      "(428, 284, 'ODS random coffee with Roman', 'üíÅüèº', None, None, None, None)\n",
      "(429, 284, 'DL semianr', 'üìö', None, None, None, None)\n",
      "(430, 282, 'DL Hm', 'üìö', None, None, None, None)\n",
      "(431, 282, 'DL Lecture', 'üìö', None, None, None, None)\n",
      "(432, 282, 'Anya arrival', None, None, None, None, None)\n",
      "(433, 280, 'Sport Judo training', 'üí™ü§º', None, None, None, None)\n",
      "(434, 280, 'DL Lecture  seminar', 'üìö', None, None, None, None)\n",
      "(435, 278, 'Diggerential geometry lecture  hm', 'üìö', None, None, None, None)\n",
      "(436, 278, 'Deep learning seminar 1', 'üìö', None, None, None, None)\n",
      "(437, 278, 'MIPT and Dolgoprudny excursion', 'üíÅüèº', None, None, None, None)\n",
      "(438, 276, 'Flat cleaning   healthcareer podcast', 'üßπ', None, None, None, None)\n",
      "(439, 276, 'Deep Learning lecture', 'üìö', None, None, None, None)\n",
      "(440, 273, 'Quantum mechanics lectures', 'üìñ', None, None, None, None)\n",
      "(441, 273, 'Gym', 'üí™üèãüèª', None, None, None, None)\n",
      "(442, 273, 'Network with groupmates', 'üíÅüèº', None, None, None, None)\n",
      "(443, 267, 'ML lecture', None, None, None, None, None)\n",
      "(444, 267, 'Movies time', None, None, None, None, None)\n",
      "(445, 263, 'Took Anna by train', None, None, None, None, None)\n",
      "(446, 263, 'Ml lecture', None, None, None, None, None)\n",
      "(447, 247, 'Relaxday', None, None, None, None, None)\n",
      "(448, 247, 'Chemistry exam', None, None, None, None, None)\n",
      "(449, 247, 'Awesome time with Anna we hiked  bought some clothes and visited mate club', None, None, None, None, None)\n",
      "(450, 247, 'Failed laptop repair', None, None, None, None, None)\n",
      "(451, 245, 'Sport pullup', None, None, None, None, None)\n",
      "(452, 245, 'ML boosting seminar', None, None, None, None, None)\n",
      "(453, 245, 'ML clusterization lecture', None, None, None, None, None)\n",
      "(454, 245, 'ML PCA seminar', None, None, None, None, None)\n",
      "(455, 245, 'ML boosting practice', None, None, None, None, None)\n",
      "(456, 245, 'ML PCA', None, None, None, None, None)\n",
      "(457, 245, 'IAD hm', '*', None, None, None, None)\n",
      "(458, 245, 'Chemistry prepare for exams', None, None, None, None, None)\n",
      "(459, 245, 'English do some tasks', None, None, None, None, None)\n",
      "(460, 245, 'Laptop repair', None, None, None, None, None)\n",
      "(461, 243, 'ML boosting lecture', None, None, None, None, None)\n",
      "(462, 243, 'ML boosting seminar', None, None, None, None, None)\n",
      "(463, 243, 'ML PCA', None, None, None, None, None)\n",
      "(464, 243, 'English exams', None, None, None, None, None)\n",
      "(465, 243, 'QM hm', None, None, None, None, None)\n",
      "(466, 241, 'MIPT seminar', None, None, None, None, None)\n",
      "(467, 241, 'Tinkoff hm', '*', None, None, None, None)\n",
      "(468, 241, 'ML finish hm classification', None, None, None, None, None)\n",
      "(469, 241, 'ML start hm boosting', None, None, None, None, None)\n",
      "(470, 241, 'QM lectures', None, None, None, None, None)\n",
      "(471, 241, 'Statistics witn Anna', None, None, None, None, None)\n",
      "(472, 239, 'Chemistry read 3 lecture notes', None, None, None, None, None)\n",
      "(473, 239, 'Google sheet sync with python daily stats plotter', None, None, None, None, None)\n",
      "(474, 239, 'Sport pull the bar pullup', None, None, None, None, None)\n",
      "(475, 239, 'Eng some tasks', None, None, None, None, None)\n",
      "(476, 239, 'Tinkoff hm', '*', None, None, None, None)\n",
      "(477, 239, 'ML hm', None, None, None, None, None)\n",
      "(478, 235, 'Qm hm 8', None, None, None, None, None)\n",
      "(479, 235, 'ML HM4', '*', None, None, None, None)\n",
      "(480, 235, 'Tinkoff ml hm', '*', None, None, None, None)\n",
      "(481, 235, 'print notes for chemistry', '*', None, None, None, None)\n",
      "(482, 235, '160323', None, None, None, None, None)\n",
      "(483, 235, 'Ubuntu setup', None, None, None, None, None)\n",
      "(484, 235, 'English', None, None, None, None, None)\n",
      "(485, 235, 'QM hm 67', None, None, None, None, None)\n",
      "(486, 235, 'Coffee make me alive!', None, None, None, None, None)\n",
      "(487, 235, 'How productive have you been 510', None, None, None, None, None)\n",
      "(488, 235, 'How interesting was the day 510', None, None, None, None, None)\n",
      "(489, 235, 'How stressful was the day 010', None, None, None, None, None)\n",
      "(490, 216, 'Quantum mechanics lecture', None, None, None, None, None)\n",
      "(491, 216, 'Quantum mechanics seminar', '*', None, None, None, None)\n",
      "(492, 216, 'English', None, None, None, None, None)\n",
      "(493, 216, 'Statistics lecture 8', None, None, None, None, None)\n",
      "(494, 216, 'Weekly recap video maker', '*', None, None, None, None)\n",
      "(495, 216, 'Budget planner', '*', None, None, None, None)\n",
      "(496, 214, 'Quantum mechanics lecture', '*', None, None, None, None)\n",
      "(497, 214, 'Quantum mechanics seminar', '*', None, None, None, None)\n",
      "(498, 214, 'Statistics lecture 7', None, None, None, None, None)\n",
      "(499, 214, 'Statistics  seminar 7', None, None, None, None, None)\n",
      "(500, 214, 'ML lecture Bagging random forest', None, None, None, None, None)\n",
      "(501, 214, 'Write letter to hse manager', None, None, None, None, None)\n",
      "(502, 214, 'English write essays use chat GPT', None, None, None, None, None)\n",
      "(503, 214, '–ü—Ä–∞–≤–æ —Ç–µ—Å—Ç–∏–∫–∏', None, None, None, None, None)\n",
      "(504, 212, 'Tinkoff ML HM', None, None, None, None, None)\n",
      "(505, 212, 'ML Lecture bias variance decompose', None, None, None, None, None)\n",
      "(506, 212, 'MIPT differential geometry', None, None, None, None, None)\n",
      "(507, 212, 'Quantum mechanics lecture  seminar', '*', None, None, None, None)\n",
      "(508, 210, 'Chemistry labs 14', None, None, None, None, None)\n",
      "(509, 210, 'English pass homeworks', None, None, None, None, None)\n",
      "(510, 210, 'Quantum mechanics', None, None, None, None, None)\n",
      "(511, 208, 'Statistics lecture', None, None, None, None, None)\n",
      "(512, 208, 'ML decision trees lecture', None, None, None, None, None)\n",
      "(513, 208, 'ML decision trees seminar', None, None, None, None, None)\n",
      "(514, 206, 'MTS school NLP seminar', None, None, None, None, None)\n",
      "(515, 206, 'IAD HM', 'üìö', None, None, None, None)\n",
      "(516, 206, 'Statistics lecture', None, None, None, None, None)\n",
      "(517, 206, 'ML decision trees lecture', 'üìö', None, None, None, None)\n",
      "(518, 206, 'English pass homeworks', 'ü§ï', None, None, None, None)\n",
      "(519, 204, 'Tinkoff generation ml i have been doing this homework all day plot graphs with plotly i think that Ive been doing it for too long', None, None, None, None, None)\n",
      "(520, 204, 'Rick and Morty 1 series how did I watch it before now it reminds me of some stupid teen cartoon', None, None, None, None, None)\n",
      "(521, 204, 'Series with Ann The last of us ep4', None, None, None, None, None)\n",
      "(522, 202, 'MTS school it was really interesting the atmosphere was cozy lecturer told about his experiense in data science', None, None, None, None, None)\n",
      "(523, 202, 'Tinkoff generation ML do hm', None, None, None, None, None)\n",
      "(524, 202, 'Im getting sick', None, None, None, None, None)\n",
      "(525, 202, 'The last of us ep3', None, None, None, None, None)\n",
      "(526, 170, 'MTS ML registrate', None, None, None, None, None)\n",
      "(527, 170, 'QM hm', None, None, None, None, None)\n",
      "(528, 170, 'QM seminar', None, None, None, None, None)\n",
      "(529, 170, 'Tinkoff tasks', 'üìö', None, None, None, None)\n",
      "(530, 170, 'ML HM', 'üìö', None, None, None, None)\n",
      "(531, 170, 'Correct my antiplagiasm project', 'üìö', None, None, None, None)\n",
      "(532, 170, 'Add my mlhm to github', 'üìÑ', None, None, None, None)\n",
      "(533, 166, 'Download mentor programs and choose one link', 'üîé', None, None, None, None)\n",
      "(534, 166, 'MTS ML registrate', 'üîé', None, None, None, None)\n",
      "(535, 166, 'Statistics lecture linear regression', 'üìö', None, None, None, None)\n",
      "(536, 166, 'Tinkoff tasks', 'üìö', None, None, None, None)\n",
      "(537, 166, 'ML HM', 'üìö', None, None, None, None)\n",
      "(538, 166, 'Stats HM', 'üìö', None, None, None, None)\n",
      "(539, 166, 'Correct my antiplagiasm project', 'üìÑ', None, None, None, None)\n",
      "(540, 166, 'Add my mlhm to github', 'üìÑ', None, None, None, None)\n",
      "(541, 164, 'Download mentor programs and choose one link', 'üîé', None, None, None, None)\n",
      "(542, 164, 'Statistics lecture linear regression', 'üìö', None, None, None, None)\n",
      "(543, 164, 'Statistics seminar link', 'üìö', None, None, None, None)\n",
      "(544, 164, 'ML lecture', 'üìö', None, None, None, None)\n",
      "(545, 164, 'ML hm', 'üìö', None, None, None, None)\n",
      "(546, 164, 'Tinkoff tasks', 'üìö', None, None, None, None)\n",
      "(547, 164, 'Boxing 1900', 'ü•ä', None, None, None, None)\n",
      "(548, 162, 'Friday', 'üö©', None, None, None, None)\n",
      "(549, 162, 'English finish tests please', 'üéí', None, None, None, None)\n",
      "(550, 162, 'Chemistry make two reports', 'üéí', None, None, None, None)\n",
      "(551, 162, 'Statistics lecture hypothesis testing', 'üìö', None, None, None, None)\n",
      "(552, 162, 'Statistics lecture linear regression', 'üìö', None, None, None, None)\n",
      "(553, 162, 'ML seminar link', 'üìö', None, None, None, None)\n",
      "(554, 162, 'ML hm', 'üìö', None, None, None, None)\n",
      "(555, 157, 'Thursday', 'üö©', None, None, None, None)\n",
      "(556, 157, 'Successfully skipped English', 'ü§™', None, None, None, None)\n",
      "(557, 157, 'English finish tests please', 'üéí', None, None, None, None)\n",
      "(558, 157, 'Statistics lecture', 'üìö', None, None, None, None)\n",
      "(559, 157, 'Minor ML hm DEADLINE', 'üìö', None, None, None, None)\n",
      "(560, 157, 'ML seminar', 'üìö', None, None, None, None)\n",
      "(561, 157, 'Boxing it was an awesome workout Ive been practicing punches with cool guy a cool guy who showed me the basics of boxing', 'ü•ä', None, None, None, None)\n",
      "(562, 157, 'ML HM', 'üìö', None, None, None, None)\n",
      "(563, 157, 'Remind mom about booking', 'üôã', None, None, None, None)\n",
      "(564, 155, 'Passport', None, None, None, None, None)\n",
      "(565, 155, 'Time series lecture I have been looking for good lecture so long and because of this i cant concentrate', None, None, None, None, None)\n",
      "(566, 155, 'Time series tasks', None, None, None, None, None)\n",
      "(567, 155, 'English!', '*', None, None, None, None)\n",
      "(568, 155, 'ML hm', '*', None, None, None, None)\n",
      "(569, 155, 'ML seminar', '*', None, None, None, None)\n",
      "(570, 155, 'Stats lecture', None, None, None, None, None)\n",
      "(571, 155, 'Me and Anna listened interesting interview with Sergey Guriev about the current economy in Russia Also i was really surprised when i knew that hes from Vladikavkaz', '*', None, None, None, None)\n",
      "(572, 153, 'Quantum mechanics hm', None, None, None, None, None)\n",
      "(573, 153, 'Tinkoff hm', None, None, None, None, None)\n",
      "(574, 153, 'Good rest with Anna we watched The Last of Us and ate pizza', None, None, None, None, None)\n",
      "(575, 149, 'Sport my first martial art training 5 years after retiring from judo  that was really good', None, None, None, None, None)\n",
      "(576, 149, 'Quantum mechanics hm', None, None, None, None, None)\n",
      "(577, 147, 'Apply for a internationalabroad  passport', '*', None, None, None, None)\n",
      "(578, 147, 'ML hm', None, None, None, None, None)\n",
      "(579, 147, 'Stats lecture  hm', None, None, None, None, None)\n",
      "(580, 147, 'QM hm', '*', None, None, None, None)\n",
      "(581, 147, 'Choose project mipt', '*', None, None, None, None)\n",
      "(582, 147, 'Talk with a guy from ozon', '*', None, None, None, None)\n",
      "(583, 144, 'Sport morning excercise', None, None, None, None, None)\n",
      "(584, 144, 'Clear telegram channels', '*', None, None, None, None)\n",
      "(585, 144, 'Watch the rest of the lecture and seminar on Ml', None, None, None, None, None)\n",
      "(586, 144, 'ML hm', '*', None, None, None, None)\n",
      "(587, 144, 'Stats lecture  hm', None, None, None, None, None)\n",
      "(588, 143, 'book a haircut', None, None, None, None, None)\n",
      "(589, 143, 'ML lecture', None, None, None, None, None)\n",
      "(590, 143, 'ML seminar', None, None, None, None, None)\n",
      "(591, 143, 'Stats hm', None, None, None, None, None)\n",
      "(592, 143, 'Online meeting with sister', None, None, None, None, None)\n",
      "(593, 143, 'Edit my sport channel', None, None, None, None, None)\n",
      "(594, 143, 'Chemistry', None, None, None, None, None)\n",
      "(595, 142, 'Stats lecture', None, None, None, None, None)\n",
      "(596, 142, 'Sport gym', None, None, None, None, None)\n",
      "(597, 142, 'Stats hm', None, None, None, None, None)\n",
      "(598, 142, 'ML hm', None, None, None, None, None)\n",
      "(599, 142, 'OAD hm', None, None, None, None, None)\n",
      "(600, 142, 'Recover my metro student card', None, None, None, None, None)\n",
      "(601, 141, 'English', None, None, None, None, None)\n",
      "(602, 141, 'Tinkoff hm', None, None, None, None, None)\n",
      "(603, 141, 'Stats lecture', None, None, None, None, None)\n",
      "(604, 141, 'Stats hm', None, None, None, None, None)\n",
      "(605, 141, 'ML hm', None, None, None, None, None)\n",
      "(606, 141, 'Recover my metro student card', None, None, None, None, None)\n",
      "(607, 140, 'Quantum mechanics hm', None, None, None, None, None)\n",
      "(608, 140, 'Tinkoff hm', None, None, None, None, None)\n",
      "(609, 140, 'Stats lecture', None, None, None, None, None)\n",
      "(610, 140, 'Ml seminar  theory', None, None, None, None, None)\n",
      "(611, 140, 'ML Lecture 30 min', None, None, None, None, None)\n",
      "(612, 139, 'Tinkoff lecture', None, None, None, None, None)\n",
      "(613, 139, 'Quantum physics  hm', None, None, None, None, None)\n",
      "(614, 139, 'Stats Lecture', None, None, None, None, None)\n",
      "(615, 139, 'Stats hm', None, None, None, None, None)\n",
      "(616, 139, 'ML Lecture', None, None, None, None, None)\n",
      "(617, 137, 'Gym', None, None, None, None, None)\n",
      "(618, 137, 'Meditation', None, None, None, None, None)\n",
      "(619, 137, 'Series', None, None, None, None, None)\n",
      "(620, 137, 'ML HM1 15 h', None, None, None, None, None)\n",
      "(621, 137, 'ML Seminar 3 h', None, None, None, None, None)\n",
      "(622, 137, 'Stats hm 4', None, None, None, None, None)\n",
      "(623, 137, 'Pandas', None, None, None, None, None)\n",
      "(624, 137, 'English', None, None, None, None, None)\n",
      "(625, 135, 'Sport morning exercise', None, None, None, None, None)\n",
      "(626, 135, 'Optics Lecture score 1 time 70 min', None, None, None, None, None)\n",
      "(627, 135, 'Optice HM score 1 time 120 number of distractions inf', None, None, None, None, None)\n",
      "(628, 135, 'Stats HM score 2 time  number of distractions', None, None, None, None, None)\n",
      "(629, 135, 'Pandas score 15', None, None, None, None, None)\n",
      "(630, 135, 'ML HM score 1 time 60 min', None, None, None, None, None)\n",
      "(631, 133, 'Wiping with cold water', None, None, None, None, None)\n",
      "(632, 133, 'Morning exercise', None, None, None, None, None)\n",
      "(633, 133, 'Find interesting courses in Steklov university', None, None, None, None, None)\n",
      "(634, 133, 'Studywork', None, None, None, None, None)\n",
      "(635, 133, 'Optics lectures score 1 30 –º–∏–Ω', None, None, None, None, None)\n",
      "(636, 133, 'English practice with chatGTP or watch some videos score 05', None, None, None, None, None)\n",
      "(637, 133, 'ML 1 lecture score 1 60 –º–∏–Ω', None, None, None, None, None)\n",
      "(638, 133, 'ML 1  hm score 15', None, None, None, None, None)\n",
      "(639, 133, 'Statistics lecture score 15 180 –º–∏–Ω', None, None, None, None, None)\n",
      "(640, 133, 'Statistics hm score 20', None, None, None, None, None)\n",
      "(641, 132, 'Wiping with cold water', None, None, None, None, None)\n",
      "(642, 132, 'Morning exercise', None, None, None, None, None)\n",
      "(643, 132, 'Find interesting courses in Steklov university', None, None, None, None, None)\n",
      "(644, 132, 'English do graded hm assessment', None, None, None, None, None)\n",
      "(645, 132, 'English practice with chatGTP or watch some videos', '*', None, None, None, None)\n",
      "(646, 132, 'ML minor HM', None, None, None, None, None)\n",
      "(647, 132, 'ML 1 lecture  hm', None, None, None, None, None)\n",
      "(648, 132, 'Statistics lecture  hm', None, None, None, None, None)\n",
      "(649, 132, 'Hiking', None, None, None, None, None)\n",
      "(650, 132, 'Discuss my day with Anna at evening', None, None, None, None, None)\n",
      "(651, 129, 'Wiping with cold water', None, None, None, None, None)\n",
      "(652, 129, 'Sport morning exercise', None, None, None, None, None)\n",
      "(653, 129, 'Quantum physics HM', None, None, None, None, None)\n",
      "(654, 129, 'English!', None, None, None, None, None)\n",
      "(655, 129, 'Tinkoff HM2', None, None, None, None, None)\n",
      "(656, 129, 'Statistics lecture  hm', None, None, None, None, None)\n",
      "(657, 128, 'Wiping with cold water', None, None, None, None, None)\n",
      "(658, 128, 'Sport morning exercise', None, None, None, None, None)\n",
      "(659, 128, 'Tinkoff HM2', None, None, None, None, None)\n",
      "(660, 128, 'Quantum physics HM', None, None, None, None, None)\n",
      "(661, 128, 'Statistics hm  lecture', None, None, None, None, None)\n",
      "(662, 128, 'English try to start do some tasks from homework', None, None, None, None, None)\n",
      "(663, 128, 'Make company list and find interesting job openings', None, None, None, None, None)\n",
      "(664, 127, 'Statistics seminar', None, None, None, None, None)\n",
      "(665, 127, 'TInkoff HM smashed it! i didt suppose that it will be not that easy', None, None, None, None, None)\n",
      "(666, 127, 'Quantum physics HM', None, None, None, None, None)\n",
      "(667, 127, 'Make plans for month and plans for week', None, None, None, None, None)\n",
      "(668, 127, 'still recovering from lack of sleep', None, None, None, None, None)\n",
      "(669, 126, 'Slept for 6 hours in the morning i have visited  my university and then i didn nothing i was really tired and sleepy I have make i little nap but it didnt help', None, None, None, None, None)\n",
      "(670, 125, 'Statistics HM', None, None, None, None, None)\n",
      "(671, 125, 'Tinkoff HM first two tasks', None, None, None, None, None)\n",
      "(672, 125, 'Send a request for mentoring programm', None, None, None, None, None)\n"
     ]
    }
   ],
   "source": [
    "db_execute_query('SELECT * FROM activities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e98aed0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2026"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "datetime.date(2026, 7, 23).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2e0762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'sex':2, 'me': 5} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec5622b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('sex', 2), ('me', 5)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7efe70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8259fde9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4f15aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93112fad",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "84f0cde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_post(post):\n",
    "    \n",
    "    date = post.get('upload_date', None)\n",
    "    \n",
    "    if post.get('text', None) is None:\n",
    "        print(f'I dont see any text, can you add it to post uploaded at {date}?')\n",
    "        return False\n",
    "    \n",
    "    text = post.get('text', None)\n",
    "    \n",
    "    if post.get('parsed_date', None) is None:\n",
    "        print(f'I dont see date, can you add it to post uploaded at {date} with text:{text}?')\n",
    "        return False\n",
    "\n",
    "    if post.get('productivity_score', None) is None:\n",
    "        print(f'I dont see productivity_score, can you add it to post uploaded at {date} with text: {text}?')\n",
    "        return False\n",
    "        \n",
    "    if post.get('interest_score', None) is None:\n",
    "        print(f'I dont see interest_score, can you add it to post uploaded at {date} with text: {text}?')\n",
    "        return False\n",
    "        \n",
    "    if post.get('productivity_score', None) is None:\n",
    "        print(f'I dont see productivity_score, can you add it to post uploaded at {date} with text: {text}?')\n",
    "        return False\n",
    "        \n",
    "    if post.get('stress_score', None) is None:\n",
    "        print(f'I dont see stress_score, can you add it to post uploaded at {date} with text: {text}?')\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def check_activities(post):\n",
    "    \n",
    "    date = post.get('upload_date', None)\n",
    "    \n",
    "    \n",
    "    if post.get('parsed_activities', None) is None or len(post.get('parsed_activities', None)) < 0:\n",
    "        print(f'I dont see activities, can you add some to post uploaded at {date}?')\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b8fd552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "posts = get_posts(num_posts = 1000)\n",
    "\n",
    "for post in posts:\n",
    "    post = parse_text(post)\n",
    "    post = parse_activities(post)\n",
    "    if check_post(post):\n",
    "        upload_post(post, overwrite = False)\n",
    "        if check_activities(post):\n",
    "            upload_activities(post, overwrite = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0ba796c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg\n"
     ]
    }
   ],
   "source": [
    "print('fg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e599d55",
   "metadata": {},
   "source": [
    "# Data markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "23be7d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def markup_activities_type():\n",
    "    try:\n",
    "        with connect(host=db_host, user=db_user, password=db_password,) as connection:\n",
    "            use_db_query = f\"USE {db_name};\"\n",
    "            \n",
    "            markup_query = '''SELECT * FROM activities WHERE activity_type is NULL'''    \n",
    "            \n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(use_db_query)\n",
    "                cursor.execute(markup_query)\n",
    "                for el in cursor:\n",
    "                    activity_id = el[0]\n",
    "                    activity_name = el[2]\n",
    "                    activity_types = ['self_development', 'university', 'work', 'relax_&_rest', 'chill', 'sport_&_health', 'family', 'social_&_friends' 'travel_&_adventure', 'chore', 'other']\n",
    "                    print('==============================================================================')\n",
    "                    print(f'ACTIVITY NAME: {activity_name}')\n",
    "                    #print('What type of activity this is?')\n",
    "                    print('\\n'.join([str(i) + ' - ' + activity_types[i-1] for i in range(1, len(activity_types) + 1)]))\n",
    "                    activity_num = input('SELECT ACTIVITY TYPE:')\n",
    "                    \n",
    "                    try:\n",
    "                        activity_type = activity_types[int(activity_num) - 1]\n",
    "                        update_activity(activity_id, {'activity_type':activity_type})\n",
    "                    except Error as e:\n",
    "                        print(f'ERROR: {e}')\n",
    "\n",
    "    except Error as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "ec2ffe13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================\n",
      "ACTIVITY NAME: Hiking with Ann\n",
      "1 - self_development;\n",
      "2 - university;\n",
      "3 - work;\n",
      "4 - relax_&_rest;\n",
      "5 - chill;\n",
      "6 - sport_&_health;\n",
      "7 - family;\n",
      "8 - social_&_friendstravel_&_adventure;\n",
      "9 - chore;\n",
      "10 - other;\n",
      "SELECT ACTIVITY TYPE:7\n",
      "UPDATED: activity with id:9\n",
      "==============================================================================\n",
      "ACTIVITY NAME: Working on my project\n",
      "1 - self_development;\n",
      "2 - university;\n",
      "3 - work;\n",
      "4 - relax_&_rest;\n",
      "5 - chill;\n",
      "6 - sport_&_health;\n",
      "7 - family;\n",
      "8 - social_&_friendstravel_&_adventure;\n",
      "9 - chore;\n",
      "10 - other;\n",
      "SELECT ACTIVITY TYPE:1\n",
      "UPDATED: activity with id:10\n",
      "==============================================================================\n",
      "ACTIVITY NAME: Gym\n",
      "1 - self_development;\n",
      "2 - university;\n",
      "3 - work;\n",
      "4 - relax_&_rest;\n",
      "5 - chill;\n",
      "6 - sport_&_health;\n",
      "7 - family;\n",
      "8 - social_&_friendstravel_&_adventure;\n",
      "9 - chore;\n",
      "10 - other;\n",
      "SELECT ACTIVITY TYPE:6\n",
      "UPDATED: activity with id:11\n",
      "==============================================================================\n",
      "ACTIVITY NAME: Interesting history lecture\n",
      "1 - self_development;\n",
      "2 - university;\n",
      "3 - work;\n",
      "4 - relax_&_rest;\n",
      "5 - chill;\n",
      "6 - sport_&_health;\n",
      "7 - family;\n",
      "8 - social_&_friendstravel_&_adventure;\n",
      "9 - chore;\n",
      "10 - other;\n",
      "Unread result found\n"
     ]
    }
   ],
   "source": [
    "markup_activities_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7f372a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_id INT AUTO_INCREMENT,\n",
    "                post_id INT,\n",
    "                activity_name TEXT,\n",
    "                activity_emoji TEXT,\n",
    "                activity_type TEXT,\n",
    "                activity_emotion TEXT,\n",
    "                predicted_activity_type TEXT,\n",
    "                predicted_activity_emotion TEXT,\n",
    "                FOREIGN KEY (post_id) REFERENCES posts(post_id),\n",
    "                PRIMARY KEY (activity_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "8bc8a270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================\n",
      "ACTIVITY NAME: sakisaki Hiking with Ann\n",
      "1 - self_development;\n",
      "2 - university;\n",
      "3 - work;\n",
      "4 - relax_&_rest;\n",
      "5 - sport_&_health;\n",
      "6 - family;\n",
      "7 - travel_&_adventure;\n",
      "8 - chore;\n",
      "9 - other;\n",
      "SELECT ACTIVITY TYPE:1\n",
      "==============================================================================\n",
      "ACTIVITY NAME: Working on my project\n",
      "1 - self_development;\n",
      "2 - university;\n",
      "3 - work;\n",
      "4 - relax_&_rest;\n",
      "5 - sport_&_health;\n",
      "6 - family;\n",
      "7 - travel_&_adventure;\n",
      "8 - chore;\n",
      "9 - other;\n",
      "SELECT ACTIVITY TYPE:1\n",
      "==============================================================================\n",
      "ACTIVITY NAME: Gym\n",
      "1 - self_development;\n",
      "2 - university;\n",
      "3 - work;\n",
      "4 - relax_&_rest;\n",
      "5 - sport_&_health;\n",
      "6 - family;\n",
      "7 - travel_&_adventure;\n",
      "8 - chore;\n",
      "9 - other;\n",
      "Unread result found\n"
     ]
    }
   ],
   "source": [
    "def markup_activity_type():\n",
    "    pass\n",
    "\n",
    "res = db_test_query('SELECT * FROM activities WHERE activity_type is NULL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979c2689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "989d3e8a",
   "metadata": {},
   "source": [
    "# Activity classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "760d30ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there some stupid shit,later i will finetune bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d53d2412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45d71be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "279d7fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'box traning',\n",
       " 'labels': ['other',\n",
       "  'self_development',\n",
       "  'relax_&_rest',\n",
       "  'travel_&_adventure',\n",
       "  'work_&_job',\n",
       "  'home_chore',\n",
       "  'sport',\n",
       "  'family',\n",
       "  'university'],\n",
       " 'scores': [0.3176390826702118,\n",
       "  0.18102319538593292,\n",
       "  0.10530360788106918,\n",
       "  0.10282707959413528,\n",
       "  0.10149189084768295,\n",
       "  0.08444009721279144,\n",
       "  0.059940967708826065,\n",
       "  0.03241773694753647,\n",
       "  0.014916374348104]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_to_classify = \"box traning\"\n",
    "candidate_labels = ['self_development', 'university', 'work_&_job', 'relax_&_rest', 'sport', 'family', 'travel_&_adventure', 'home_chore', 'other']\n",
    "facebook_bart_large_mnli(sequence_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e29add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activity_type(activity_name, classifier):\n",
    "    candidate_labels = ['self_development', 'university', 'work_&_job', 'relax_&_rest', 'sport', 'family', 'travel_&_adventure', 'home_chore', 'other']\n",
    "    return classifier(activity_name, candidate_labels)['labels'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d38fa08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sport'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_activity_type('boxing traning',facebook_bart_large_mnli)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fe08cb",
   "metadata": {},
   "source": [
    "# Sentiment analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96b4e41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fdee3305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "bertweet_base_sentiment_analysis = pipeline(\"text-classification\", model=\"/media/tonyalpha/HDD/bertweet-base-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9fd8bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEG', 'score': 0.8925472497940063},\n",
       " {'label': 'NEU', 'score': 0.0853690579533577},\n",
       " {'label': 'POS', 'score': 0.022083677351474762}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertweet_base_sentiment_analysis('Sad day', top_k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f974e66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a56fc91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b19323d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b6f1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d25107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f975e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71529a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7238e02f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316cc5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1637d01a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141b4c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a8ecd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd4e8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b67e6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0180f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0355a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c821d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad4c45d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aee8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313ce9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fdaacf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15339314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1c3a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7853c2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22b9b64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f280c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf06b60357b449aa3989e5a2d4f2e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e513cdf44054a55b8996fca5b1e574d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/2.04k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b69fcc109e49898727f7e37dcdf8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/6.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b691bfe0e5494e9bf80942152a69c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/196M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a254b4a65604b8aadaaf1f14cb2f1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/650000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c87d9c09e5064d2fa4768a5550e95137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'text': 'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\'s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\\"serving off their orders\\\\\" when they didn\\'t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\'ve eaten at various McDonalds restaurants for over 30 years. I\\'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "dataset[\"train\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "866fbdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662b4baaf27e4232a0dbe97d4dd52e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd082cccd5ee4d4aab3295c7282ac363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f952412163f44774a4f7dee4156c9c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3455aee3059c46118e65104c4323edb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16cc464ef1694d6bbedf9dfe254adf5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/650000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4142f7dfd54e4f10b957a6236b309a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f493950",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b03ae85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853c8b23f9594586b68fa39fdb65d358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-cdd4dd3d4f8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-cased\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    472\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2448\u001b[0m                         \u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcommit_hash\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2449\u001b[0m                     }\n\u001b[0;32m-> 2450\u001b[0;31m                     \u001b[0mresolved_archive_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcached_file_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2452\u001b[0m                     \u001b[0;31m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    410\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1362\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"downloading %s to %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m             http_get(\n\u001b[0m\u001b[1;32m   1365\u001b[0m                 \u001b[0murl_to_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m                 \u001b[0mtemp_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries, expected_size)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetEffectiveLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOTSET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     )\n\u001b[0;32m--> 541\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_catcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m                 \u001b[0mflush_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;31m# StringIO doesn't like amt=None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202cf443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed11403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adbcda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e864ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693a263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9700a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451b40ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fa9ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d94ac33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f220cdf",
   "metadata": {},
   "source": [
    "# Sync with DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea8fc77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6dd978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110f7054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f01201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4152b34b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987df34b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3eb385a6",
   "metadata": {},
   "source": [
    "# Etc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524700f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
